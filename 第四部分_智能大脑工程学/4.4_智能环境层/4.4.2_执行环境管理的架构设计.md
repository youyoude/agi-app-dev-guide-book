# 4.4.2 æ‰§è¡Œç¯å¢ƒç®¡ç†çš„æ¶æ„è®¾è®¡

> "æ‰§è¡Œç¯å¢ƒæ˜¯AIåº”ç”¨çš„èˆå°ï¼Œä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„èˆå°ã€‚æ™ºèƒ½ç¯å¢ƒç®¡ç†çš„è‰ºæœ¯åœ¨äºä¸ºæ¯ä¸ªæ¼”å‡ºæä¾›æœ€åˆé€‚çš„èˆå°ï¼Œè®©æ™ºèƒ½åº”ç”¨çš„æ¯ä¸€æ¬¡æ‰§è¡Œéƒ½èƒ½å‘æŒ¥æœ€ä½³æ€§èƒ½ã€‚"

## ğŸ¯ æœ¬èŠ‚å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬èŠ‚å­¦ä¹ åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- âœ… è®¾è®¡å¤šå±‚æ¬¡çš„æ‰§è¡Œç¯å¢ƒç®¡ç†ä½“ç³»
- âœ… å®ç°å®¹å™¨åŒ–ã€è™šæ‹ŸåŒ–å’Œæ²™ç®±ç¯å¢ƒçš„ç»Ÿä¸€ç®¡ç†
- âœ… æ„å»ºå“åº”å·¥å…·è¿è¡Œå±‚éœ€æ±‚çš„ç¯å¢ƒåˆ†é…æœºåˆ¶
- âœ… å»ºç«‹ç¯å¢ƒç”Ÿå‘½å‘¨æœŸç®¡ç†å’Œç›‘æ§ä½“ç³»

## å¤šç±»å‹æ‰§è¡Œç¯å¢ƒæ¦‚è¿°

### AIåº”ç”¨çš„ç¯å¢ƒéœ€æ±‚ç‰¹ç‚¹

åŸºäºæˆ‘ä»¬ä¿®æ­£çš„æ¶æ„å…³ç³»ï¼Œå·¥å…·æ‰©å±•è¿è¡Œå±‚ä¼šå‘æ™ºèƒ½ç¯å¢ƒå±‚ç”³è¯·ä¸åŒç±»å‹çš„æ‰§è¡Œç¯å¢ƒã€‚AIåº”ç”¨çš„ç¯å¢ƒéœ€æ±‚å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

```mermaid
graph TB
    subgraph "å·¥å…·æ‰©å±•è¿è¡Œå±‚çš„ç¯å¢ƒç”³è¯·"
        TR[ğŸ”§ å·¥å…·æ‰©å±•è¿è¡Œå±‚]
        REQ1[æ•°æ®å¤„ç†å·¥å…·éœ€æ±‚]
        REQ2[APIè°ƒç”¨å·¥å…·éœ€æ±‚]  
        REQ3[ä»£ç æ‰§è¡Œå·¥å…·éœ€æ±‚]
        REQ4[AIæ¨¡å‹æ¨ç†éœ€æ±‚]
        
        TR --> REQ1
        TR --> REQ2
        TR --> REQ3
        TR --> REQ4
    end
    
    subgraph "æ™ºèƒ½ç¯å¢ƒå±‚çš„ç¯å¢ƒå“åº”"
        ENV[ğŸ³ æ™ºèƒ½ç¯å¢ƒå±‚]
        CONTAINER[ğŸ“¦ å®¹å™¨ç¯å¢ƒ]
        VM[ğŸ–¥ï¸ è™šæ‹Ÿæœºç¯å¢ƒ]  
        SANDBOX[ğŸ›ï¸ æ²™ç®±ç¯å¢ƒ]
        GPU_CLUSTER[âš¡ GPUé›†ç¾¤ç¯å¢ƒ]
        
        ENV --> CONTAINER
        ENV --> VM
        ENV --> SANDBOX
        ENV --> GPU_CLUSTER
    end
    
    REQ1 --> CONTAINER
    REQ2 --> SANDBOX
    REQ3 --> VM
    REQ4 --> GPU_CLUSTER
    
    style TR fill:#e8f5e8
    style ENV fill:#fff3e0
```

### ç¯å¢ƒç±»å‹å¯¹æ¯”åˆ†æ

ä¸åŒæ‰§è¡Œç¯å¢ƒçš„æŠ€æœ¯ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯å¯¹æ¯”ï¼š

| ç¯å¢ƒç±»å‹ | å¯åŠ¨é€Ÿåº¦ | èµ„æºéš”ç¦» | å®‰å…¨æ€§ | é€‚ç”¨åœºæ™¯ | èµ„æºå¼€é”€ |
|---------|----------|----------|--------|----------|----------|
| **å®¹å™¨ç¯å¢ƒ** | ç§’çº§ | è¿›ç¨‹çº§ | ä¸­ç­‰ | å¾®æœåŠ¡ã€å¿«é€Ÿéƒ¨ç½² | ä½ |
| **è™šæ‹Ÿæœºç¯å¢ƒ** | åˆ†é’Ÿçº§ | ç³»ç»Ÿçº§ | é«˜ | å®Œæ•´ç³»ç»Ÿç¯å¢ƒ | é«˜ |
| **æ²™ç®±ç¯å¢ƒ** | ç§’çº§ | è¿›ç¨‹çº§+ | å¾ˆé«˜ | ä¸trustedä»£ç æ‰§è¡Œ | ä¸­ç­‰ |
| **Serverlessç¯å¢ƒ** | æ¯«ç§’çº§ | å‡½æ•°çº§ | é«˜ | äº‹ä»¶é©±åŠ¨ä»»åŠ¡ | æä½ |

### ç¯å¢ƒé€‰æ‹©å†³ç­–ç®—æ³•

```python
from typing import Dict, Any, List
from dataclasses import dataclass
from enum import Enum

class EnvironmentType(Enum):
    CONTAINER = "container"
    VIRTUAL_MACHINE = "virtual_machine"
    SANDBOX = "sandbox"
    SERVERLESS = "serverless"
    GPU_CLUSTER = "gpu_cluster"

@dataclass
class EnvironmentRequirement:
    """ç¯å¢ƒéœ€æ±‚å®šä¹‰"""
    tool_type: str
    security_level: str  # low, medium, high, critical
    resource_needs: Dict[str, Any]
    execution_time_estimate: float  # seconds
    isolation_level: str  # process, container, vm, bare_metal
    network_access: bool
    persistent_storage: bool
    gpu_required: bool

class EnvironmentSelector:
    """ç¯å¢ƒé€‰æ‹©å†³ç­–å¼•æ“"""
    
    def __init__(self):
        self.selection_rules = self._initialize_selection_rules()
        self.environment_capabilities = self._initialize_environment_capabilities()
        
    def select_environment(self, requirement: EnvironmentRequirement) -> EnvironmentType:
        """æ™ºèƒ½é€‰æ‹©æ‰§è¡Œç¯å¢ƒ"""
        
        # 1. å®‰å…¨çº§åˆ«è¿‡æ»¤
        security_filtered = self._filter_by_security_level(requirement.security_level)
        
        # 2. èµ„æºéœ€æ±‚åŒ¹é…
        resource_matched = self._match_resource_requirements(
            security_filtered, requirement.resource_needs
        )
        
        # 3. æ€§èƒ½æ•ˆç‡è¯„ä¼°
        performance_scored = self._score_by_performance(
            resource_matched, requirement.execution_time_estimate
        )
        
        # 4. æˆæœ¬æ•ˆç›Šåˆ†æ
        cost_optimized = self._optimize_by_cost(performance_scored, requirement)
        
        return cost_optimized[0] if cost_optimized else EnvironmentType.CONTAINER
    
    def _initialize_selection_rules(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–é€‰æ‹©è§„åˆ™"""
        
        return {
            "security_critical": {
                "required_isolation": "vm",
                "network_restrictions": True,
                "audit_required": True
            },
            "gpu_intensive": {
                "environment_types": [EnvironmentType.GPU_CLUSTER],
                "resource_scaling": "vertical"
            },
            "short_lived_tasks": {
                "preferred_types": [EnvironmentType.SERVERLESS, EnvironmentType.CONTAINER],
                "startup_time_priority": "high"
            },
            "data_processing": {
                "preferred_types": [EnvironmentType.CONTAINER, EnvironmentType.VIRTUAL_MACHINE],
                "storage_requirements": "high"
            }
        }
    
    def _filter_by_security_level(self, security_level: str) -> List[EnvironmentType]:
        """æ ¹æ®å®‰å…¨çº§åˆ«è¿‡æ»¤ç¯å¢ƒç±»å‹"""
        
        security_mappings = {
            "low": [EnvironmentType.CONTAINER, EnvironmentType.SERVERLESS],
            "medium": [EnvironmentType.CONTAINER, EnvironmentType.SANDBOX, EnvironmentType.SERVERLESS],
            "high": [EnvironmentType.SANDBOX, EnvironmentType.VIRTUAL_MACHINE],
            "critical": [EnvironmentType.VIRTUAL_MACHINE]
        }
        
        return security_mappings.get(security_level, [EnvironmentType.CONTAINER])
    
    def _score_by_performance(self, 
                            environment_types: List[EnvironmentType],
                            execution_time: float) -> List[EnvironmentType]:
        """æ ¹æ®æ€§èƒ½éœ€æ±‚è¯„åˆ†æ’åº"""
        
        performance_scores = {}
        
        for env_type in environment_types:
            score = 0
            
            # å¯åŠ¨æ—¶é—´è¯„åˆ†
            startup_times = {
                EnvironmentType.SERVERLESS: 0.1,
                EnvironmentType.CONTAINER: 2.0,
                EnvironmentType.SANDBOX: 1.5,
                EnvironmentType.VIRTUAL_MACHINE: 30.0,
                EnvironmentType.GPU_CLUSTER: 10.0
            }
            
            startup_time = startup_times.get(env_type, 5.0)
            
            # å¯¹äºçŸ­æ—¶ä»»åŠ¡ï¼Œå¯åŠ¨æ—¶é—´å½±å“æ›´å¤§
            if execution_time < 60:  # 1åˆ†é’Ÿä»¥ä¸‹
                score += (10 - startup_time) * 2
            else:
                score += (10 - startup_time)
            
            # æ‰§è¡Œæ•ˆç‡è¯„åˆ†
            execution_efficiency = {
                EnvironmentType.VIRTUAL_MACHINE: 9,
                EnvironmentType.GPU_CLUSTER: 10,
                EnvironmentType.CONTAINER: 8,
                EnvironmentType.SANDBOX: 6,
                EnvironmentType.SERVERLESS: 7
            }
            
            score += execution_efficiency.get(env_type, 5)
            performance_scores[env_type] = score
        
        return sorted(performance_scores.keys(), 
                     key=lambda x: performance_scores[x], reverse=True)
```

## å®¹å™¨åŒ–ç¯å¢ƒç®¡ç†

### Dockerå®¹å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†

å®¹å™¨åŒ–ç¯å¢ƒæ˜¯AIåº”ç”¨æœ€å¸¸ç”¨çš„æ‰§è¡Œç¯å¢ƒï¼Œéœ€è¦å®Œå–„çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼š

```python
import asyncio
import docker
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import json

class ContainerLifecycleManager:
    """å®¹å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨"""
    
    def __init__(self):
        self.docker_client = docker.from_env()
        self.active_containers = {}
        self.container_templates = {}
        self.resource_limits = {}
        
    async def create_container_for_tool(self, 
                                      tool_request: Dict[str, Any]) -> str:
        """ä¸ºå·¥å…·è¯·æ±‚åˆ›å»ºä¸“ç”¨å®¹å™¨"""
        
        container_config = await self._build_container_config(tool_request)
        
        try:
            # åˆ›å»ºå®¹å™¨
            container = self.docker_client.containers.run(
                **container_config,
                detach=True
            )
            
            container_id = container.id
            
            # è®°å½•å®¹å™¨ä¿¡æ¯
            self.active_containers[container_id] = {
                "container": container,
                "tool_request": tool_request,
                "created_at": datetime.now(),
                "status": "created",
                "resource_usage": {}
            }
            
            # ç­‰å¾…å®¹å™¨å°±ç»ª
            await self._wait_for_container_ready(container)
            
            self.active_containers[container_id]["status"] = "running"
            
            return container_id
            
        except Exception as e:
            self.logger.error(f"Container creation failed: {e}")
            raise ContainerCreationError(str(e))
    
    async def _build_container_config(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºå®¹å™¨é…ç½®"""
        
        tool_type = tool_request.get("tool_type", "generic")
        
        # é€‰æ‹©åŸºç¡€é•œåƒ
        base_image = self._select_base_image(tool_type, tool_request)
        
        # é…ç½®èµ„æºé™åˆ¶
        resource_limits = self._calculate_resource_limits(tool_request)
        
        # é…ç½®ç¯å¢ƒå˜é‡
        environment = self._build_environment_variables(tool_request)
        
        # é…ç½®æŒ‚è½½å·
        volumes = self._configure_volumes(tool_request)
        
        # é…ç½®ç½‘ç»œ
        network_config = self._configure_network(tool_request)
        
        return {
            "image": base_image,
            "name": f"tool-{tool_request['tool_id']}-{int(datetime.now().timestamp())}",
            "environment": environment,
            "volumes": volumes,
            "mem_limit": resource_limits["memory"],
            "cpu_quota": resource_limits["cpu_quota"],
            "cpu_period": resource_limits["cpu_period"],
            "network_mode": network_config["mode"],
            "ports": network_config.get("ports", {}),
            "working_dir": "/workspace",
            "user": "1000:1000",  # érootç”¨æˆ·è¿è¡Œ
            "read_only": tool_request.get("read_only", False),
            "tmpfs": {"/tmp": "rw,size=100m"},
            "security_opt": ["no-new-privileges:true"],
            "cap_drop": ["ALL"],
            "cap_add": self._required_capabilities(tool_type)
        }
    
    def _select_base_image(self, tool_type: str, tool_request: Dict[str, Any]) -> str:
        """é€‰æ‹©åˆé€‚çš„åŸºç¡€é•œåƒ"""
        
        image_mappings = {
            "python": "python:3.11-slim",
            "nodejs": "node:18-alpine",
            "java": "openjdk:17-jre-slim", 
            "data_analysis": "jupyter/scipy-notebook:latest",
            "ml_inference": "tensorflow/tensorflow:2.13.0",
            "web_scraping": "selenium/standalone-chrome:latest"
        }
        
        # æ ¹æ®ç‰¹æ®Šéœ€æ±‚è°ƒæ•´
        if tool_request.get("gpu_required", False):
            gpu_images = {
                "python": "tensorflow/tensorflow:2.13.0-gpu",
                "ml_inference": "pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime"
            }
            return gpu_images.get(tool_type, "nvidia/cuda:11.7-runtime-ubuntu20.04")
        
        return image_mappings.get(tool_type, "alpine:latest")
    
    def _calculate_resource_limits(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—èµ„æºé™åˆ¶"""
        
        resource_requirements = tool_request.get("resource_requirements", {})
        
        # é»˜è®¤èµ„æºé™åˆ¶
        defaults = {
            "memory": "512m",
            "cpu_quota": 50000,  # 0.5 CPU
            "cpu_period": 100000
        }
        
        # æ ¹æ®å·¥å…·ç±»å‹è°ƒæ•´
        tool_type_adjustments = {
            "data_analysis": {"memory": "2g", "cpu_quota": 100000},
            "ml_inference": {"memory": "4g", "cpu_quota": 200000},
            "web_scraping": {"memory": "1g", "cpu_quota": 100000}
        }
        
        tool_type = tool_request.get("tool_type", "generic")
        if tool_type in tool_type_adjustments:
            defaults.update(tool_type_adjustments[tool_type])
        
        # åº”ç”¨ç”¨æˆ·æŒ‡å®šçš„èµ„æºéœ€æ±‚
        if "memory" in resource_requirements:
            defaults["memory"] = resource_requirements["memory"]
        
        if "cpu_cores" in resource_requirements:
            cpu_cores = float(resource_requirements["cpu_cores"])
            defaults["cpu_quota"] = int(cpu_cores * 100000)
        
        return defaults
    
    async def monitor_container_health(self, container_id: str) -> Dict[str, Any]:
        """ç›‘æ§å®¹å™¨å¥åº·çŠ¶æ€"""
        
        if container_id not in self.active_containers:
            return {"error": "Container not found"}
        
        container_info = self.active_containers[container_id]
        container = container_info["container"]
        
        try:
            # åˆ·æ–°å®¹å™¨çŠ¶æ€
            container.reload()
            
            # è·å–å®¹å™¨ç»Ÿè®¡ä¿¡æ¯
            stats = container.stats(stream=False)
            
            # è§£æèµ„æºä½¿ç”¨æƒ…å†µ
            resource_usage = self._parse_container_stats(stats)
            
            # æ›´æ–°å®¹å™¨ä¿¡æ¯
            container_info["resource_usage"] = resource_usage
            container_info["last_check"] = datetime.now()
            
            # å¥åº·æ£€æŸ¥
            health_status = await self._perform_health_check(container)
            
            return {
                "container_id": container_id,
                "status": container.status,
                "resource_usage": resource_usage,
                "health_status": health_status,
                "uptime": (datetime.now() - container_info["created_at"]).total_seconds()
            }
            
        except Exception as e:
            return {
                "container_id": container_id,
                "error": str(e),
                "status": "error"
            }
    
    def _parse_container_stats(self, stats: Dict) -> Dict[str, float]:
        """è§£æå®¹å™¨ç»Ÿè®¡ä¿¡æ¯"""
        
        # CPUä½¿ç”¨ç‡è®¡ç®—
        cpu_stats = stats.get("cpu_stats", {})
        precpu_stats = stats.get("precpu_stats", {})
        
        cpu_delta = (cpu_stats.get("cpu_usage", {}).get("total_usage", 0) - 
                    precpu_stats.get("cpu_usage", {}).get("total_usage", 0))
        system_delta = (cpu_stats.get("system_cpu_usage", 0) - 
                       precpu_stats.get("system_cpu_usage", 0))
        
        cpu_percent = 0.0
        if system_delta > 0:
            num_cpus = len(cpu_stats.get("cpu_usage", {}).get("percpu_usage", [1]))
            cpu_percent = (cpu_delta / system_delta) * num_cpus * 100
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory_stats = stats.get("memory_stats", {})
        memory_usage = memory_stats.get("usage", 0)
        memory_limit = memory_stats.get("limit", 0)
        memory_percent = (memory_usage / memory_limit * 100) if memory_limit > 0 else 0
        
        # ç½‘ç»œI/O
        networks = stats.get("networks", {})
        network_rx = sum(net.get("rx_bytes", 0) for net in networks.values())
        network_tx = sum(net.get("tx_bytes", 0) for net in networks.values())
        
        return {
            "cpu_percent": round(cpu_percent, 2),
            "memory_usage_mb": round(memory_usage / 1024 / 1024, 2),
            "memory_percent": round(memory_percent, 2),
            "network_rx_mb": round(network_rx / 1024 / 1024, 2),
            "network_tx_mb": round(network_tx / 1024 / 1024, 2)
        }
```

### Kubernetesé›†ç¾¤ç¼–æ’

å¯¹äºå¤§è§„æ¨¡AIåº”ç”¨éƒ¨ç½²ï¼ŒKubernetesæä¾›äº†å¼ºå¤§çš„å®¹å™¨ç¼–æ’èƒ½åŠ›ï¼š

```python
from kubernetes import client, config
from kubernetes.client.rest import ApiException
import yaml

class KubernetesEnvironmentManager:
    """Kubernetesç¯å¢ƒç®¡ç†å™¨"""
    
    def __init__(self, kubeconfig_path: Optional[str] = None):
        if kubeconfig_path:
            config.load_kube_config(config_file=kubeconfig_path)
        else:
            config.load_incluster_config()  # é›†ç¾¤å†…é…ç½®
            
        self.v1 = client.CoreV1Api()
        self.apps_v1 = client.AppsV1Api()
        self.custom_api = client.CustomObjectsApi()
        
    async def deploy_tool_environment(self, 
                                    tool_spec: Dict[str, Any]) -> Dict[str, str]:
        """éƒ¨ç½²å·¥å…·æ‰§è¡Œç¯å¢ƒ"""
        
        namespace = tool_spec.get("namespace", "default")
        
        # 1. åˆ›å»ºDeployment
        deployment = await self._create_deployment_manifest(tool_spec)
        deployment_result = self.apps_v1.create_namespaced_deployment(
            namespace=namespace, 
            body=deployment
        )
        
        # 2. åˆ›å»ºServiceï¼ˆå¦‚æœéœ€è¦ï¼‰
        service_result = None
        if tool_spec.get("expose_service", False):
            service = self._create_service_manifest(tool_spec)
            service_result = self.v1.create_namespaced_service(
                namespace=namespace,
                body=service
            )
        
        # 3. åˆ›å»ºConfigMapï¼ˆå¦‚æœæœ‰é…ç½®ï¼‰
        configmap_result = None
        if tool_spec.get("config_data"):
            configmap = self._create_configmap_manifest(tool_spec)
            configmap_result = self.v1.create_namespaced_config_map(
                namespace=namespace,
                body=configmap
            )
        
        return {
            "deployment_name": deployment_result.metadata.name,
            "service_name": service_result.metadata.name if service_result else None,
            "configmap_name": configmap_result.metadata.name if configmap_result else None,
            "namespace": namespace
        }
    
    def _create_deployment_manifest(self, tool_spec: Dict[str, Any]) -> client.V1Deployment:
        """åˆ›å»ºDeploymentæ¸…å•"""
        
        container_spec = client.V1Container(
            name=tool_spec["name"],
            image=tool_spec["image"],
            ports=[client.V1ContainerPort(container_port=tool_spec.get("port", 8080))],
            env=self._build_env_vars(tool_spec.get("environment", {})),
            resources=client.V1ResourceRequirements(
                requests=tool_spec.get("resources", {}).get("requests", {}),
                limits=tool_spec.get("resources", {}).get("limits", {})
            ),
            volume_mounts=self._build_volume_mounts(tool_spec.get("volumes", []))
        )
        
        pod_spec = client.V1PodSpec(
            containers=[container_spec],
            volumes=self._build_volumes(tool_spec.get("volumes", [])),
            security_context=client.V1PodSecurityContext(
                run_as_non_root=True,
                run_as_user=1000,
                fs_group=1000
            )
        )
        
        pod_template = client.V1PodTemplateSpec(
            metadata=client.V1ObjectMeta(
                labels=tool_spec.get("labels", {})
            ),
            spec=pod_spec
        )
        
        deployment_spec = client.V1DeploymentSpec(
            replicas=tool_spec.get("replicas", 1),
            selector=client.V1LabelSelector(
                match_labels=tool_spec.get("labels", {})
            ),
            template=pod_template
        )
        
        return client.V1Deployment(
            api_version="apps/v1",
            kind="Deployment",
            metadata=client.V1ObjectMeta(name=tool_spec["name"]),
            spec=deployment_spec
        )
```

## æ²™ç®±ç¯å¢ƒè®¾è®¡

### å®‰å…¨æ²™ç®±éš”ç¦»æœºåˆ¶

æ²™ç®±ç¯å¢ƒæ˜¯æ‰§è¡Œä¸å—ä¿¡ä»»ä»£ç çš„å…³é”®æŠ€æœ¯ï¼Œéœ€è¦å®ç°å¤šå±‚æ¬¡çš„å®‰å…¨éš”ç¦»ï¼š

```python
import subprocess
import tempfile
import os
import resource
import signal
from pathlib import Path
from typing import Dict, Any, Optional

class SecureSandboxManager:
    """å®‰å…¨æ²™ç®±ç®¡ç†å™¨"""
    
    def __init__(self):
        self.sandbox_root = Path("/tmp/sandboxes")
        self.sandbox_root.mkdir(exist_ok=True)
        self.active_sandboxes = {}
        
    async def create_sandbox(self, 
                           sandbox_config: Dict[str, Any]) -> str:
        """åˆ›å»ºå®‰å…¨æ²™ç®±ç¯å¢ƒ"""
        
        sandbox_id = self._generate_sandbox_id()
        sandbox_path = self.sandbox_root / sandbox_id
        
        try:
            # 1. åˆ›å»ºæ²™ç®±ç›®å½•ç»“æ„
            await self._setup_sandbox_filesystem(sandbox_path, sandbox_config)
            
            # 2. é…ç½®èµ„æºé™åˆ¶
            resource_limits = self._configure_resource_limits(sandbox_config)
            
            # 3. è®¾ç½®ç½‘ç»œéš”ç¦»
            network_config = await self._setup_network_isolation(sandbox_id, sandbox_config)
            
            # 4. é…ç½®å®‰å…¨ç­–ç•¥
            security_policy = self._create_security_policy(sandbox_config)
            
            # 5. è®°å½•æ²™ç®±ä¿¡æ¯
            self.active_sandboxes[sandbox_id] = {
                "path": sandbox_path,
                "config": sandbox_config,
                "resource_limits": resource_limits,
                "network_config": network_config,
                "security_policy": security_policy,
                "created_at": datetime.now(),
                "status": "ready"
            }
            
            return sandbox_id
            
        except Exception as e:
            # æ¸…ç†å¤±è´¥çš„æ²™ç®±
            await self._cleanup_sandbox(sandbox_id)
            raise SandboxCreationError(f"Failed to create sandbox: {e}")
    
    async def _setup_sandbox_filesystem(self, 
                                      sandbox_path: Path, 
                                      config: Dict[str, Any]):
        """è®¾ç½®æ²™ç®±æ–‡ä»¶ç³»ç»Ÿ"""
        
        # åˆ›å»ºåŸºæœ¬ç›®å½•ç»“æ„
        directories = ["bin", "lib", "tmp", "workspace", "logs"]
        for directory in directories:
            (sandbox_path / directory).mkdir(parents=True, exist_ok=True)
        
        # å¤åˆ¶å¿…è¦çš„ç³»ç»Ÿæ–‡ä»¶
        system_files = [
            "/bin/sh",
            "/bin/bash", 
            "/usr/bin/python3",
            "/lib/x86_64-linux-gnu/libc.so.6",
            "/lib64/ld-linux-x86-64.so.2"
        ]
        
        for src_file in system_files:
            if os.path.exists(src_file):
                dest_file = sandbox_path / src_file.lstrip("/")
                dest_file.parent.mkdir(parents=True, exist_ok=True)
                
                # ä½¿ç”¨ç¡¬é“¾æ¥æˆ–å¤åˆ¶
                try:
                    os.link(src_file, str(dest_file))
                except OSError:
                    shutil.copy2(src_file, str(dest_file))
        
        # åˆ›å»ºå¿…è¦çš„è®¾å¤‡æ–‡ä»¶
        self._create_device_files(sandbox_path)
        
        # è®¾ç½®é€‚å½“çš„æƒé™
        os.chmod(str(sandbox_path), 0o755)
        for item in sandbox_path.rglob("*"):
            if item.is_file():
                os.chmod(str(item), 0o644)
            else:
                os.chmod(str(item), 0o755)
    
    def _create_device_files(self, sandbox_path: Path):
        """åˆ›å»ºå¿…è¦çš„è®¾å¤‡æ–‡ä»¶"""
        
        dev_path = sandbox_path / "dev"
        dev_path.mkdir(exist_ok=True)
        
        # åˆ›å»ºnullè®¾å¤‡
        null_path = dev_path / "null"
        if not null_path.exists():
            os.mknod(str(null_path), 0o666 | stat.S_IFCHR, os.makedev(1, 3))
        
        # åˆ›å»ºzeroè®¾å¤‡
        zero_path = dev_path / "zero"
        if not zero_path.exists():
            os.mknod(str(zero_path), 0o666 | stat.S_IFCHR, os.makedev(1, 5))
        
        # åˆ›å»ºrandomè®¾å¤‡
        random_path = dev_path / "random"
        if not random_path.exists():
            os.mknod(str(random_path), 0o666 | stat.S_IFCHR, os.makedev(1, 8))
    
    async def execute_in_sandbox(self, 
                                sandbox_id: str,
                                command: str,
                                input_data: Optional[str] = None) -> Dict[str, Any]:
        """åœ¨æ²™ç®±ä¸­æ‰§è¡Œå‘½ä»¤"""
        
        if sandbox_id not in self.active_sandboxes:
            raise SandboxNotFoundError(f"Sandbox {sandbox_id} not found")
        
        sandbox_info = self.active_sandboxes[sandbox_id]
        sandbox_path = sandbox_info["path"]
        
        try:
            # æ„å»ºæ‰§è¡Œç¯å¢ƒ
            env = self._build_sandbox_environment(sandbox_info)
            
            # é…ç½®èµ„æºé™åˆ¶
            self._apply_resource_limits(sandbox_info["resource_limits"])
            
            # æ‰§è¡Œå‘½ä»¤
            start_time = time.time()
            
            process = subprocess.Popen(
                ["chroot", str(sandbox_path), "/bin/sh", "-c", command],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                env=env,
                preexec_fn=self._setup_child_process,
                text=True
            )
            
            # è®¾ç½®æ‰§è¡Œè¶…æ—¶
            timeout = sandbox_info["config"].get("timeout", 30)
            
            try:
                stdout, stderr = process.communicate(
                    input=input_data,
                    timeout=timeout
                )
                
                execution_time = time.time() - start_time
                
                return {
                    "exit_code": process.returncode,
                    "stdout": stdout,
                    "stderr": stderr,
                    "execution_time": execution_time,
                    "sandbox_id": sandbox_id
                }
                
            except subprocess.TimeoutExpired:
                process.kill()
                return {
                    "exit_code": -1,
                    "stdout": "",
                    "stderr": "Execution timeout",
                    "execution_time": timeout,
                    "sandbox_id": sandbox_id,
                    "error": "timeout"
                }
                
        except Exception as e:
            return {
                "exit_code": -1,
                "stdout": "",
                "stderr": str(e),
                "execution_time": 0,
                "sandbox_id": sandbox_id,
                "error": str(e)
            }
    
    def _setup_child_process(self):
        """è®¾ç½®å­è¿›ç¨‹çš„å®‰å…¨é…ç½®"""
        
        # è®¾ç½®æ–°çš„è¿›ç¨‹ç»„
        os.setpgrp()
        
        # é™åˆ¶å¯ç”¨ä¿¡å·
        signal.signal(signal.SIGTERM, signal.SIG_DFL)
        signal.signal(signal.SIGINT, signal.SIG_DFL)
        
        # è®¾ç½®umask
        os.umask(0o022)
        
        # é™åˆ¶æ ¸å¿ƒè½¬å‚¨
        resource.setrlimit(resource.RLIMIT_CORE, (0, 0))
```

## ç»Ÿä¸€ç¯å¢ƒç®¡ç†æ¥å£

### ç¯å¢ƒæŠ½è±¡å±‚è®¾è®¡

ä¸ºäº†ç®¡ç†å¤šç§ç±»å‹çš„æ‰§è¡Œç¯å¢ƒï¼Œæˆ‘ä»¬éœ€è¦è®¾è®¡ç»Ÿä¸€çš„æŠ½è±¡æ¥å£ï¼š

```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from enum import Enum
import asyncio

class EnvironmentStatus(Enum):
    CREATING = "creating"
    READY = "ready"
    RUNNING = "running"  
    STOPPING = "stopping"
    STOPPED = "stopped"
    ERROR = "error"

class ExecutionEnvironment(ABC):
    """æ‰§è¡Œç¯å¢ƒæŠ½è±¡åŸºç±»"""
    
    def __init__(self, environment_id: str, config: Dict[str, Any]):
        self.environment_id = environment_id
        self.config = config
        self.status = EnvironmentStatus.CREATING
        self.created_at = datetime.now()
        self.resource_usage = {}
        
    @abstractmethod
    async def create(self) -> bool:
        """åˆ›å»ºç¯å¢ƒ"""
        pass
    
    @abstractmethod
    async def start(self) -> bool:
        """å¯åŠ¨ç¯å¢ƒ"""
        pass
    
    @abstractmethod
    async def stop(self) -> bool:
        """åœæ­¢ç¯å¢ƒ"""
        pass
    
    @abstractmethod
    async def destroy(self) -> bool:
        """é”€æ¯ç¯å¢ƒ"""
        pass
    
    @abstractmethod
    async def execute(self, command: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œå‘½ä»¤"""
        pass
    
    @abstractmethod
    async def get_status(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€ä¿¡æ¯"""
        pass
    
    @abstractmethod
    async def get_resource_usage(self) -> Dict[str, float]:
        """è·å–èµ„æºä½¿ç”¨æƒ…å†µ"""
        pass

class UnifiedEnvironmentManager:
    """ç»Ÿä¸€ç¯å¢ƒç®¡ç†å™¨"""
    
    def __init__(self):
        self.environments = {}
        self.environment_factories = {
            EnvironmentType.CONTAINER: ContainerEnvironmentFactory(),
            EnvironmentType.VIRTUAL_MACHINE: VMEnvironmentFactory(),
            EnvironmentType.SANDBOX: SandboxEnvironmentFactory(),
            EnvironmentType.SERVERLESS: ServerlessEnvironmentFactory()
        }
        
    async def create_environment(self, 
                               env_type: EnvironmentType,
                               config: Dict[str, Any]) -> str:
        """åˆ›å»ºæ‰§è¡Œç¯å¢ƒ"""
        
        if env_type not in self.environment_factories:
            raise UnsupportedEnvironmentError(f"Environment type {env_type} not supported")
        
        # ç”Ÿæˆç¯å¢ƒID
        env_id = self._generate_environment_id(env_type)
        
        # ä½¿ç”¨å·¥å‚åˆ›å»ºç¯å¢ƒå®ä¾‹
        factory = self.environment_factories[env_type]
        environment = await factory.create_environment(env_id, config)
        
        # æ³¨å†Œç¯å¢ƒ
        self.environments[env_id] = {
            "type": env_type,
            "instance": environment,
            "config": config,
            "created_at": datetime.now()
        }
        
        return env_id
    
    async def execute_in_environment(self, 
                                   env_id: str,
                                   command: str,
                                   **kwargs) -> Dict[str, Any]:
        """åœ¨æŒ‡å®šç¯å¢ƒä¸­æ‰§è¡Œå‘½ä»¤"""
        
        if env_id not in self.environments:
            raise EnvironmentNotFoundError(f"Environment {env_id} not found")
        
        environment_info = self.environments[env_id]
        environment = environment_info["instance"]
        
        # ç¡®ä¿ç¯å¢ƒå¤„äºè¿è¡ŒçŠ¶æ€
        if environment.status not in [EnvironmentStatus.READY, EnvironmentStatus.RUNNING]:
            await environment.start()
        
        # æ‰§è¡Œå‘½ä»¤
        result = await environment.execute(command, **kwargs)
        
        # æ›´æ–°èµ„æºä½¿ç”¨æƒ…å†µ
        resource_usage = await environment.get_resource_usage()
        environment_info["resource_usage"] = resource_usage
        
        return result
    
    async def get_environment_status(self, env_id: str) -> Dict[str, Any]:
        """è·å–ç¯å¢ƒçŠ¶æ€"""
        
        if env_id not in self.environments:
            raise EnvironmentNotFoundError(f"Environment {env_id} not found")
        
        environment_info = self.environments[env_id]
        environment = environment_info["instance"]
        
        status = await environment.get_status()
        resource_usage = await environment.get_resource_usage()
        
        return {
            "environment_id": env_id,
            "type": environment_info["type"].value,
            "status": status,
            "resource_usage": resource_usage,
            "created_at": environment_info["created_at"].isoformat(),
            "uptime": (datetime.now() - environment_info["created_at"]).total_seconds()
        }
    
    async def cleanup_environment(self, env_id: str) -> bool:
        """æ¸…ç†ç¯å¢ƒ"""
        
        if env_id not in self.environments:
            return False
        
        environment_info = self.environments[env_id]
        environment = environment_info["instance"]
        
        try:
            # åœæ­¢ç¯å¢ƒ
            await environment.stop()
            
            # é”€æ¯ç¯å¢ƒ
            await environment.destroy()
            
            # ä»ç®¡ç†å™¨ä¸­ç§»é™¤
            del self.environments[env_id]
            
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to cleanup environment {env_id}: {e}")
            return False
    
    async def list_environments(self, 
                              env_type: Optional[EnvironmentType] = None) -> List[Dict[str, Any]]:
        """åˆ—å‡ºç¯å¢ƒ"""
        
        result = []
        
        for env_id, env_info in self.environments.items():
            if env_type is None or env_info["type"] == env_type:
                status = await env_info["instance"].get_status()
                
                result.append({
                    "environment_id": env_id,
                    "type": env_info["type"].value,
                    "status": status["status"],
                    "created_at": env_info["created_at"].isoformat(),
                    "config": env_info["config"]
                })
        
        return result
```

## æœ¬èŠ‚æ€»ç»“

æœ¬èŠ‚æ·±å…¥ä»‹ç»äº†æ‰§è¡Œç¯å¢ƒç®¡ç†çš„æ¶æ„è®¾è®¡ï¼š

### ğŸ¯ æ ¸å¿ƒè®¾è®¡ç‰¹ç‚¹
1. **å¤šç¯å¢ƒæ”¯æŒ**ï¼šå®¹å™¨ã€è™šæ‹Ÿæœºã€æ²™ç®±ã€Serverlessç­‰å¤šç§ç¯å¢ƒç±»å‹
2. **æ™ºèƒ½é€‰æ‹©**ï¼šåŸºäºéœ€æ±‚ç‰¹å¾çš„ç¯å¢ƒç±»å‹æ™ºèƒ½é€‰æ‹©ç®—æ³•
3. **ç”Ÿå‘½å‘¨æœŸç®¡ç†**ï¼šä»åˆ›å»ºåˆ°é”€æ¯çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†
4. **ç»Ÿä¸€æ¥å£**ï¼šæŠ½è±¡åŒ–çš„ç¯å¢ƒç®¡ç†æ¥å£ï¼Œå±è”½åº•å±‚å·®å¼‚

### ğŸ”§ å…³é”®æŠ€æœ¯å®ç°
- å“åº”å¼ç¯å¢ƒåˆ†é…ï¼šå“åº”å·¥å…·æ‰©å±•è¿è¡Œå±‚çš„ç¯å¢ƒç”³è¯·
- Dockerå®¹å™¨çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†
- Kubernetesé›†ç¾¤çš„æ™ºèƒ½ç¼–æ’å’Œè°ƒåº¦  
- å®‰å…¨æ²™ç®±çš„å¤šå±‚æ¬¡éš”ç¦»æœºåˆ¶
- ç»Ÿä¸€ç¯å¢ƒç®¡ç†çš„æŠ½è±¡æ¥å£è®¾è®¡

### ğŸš€ åˆ›æ–°ä»·å€¼
- **æ™ºèƒ½åŒ–**ï¼šåŸºäºéœ€æ±‚ç‰¹å¾çš„è‡ªåŠ¨åŒ–ç¯å¢ƒé€‰æ‹©
- **æ ‡å‡†åŒ–**ï¼šç»Ÿä¸€çš„ç¯å¢ƒç®¡ç†æ¥å£å’Œæ“ä½œæ–¹å¼
- **å®‰å…¨æ€§**ï¼šå¤šå±‚æ¬¡çš„å®‰å…¨éš”ç¦»å’Œè®¿é—®æ§åˆ¶
- **é«˜æ•ˆæ€§**ï¼šä¼˜åŒ–çš„èµ„æºåˆ†é…å’Œç¯å¢ƒå¤ç”¨æœºåˆ¶

---

**ä¸‹ä¸€æ­¥å­¦ä¹ **ï¼šæŒæ¡äº†æ‰§è¡Œç¯å¢ƒç®¡ç†åï¼Œæˆ‘ä»¬å°†åœ¨4.4.3èŠ‚å­¦ä¹ æ™ºèƒ½èµ„æºè°ƒåº¦ä¸ç®¡ç†ï¼Œäº†è§£å¦‚ä½•å®ç°AIåº”ç”¨çš„æ™ºèƒ½åŒ–èµ„æºåˆ†é…å’ŒåŠ¨æ€ä¼¸ç¼©ã€‚

> **ğŸ’¡ è®¾è®¡è¦ç‚¹**ï¼šæ‰§è¡Œç¯å¢ƒç®¡ç†çš„å…³é”®åœ¨äºå¹³è¡¡å®‰å…¨æ€§ã€æ€§èƒ½å’Œæˆæœ¬ï¼Œæ ¹æ®ä¸åŒå·¥å…·çš„ç‰¹ç‚¹é€‰æ‹©æœ€é€‚åˆçš„ç¯å¢ƒç±»å‹ï¼Œå¹¶æä¾›ç»Ÿä¸€çš„ç®¡ç†æ¥å£ã€‚
