# 4.4.5 æ™ºèƒ½ç¯å¢ƒå±‚çš„å·¥ç¨‹åŒ–å®è·µ

> "ç†è®ºæŒ‡å¯¼å®è·µï¼Œå®è·µæ£€éªŒç†è®ºã€‚æ™ºèƒ½ç¯å¢ƒå±‚çš„å·¥ç¨‹åŒ–å®è·µï¼Œæ˜¯å°†è®¾è®¡ç†å¿µè½¬åŒ–ä¸ºå¯è¿è¡Œã€å¯æ‰©å±•ã€å¯ç»´æŠ¤ç³»ç»Ÿçš„å…³é”®æ¡¥æ¢ã€‚"

## ğŸ¯ æœ¬èŠ‚å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬èŠ‚å­¦ä¹ åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- âœ… æŒæ¡åŸºç¡€è®¾æ–½å³ä»£ç ï¼ˆIaCï¼‰çš„è®¾è®¡å’Œå®ç°
- âœ… å®ç°å®¹å™¨ç¼–æ’å’Œäº‘åŸç”Ÿéƒ¨ç½²ç­–ç•¥
- âœ… æ„å»ºè‡ªåŠ¨åŒ–é…ç½®ç®¡ç†å’Œæ•…éšœæ¢å¤æœºåˆ¶
- âœ… å»ºç«‹æŒç»­é›†æˆéƒ¨ç½²çš„å®Œæ•´æµæ°´çº¿

## åŸºç¡€è®¾æ–½å³ä»£ç ï¼ˆIaCï¼‰

### Terraformæ™ºèƒ½ç¯å¢ƒå®šä¹‰

å°†æ™ºèƒ½ç¯å¢ƒå±‚çš„åŸºç¡€è®¾æ–½ç”¨ä»£ç çš„æ–¹å¼å®šä¹‰å’Œç®¡ç†ï¼š

```hcl
# æ™ºèƒ½ç¯å¢ƒå±‚ä¸»é…ç½®
# file: infrastructure/main.tf

terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

# æ™ºèƒ½ç¯å¢ƒå±‚VPCé…ç½®
resource "aws_vpc" "intelligent_environment" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name        = "intelligent-environment-vpc"
    Environment = var.environment
    Purpose     = "agi-application-infrastructure"
  }
}

# å¤šå¯ç”¨åŒºå­ç½‘é…ç½®
resource "aws_subnet" "environment_subnets" {
  count = length(var.availability_zones)
  
  vpc_id                  = aws_vpc.intelligent_environment.id
  cidr_block              = cidrsubnet(var.vpc_cidr, 8, count.index + 1)
  availability_zone       = var.availability_zones[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = "intelligent-environment-subnet-${count.index + 1}"
    Type = "public"
    "kubernetes.io/cluster/${var.cluster_name}" = "shared"
  }
}

# EKSé›†ç¾¤é…ç½®
resource "aws_eks_cluster" "intelligent_environment" {
  name     = var.cluster_name
  role_arn = aws_iam_role.eks_cluster_role.arn
  version  = var.kubernetes_version
  
  vpc_config {
    subnet_ids              = aws_subnet.environment_subnets[*].id
    endpoint_private_access = true
    endpoint_public_access  = true
    public_access_cidrs     = var.allowed_cidrs
  }
  
  enabled_cluster_log_types = [
    "api", "audit", "authenticator", "controllerManager", "scheduler"
  ]
  
  depends_on = [
    aws_iam_role_policy_attachment.eks_cluster_policy,
    aws_iam_role_policy_attachment.eks_vpc_resource_controller,
  ]
  
  tags = {
    Environment = var.environment
    Purpose     = "agi-intelligent-environment"
  }
}

# æ™ºèƒ½ç¯å¢ƒèŠ‚ç‚¹ç»„é…ç½®
resource "aws_eks_node_group" "environment_nodes" {
  cluster_name    = aws_eks_cluster.intelligent_environment.name
  node_group_name = "intelligent-environment-nodes"
  node_role_arn   = aws_iam_role.eks_node_group_role.arn
  subnet_ids      = aws_subnet.environment_subnets[*].id
  
  scaling_config {
    desired_size = var.node_desired_size
    max_size     = var.node_max_size
    min_size     = var.node_min_size
  }
  
  update_config {
    max_unavailable_percentage = 25
  }
  
  instance_types = var.node_instance_types
  capacity_type  = "SPOT"  # ä½¿ç”¨Spotå®ä¾‹é™ä½æˆæœ¬
  
  # æ™ºèƒ½ç¯å¢ƒä¸“ç”¨æ ‡ç­¾
  labels = {
    "node-type"           = "intelligent-environment"
    "workload-isolation" = "enabled"
    "auto-scaling"       = "enabled"
  }
  
  # æ±¡ç‚¹é…ç½®ï¼Œä¸“ç”¨äºæ™ºèƒ½ç¯å¢ƒå·¥ä½œè´Ÿè½½
  taint {
    key    = "intelligent-environment"
    value  = "dedicated"
    effect = "NO_SCHEDULE"
  }
  
  depends_on = [
    aws_iam_role_policy_attachment.eks_worker_node_policy,
    aws_iam_role_policy_attachment.eks_cni_policy,
    aws_iam_role_policy_attachment.eks_container_registry_policy,
  ]
}

# GPUèŠ‚ç‚¹ç»„ï¼ˆç”¨äºAIæ¨ç†å·¥ä½œè´Ÿè½½ï¼‰
resource "aws_eks_node_group" "gpu_nodes" {
  count = var.enable_gpu_nodes ? 1 : 0
  
  cluster_name    = aws_eks_cluster.intelligent_environment.name
  node_group_name = "gpu-inference-nodes"
  node_role_arn   = aws_iam_role.eks_node_group_role.arn
  subnet_ids      = aws_subnet.environment_subnets[*].id
  
  scaling_config {
    desired_size = var.gpu_node_desired_size
    max_size     = var.gpu_node_max_size
    min_size     = 0
  }
  
  instance_types = ["p3.2xlarge", "g4dn.xlarge"]  # GPUå®ä¾‹ç±»å‹
  
  labels = {
    "node-type"        = "gpu-inference"
    "accelerator"      = "nvidia-tesla"
    "workload-type"    = "ml-inference"
  }
  
  taint {
    key    = "nvidia.com/gpu"
    value  = "present"
    effect = "NO_SCHEDULE"
  }
}
```

### å˜é‡å’Œé…ç½®ç®¡ç†

```hcl
# file: infrastructure/variables.tf

variable "environment" {
  description = "ç¯å¢ƒåç§°"
  type        = string
  default     = "development"
  
  validation {
    condition     = contains(["development", "staging", "production"], var.environment)
    error_message = "ç¯å¢ƒå¿…é¡»æ˜¯developmentã€stagingæˆ–productionä¹‹ä¸€ã€‚"
  }
}

variable "vpc_cidr" {
  description = "VPC CIDRå—"
  type        = string
  default     = "10.0.0.0/16"
}

variable "availability_zones" {
  description = "å¯ç”¨åŒºåˆ—è¡¨"
  type        = list(string)
  default     = ["us-west-2a", "us-west-2b", "us-west-2c"]
}

variable "cluster_name" {
  description = "EKSé›†ç¾¤åç§°"
  type        = string
  default     = "intelligent-environment-cluster"
}

variable "kubernetes_version" {
  description = "Kubernetesç‰ˆæœ¬"
  type        = string
  default     = "1.28"
}

variable "node_instance_types" {
  description = "èŠ‚ç‚¹å®ä¾‹ç±»å‹"
  type        = list(string)
  default     = ["t3.medium", "t3.large", "c5.large"]
}

variable "intelligent_environment_config" {
  description = "æ™ºèƒ½ç¯å¢ƒå±‚é…ç½®"
  type = object({
    resource_scheduler = object({
      enable_prediction     = bool
      scheduling_interval   = number
      optimization_strategy = string
    })
    security_policies = object({
      zero_trust_enabled    = bool
      isolation_level       = string
      audit_logging        = bool
    })
    monitoring = object({
      enable_detailed_metrics = bool
      log_retention_days      = number
      alerting_enabled        = bool
    })
  })
  
  default = {
    resource_scheduler = {
      enable_prediction     = true
      scheduling_interval   = 30
      optimization_strategy = "multi-objective"
    }
    security_policies = {
      zero_trust_enabled = true
      isolation_level    = "strict"
      audit_logging     = true
    }
    monitoring = {
      enable_detailed_metrics = true
      log_retention_days      = 30
      alerting_enabled        = true
    }
  }
}
```

### æ™ºèƒ½ç¯å¢ƒå±‚åº”ç”¨å®šä¹‰

```yaml
# file: kubernetes/intelligent-environment/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: intelligent-environment
  labels:
    name: intelligent-environment
    purpose: agi-application-infrastructure
  annotations:
    scheduler.alpha.kubernetes.io/preferred-zone: multi-zone
    security-policy.kubernetes.io/isolation-level: strict

---
# èµ„æºè°ƒåº¦å™¨éƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resource-scheduler
  namespace: intelligent-environment
  labels:
    component: resource-scheduler
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      component: resource-scheduler
  template:
    metadata:
      labels:
        component: resource-scheduler
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: resource-scheduler
      tolerations:
      - key: intelligent-environment
        operator: Equal
        value: dedicated
        effect: NoSchedule
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: component
                  operator: In
                  values: ["resource-scheduler"]
              topologyKey: kubernetes.io/hostname
      containers:
      - name: scheduler
        image: intelligent-environment/resource-scheduler:v1.0.0
        ports:
        - containerPort: 8080
          name: http-metrics
        - containerPort: 9090
          name: grpc-api
        env:
        - name: ENVIRONMENT
          value: "{{ .Values.environment }}"
        - name: LOG_LEVEL
          value: "INFO"
        - name: SCHEDULER_INTERVAL
          value: "30s"
        - name: PREDICTION_ENABLED
          value: "true"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 3
        volumeMounts:
        - name: config-volume
          mountPath: /etc/scheduler
          readOnly: true
        - name: tls-certs
          mountPath: /etc/tls
          readOnly: true
      volumes:
      - name: config-volume
        configMap:
          name: scheduler-config
      - name: tls-certs
        secret:
          secretName: scheduler-tls

---
# ç¯å¢ƒç®¡ç†å™¨éƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: environment-manager
  namespace: intelligent-environment
spec:
  replicas: 2
  selector:
    matchLabels:
      component: environment-manager
  template:
    metadata:
      labels:
        component: environment-manager
        version: v1.0.0
    spec:
      serviceAccountName: environment-manager
      containers:
      - name: manager
        image: intelligent-environment/environment-manager:v1.0.0
        ports:
        - containerPort: 8081
          name: http-api
        env:
        - name: ISOLATION_LEVEL
          value: "strict"
        - name: SECURITY_POLICIES_ENABLED
          value: "true"
        resources:
          requests:
            cpu: 200m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
          readOnlyRootFilesystem: true
```

## å®¹å™¨ç¼–æ’å®è·µ

### Helm Chartæ™ºèƒ½ç¯å¢ƒéƒ¨ç½²

```yaml
# file: helm-charts/intelligent-environment/Chart.yaml
apiVersion: v2
name: intelligent-environment
description: æ™ºèƒ½ç¯å¢ƒå±‚ Helm Chart
type: application
version: 1.0.0
appVersion: "1.0.0"
keywords:
  - agi
  - intelligent-environment
  - resource-scheduling
  - security
home: https://github.com/joyagent/intelligent-environment
sources:
  - https://github.com/joyagent/intelligent-environment
maintainers:
  - name: AI Team
    email: agi-team@example.com

dependencies:
  - name: prometheus
    version: "15.x"
    repository: "https://prometheus-community.github.io/helm-charts"
    condition: monitoring.prometheus.enabled
  - name: grafana
    version: "6.x"
    repository: "https://grafana.github.io/helm-charts"
    condition: monitoring.grafana.enabled
  - name: cert-manager
    version: "v1.13.x"
    repository: "https://charts.jetstack.io"
    condition: security.certManager.enabled
```

```yaml
# file: helm-charts/intelligent-environment/values.yaml
# é»˜è®¤é…ç½®å€¼

global:
  imageRegistry: ""
  imagePullSecrets: []
  storageClass: "gp2"

environment: development
replicaCount: 3

image:
  repository: intelligent-environment
  pullPolicy: IfNotPresent
  tag: "v1.0.0"

service:
  type: ClusterIP
  ports:
    http: 8080
    grpc: 9090
    metrics: 8081

ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: intelligent-env.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: intelligent-environment-tls
      hosts:
        - intelligent-env.example.com

# èµ„æºè°ƒåº¦å™¨é…ç½®
resourceScheduler:
  enabled: true
  config:
    schedulingInterval: "30s"
    predictionEnabled: true
    optimizationStrategy: "multi-objective"
    objectives:
      resourceUtilization: 0.3
      responseTime: 0.25
      fairness: 0.2
      energyEfficiency: 0.15
      costOptimization: 0.1
  
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 4Gi

# ç¯å¢ƒç®¡ç†å™¨é…ç½®
environmentManager:
  enabled: true
  isolationLevel: "strict"
  securityPolicies:
    zeroTrustEnabled: true
    auditLogging: true
  
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi

# å®‰å…¨æ§åˆ¶é…ç½®
security:
  podSecurityPolicy:
    enabled: true
  networkPolicies:
    enabled: true
  certManager:
    enabled: true
    issuer: "letsencrypt-prod"
  
  rbac:
    create: true
    serviceAccountName: intelligent-environment

# ç›‘æ§é…ç½®
monitoring:
  prometheus:
    enabled: true
    serviceMonitor:
      enabled: true
      interval: 30s
  grafana:
    enabled: true
    dashboards:
      enabled: true
  alerts:
    enabled: true
    rules:
      - name: ResourceScheduler
        rules:
          - alert: HighSchedulingLatency
            expr: scheduler_latency_seconds > 5
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: "èµ„æºè°ƒåº¦å»¶è¿Ÿè¿‡é«˜"
              description: "èµ„æºè°ƒåº¦å»¶è¿Ÿè¶…è¿‡5ç§’ï¼Œå½±å“ç”¨æˆ·ä½“éªŒ"

# æŒä¹…åŒ–å­˜å‚¨é…ç½®  
persistence:
  enabled: true
  accessMode: ReadWriteOnce
  size: 50Gi
  annotations: {}

# è‡ªåŠ¨æ‰©ç¼©å®¹é…ç½®
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60

# èŠ‚ç‚¹äº²å’Œæ€§é…ç½®
nodeAffinity:
  preferredDuringSchedulingIgnoredDuringExecution:
  - weight: 100
    preference:
      matchExpressions:
      - key: node-type
        operator: In
        values: ["intelligent-environment"]

# å®¹å¿åº¦é…ç½®
tolerations:
- key: intelligent-environment
  operator: Equal
  value: dedicated
  effect: NoSchedule
```

### IstioæœåŠ¡ç½‘æ ¼é…ç½®

```yaml
# file: service-mesh/intelligent-environment-mesh.yaml
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: intelligent-environment-mesh
  namespace: istio-system
spec:
  values:
    pilot:
      env:
        EXTERNAL_ISTIOD: false
    global:
      meshID: intelligent-environment
      multiCluster:
        clusterName: intelligent-environment-cluster
      network: network1
  components:
    pilot:
      k8s:
        resources:
          requests:
            cpu: 500m
            memory: 2048Mi
          limits:
            cpu: 1000m
            memory: 4096Mi
        hpaSpec:
          minReplicas: 2
          maxReplicas: 5
          scaleTargetRef:
            apiVersion: apps/v1
            kind: Deployment
            name: istiod
          metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 80

---
# æ™ºèƒ½ç¯å¢ƒå‘½åç©ºé—´æœåŠ¡ç½‘æ ¼é…ç½®
apiVersion: v1
kind: Namespace
metadata:
  name: intelligent-environment
  labels:
    istio-injection: enabled
    security-policy: strict
    network-policy: enabled

---
# æµé‡ç®¡ç†ç­–ç•¥
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: intelligent-environment-destination
  namespace: intelligent-environment
spec:
  host: "*.intelligent-environment.svc.cluster.local"
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL
    loadBalancer:
      simple: LEAST_CONN
    connectionPool:
      tcp:
        maxConnections: 100
        connectTimeout: 30s
      http:
        http1MaxPendingRequests: 100
        maxRequestsPerConnection: 10
        maxRetries: 3
    circuitBreaker:
      consecutiveErrors: 3
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50

---
# å®‰å…¨ç­–ç•¥
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: intelligent-environment
spec:
  mtls:
    mode: STRICT

---
# æˆæƒç­–ç•¥
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: intelligent-environment-authz
  namespace: intelligent-environment
spec:
  rules:
  - from:
    - source:
        namespaces: ["intelligent-environment"]
    to:
    - operation:
        methods: ["GET", "POST", "PUT", "DELETE"]
    when:
    - key: request.headers[authorization]
      values: ["Bearer *"]
```

## é…ç½®ç®¡ç†è‡ªåŠ¨åŒ–

### ConfigMapå’ŒSecretç®¡ç†

```python
"""
æ™ºèƒ½ç¯å¢ƒé…ç½®ç®¡ç†è‡ªåŠ¨åŒ–è„šæœ¬
file: scripts/config-management.py
"""

import yaml
import json
import base64
import kubernetes
from kubernetes import client, config
from typing import Dict, List, Any, Optional
import asyncio
import logging
from pathlib import Path

class IntelligentEnvironmentConfigManager:
    """æ™ºèƒ½ç¯å¢ƒé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, kubeconfig_path: Optional[str] = None):
        if kubeconfig_path:
            config.load_kube_config(config_file=kubeconfig_path)
        else:
            config.load_incluster_config()
        
        self.v1 = client.CoreV1Api()
        self.namespace = "intelligent-environment"
        self.logger = logging.getLogger(__name__)
        
    async def deploy_configurations(self, config_dir: str) -> Dict[str, Any]:
        """éƒ¨ç½²é…ç½®æ–‡ä»¶"""
        
        config_path = Path(config_dir)
        results = {
            "configmaps": [],
            "secrets": [],
            "errors": []
        }
        
        # å¤„ç†ConfigMapæ–‡ä»¶
        configmap_files = list(config_path.glob("configmaps/*.yaml"))
        for file_path in configmap_files:
            try:
                result = await self._deploy_configmap(file_path)
                results["configmaps"].append(result)
            except Exception as e:
                error_info = {
                    "file": str(file_path),
                    "error": str(e),
                    "type": "configmap"
                }
                results["errors"].append(error_info)
        
        # å¤„ç†Secretæ–‡ä»¶
        secret_files = list(config_path.glob("secrets/*.yaml"))
        for file_path in secret_files:
            try:
                result = await self._deploy_secret(file_path)
                results["secrets"].append(result)
            except Exception as e:
                error_info = {
                    "file": str(file_path),
                    "error": str(e),
                    "type": "secret"
                }
                results["errors"].append(error_info)
        
        return results
    
    async def _deploy_configmap(self, file_path: Path) -> Dict[str, Any]:
        """éƒ¨ç½²ConfigMap"""
        
        with open(file_path, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        
        configmap_name = config_data["metadata"]["name"]
        
        # æ£€æŸ¥ConfigMapæ˜¯å¦å­˜åœ¨
        try:
            existing_cm = self.v1.read_namespaced_config_map(
                name=configmap_name, 
                namespace=self.namespace
            )
            
            # æ›´æ–°ç°æœ‰ConfigMap
            existing_cm.data = config_data.get("data", {})
            updated_cm = self.v1.replace_namespaced_config_map(
                name=configmap_name,
                namespace=self.namespace,
                body=existing_cm
            )
            
            self.logger.info(f"Updated ConfigMap: {configmap_name}")
            return {
                "name": configmap_name,
                "action": "updated",
                "resource_version": updated_cm.metadata.resource_version
            }
            
        except client.ApiException as e:
            if e.status == 404:
                # åˆ›å»ºæ–°ConfigMap
                configmap = client.V1ConfigMap(
                    api_version="v1",
                    kind="ConfigMap",
                    metadata=client.V1ObjectMeta(
                        name=configmap_name,
                        namespace=self.namespace,
                        labels=config_data["metadata"].get("labels", {}),
                        annotations=config_data["metadata"].get("annotations", {})
                    ),
                    data=config_data.get("data", {})
                )
                
                created_cm = self.v1.create_namespaced_config_map(
                    namespace=self.namespace,
                    body=configmap
                )
                
                self.logger.info(f"Created ConfigMap: {configmap_name}")
                return {
                    "name": configmap_name,
                    "action": "created",
                    "resource_version": created_cm.metadata.resource_version
                }
            else:
                raise
    
    async def _deploy_secret(self, file_path: Path) -> Dict[str, Any]:
        """éƒ¨ç½²Secret"""
        
        with open(file_path, 'r', encoding='utf-8') as f:
            secret_data = yaml.safe_load(f)
        
        secret_name = secret_data["metadata"]["name"]
        
        # å¤„ç†Secretæ•°æ®ç¼–ç 
        encoded_data = {}
        raw_data = secret_data.get("data", {})
        
        for key, value in raw_data.items():
            if isinstance(value, str):
                # å¦‚æœå€¼è¿˜æœªç¼–ç ï¼Œè¿›è¡Œbase64ç¼–ç 
                if not self._is_base64(value):
                    encoded_data[key] = base64.b64encode(value.encode()).decode()
                else:
                    encoded_data[key] = value
        
        try:
            existing_secret = self.v1.read_namespaced_secret(
                name=secret_name,
                namespace=self.namespace
            )
            
            # æ›´æ–°ç°æœ‰Secret
            existing_secret.data = encoded_data
            updated_secret = self.v1.replace_namespaced_secret(
                name=secret_name,
                namespace=self.namespace,
                body=existing_secret
            )
            
            self.logger.info(f"Updated Secret: {secret_name}")
            return {
                "name": secret_name,
                "action": "updated",
                "resource_version": updated_secret.metadata.resource_version
            }
            
        except client.ApiException as e:
            if e.status == 404:
                # åˆ›å»ºæ–°Secret
                secret = client.V1Secret(
                    api_version="v1",
                    kind="Secret",
                    metadata=client.V1ObjectMeta(
                        name=secret_name,
                        namespace=self.namespace,
                        labels=secret_data["metadata"].get("labels", {}),
                        annotations=secret_data["metadata"].get("annotations", {})
                    ),
                    type=secret_data.get("type", "Opaque"),
                    data=encoded_data
                )
                
                created_secret = self.v1.create_namespaced_secret(
                    namespace=self.namespace,
                    body=secret
                )
                
                self.logger.info(f"Created Secret: {secret_name}")
                return {
                    "name": secret_name,
                    "action": "created",
                    "resource_version": created_secret.metadata.resource_version
                }
            else:
                raise
    
    def _is_base64(self, s: str) -> bool:
        """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä¸ºbase64ç¼–ç """
        try:
            return base64.b64encode(base64.b64decode(s)).decode() == s
        except:
            return False
    
    async def validate_configurations(self) -> Dict[str, Any]:
        """éªŒè¯é…ç½®å®Œæ•´æ€§"""
        
        validation_results = {
            "configmaps": {"valid": [], "invalid": []},
            "secrets": {"valid": [], "invalid": []},
            "summary": {"total": 0, "valid": 0, "invalid": 0}
        }
        
        # éªŒè¯ConfigMaps
        configmaps = self.v1.list_namespaced_config_map(namespace=self.namespace)
        for cm in configmaps.items:
            validation_result = await self._validate_configmap(cm)
            if validation_result["valid"]:
                validation_results["configmaps"]["valid"].append(validation_result)
            else:
                validation_results["configmaps"]["invalid"].append(validation_result)
        
        # éªŒè¯Secrets
        secrets = self.v1.list_namespaced_secret(namespace=self.namespace)
        for secret in secrets.items:
            validation_result = await self._validate_secret(secret)
            if validation_result["valid"]:
                validation_results["secrets"]["valid"].append(validation_result)
            else:
                validation_results["secrets"]["invalid"].append(validation_result)
        
        # è®¡ç®—æ±‡æ€»ä¿¡æ¯
        total_valid = (len(validation_results["configmaps"]["valid"]) + 
                      len(validation_results["secrets"]["valid"]))
        total_invalid = (len(validation_results["configmaps"]["invalid"]) + 
                        len(validation_results["secrets"]["invalid"]))
        
        validation_results["summary"] = {
            "total": total_valid + total_invalid,
            "valid": total_valid,
            "invalid": total_invalid,
            "success_rate": total_valid / (total_valid + total_invalid) * 100 if (total_valid + total_invalid) > 0 else 100
        }
        
        return validation_results
    
    async def _validate_configmap(self, configmap) -> Dict[str, Any]:
        """éªŒè¯ConfigMap"""
        
        validation_result = {
            "name": configmap.metadata.name,
            "type": "ConfigMap",
            "valid": True,
            "issues": []
        }
        
        # æ£€æŸ¥å¿…éœ€çš„æ ‡ç­¾
        required_labels = ["app", "component", "version"]
        labels = configmap.metadata.labels or {}
        
        for label in required_labels:
            if label not in labels:
                validation_result["issues"].append(f"ç¼ºå°‘å¿…éœ€æ ‡ç­¾: {label}")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        data = configmap.data or {}
        if not data:
            validation_result["issues"].append("ConfigMapæ•°æ®ä¸ºç©º")
        
        # éªŒè¯é…ç½®æ–‡ä»¶æ ¼å¼
        for key, value in data.items():
            if key.endswith(('.yaml', '.yml')):
                try:
                    yaml.safe_load(value)
                except yaml.YAMLError as e:
                    validation_result["issues"].append(f"YAMLæ ¼å¼é”™è¯¯ in {key}: {str(e)}")
            elif key.endswith('.json'):
                try:
                    json.loads(value)
                except json.JSONDecodeError as e:
                    validation_result["issues"].append(f"JSONæ ¼å¼é”™è¯¯ in {key}: {str(e)}")
        
        validation_result["valid"] = len(validation_result["issues"]) == 0
        return validation_result

# é…ç½®æ–‡ä»¶ç¤ºä¾‹
intelligent_environment_configs = {
    "scheduler_config.yaml": """
apiVersion: v1
kind: ConfigMap
metadata:
  name: scheduler-config
  namespace: intelligent-environment
  labels:
    app: intelligent-environment
    component: resource-scheduler
    version: v1.0.0
data:
  scheduler.yaml: |
    scheduler:
      interval: 30s
      prediction:
        enabled: true
        window: 300s
        algorithm: "lstm"
      optimization:
        strategy: "multi-objective"
        objectives:
          resource_utilization: 0.3
          response_time: 0.25
          fairness: 0.2
          energy_efficiency: 0.15
          cost_optimization: 0.1
      policies:
        cpu_overcommit_ratio: 1.5
        memory_overcommit_ratio: 1.2
        gpu_sharing_enabled: true
    """,
    
    "environment_manager_config.yaml": """
apiVersion: v1
kind: ConfigMap
metadata:
  name: environment-manager-config
  namespace: intelligent-environment
  labels:
    app: intelligent-environment
    component: environment-manager
    version: v1.0.0
data:
  manager.yaml: |
    environment_manager:
      isolation:
        level: "strict"
        network_policies: true
        pod_security_policies: true
      security:
        zero_trust: true
        audit_logging: true
        threat_detection: true
      resources:
        default_limits:
          cpu: "1000m"
          memory: "2Gi"
        quota_enforcement: true
    """
}

## æ•…éšœæ¢å¤æœºåˆ¶

### è‡ªåŠ¨æ•…éšœæ£€æµ‹ä¸æ¢å¤

```python
"""
æ™ºèƒ½ç¯å¢ƒæ•…éšœæ£€æµ‹ä¸è‡ªåŠ¨æ¢å¤ç³»ç»Ÿ
file: services/fault-recovery.py
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
import json

class FaultSeverity(Enum):
    """æ•…éšœä¸¥é‡ç¨‹åº¦"""
    INFO = 1
    WARNING = 2
    ERROR = 3
    CRITICAL = 4
    EMERGENCY = 5

class RecoveryAction(Enum):
    """æ¢å¤åŠ¨ä½œç±»å‹"""
    RESTART_SERVICE = "restart_service"
    SCALE_OUT = "scale_out"
    FAILOVER = "failover"
    ROLLBACK = "rollback"
    ISOLATE_NODE = "isolate_node"
    ALERT_ADMIN = "alert_admin"

@dataclass
class Fault:
    """æ•…éšœä¿¡æ¯"""
    fault_id: str
    component: str
    description: str
    severity: FaultSeverity
    detected_at: datetime
    metrics: Dict[str, Any]
    affected_resources: List[str]
    
class FaultDetector:
    """æ•…éšœæ£€æµ‹å™¨"""
    
    def __init__(self):
        self.detection_rules = {}
        self.metrics_collector = MetricsCollector()
        self.threshold_manager = ThresholdManager()
        self.anomaly_detector = AnomalyDetector()
        
    async def register_detection_rule(self, 
                                    rule_name: str,
                                    rule_config: Dict[str, Any]):
        """æ³¨å†Œæ•…éšœæ£€æµ‹è§„åˆ™"""
        
        self.detection_rules[rule_name] = {
            "config": rule_config,
            "enabled": True,
            "last_check": None,
            "detection_count": 0
        }
        
        logging.info(f"æ³¨å†Œæ•…éšœæ£€æµ‹è§„åˆ™: {rule_name}")
    
    async def detect_faults(self) -> List[Fault]:
        """æ‰§è¡Œæ•…éšœæ£€æµ‹"""
        
        detected_faults = []
        current_metrics = await self.metrics_collector.collect_all_metrics()
        
        for rule_name, rule_info in self.detection_rules.items():
            if not rule_info["enabled"]:
                continue
            
            rule_config = rule_info["config"]
            
            try:
                # åŸºäºè§„åˆ™çš„æ•…éšœæ£€æµ‹
                rule_faults = await self._apply_detection_rule(
                    rule_name, rule_config, current_metrics
                )
                detected_faults.extend(rule_faults)
                
                # åŸºäºå¼‚å¸¸æ£€æµ‹çš„æ•…éšœå‘ç°
                anomaly_faults = await self._detect_anomalies(
                    rule_name, rule_config, current_metrics
                )
                detected_faults.extend(anomaly_faults)
                
                # æ›´æ–°è§„åˆ™çŠ¶æ€
                rule_info["last_check"] = datetime.now()
                rule_info["detection_count"] += len(rule_faults) + len(anomaly_faults)
                
            except Exception as e:
                logging.error(f"æ•…éšœæ£€æµ‹è§„åˆ™ {rule_name} æ‰§è¡Œå¤±è´¥: {str(e)}")
                continue
        
        return detected_faults
    
    async def _apply_detection_rule(self,
                                  rule_name: str,
                                  rule_config: Dict[str, Any],
                                  metrics: Dict[str, Any]) -> List[Fault]:
        """åº”ç”¨æ£€æµ‹è§„åˆ™"""
        
        faults = []
        rule_type = rule_config["type"]
        
        if rule_type == "threshold":
            faults = await self._threshold_detection(rule_name, rule_config, metrics)
        elif rule_type == "pattern":
            faults = await self._pattern_detection(rule_name, rule_config, metrics)
        elif rule_type == "correlation":
            faults = await self._correlation_detection(rule_name, rule_config, metrics)
        
        return faults
    
    async def _threshold_detection(self,
                                 rule_name: str,
                                 rule_config: Dict[str, Any],
                                 metrics: Dict[str, Any]) -> List[Fault]:
        """é˜ˆå€¼æ£€æµ‹"""
        
        faults = []
        metric_name = rule_config["metric"]
        threshold_config = rule_config["threshold"]
        
        if metric_name not in metrics:
            return faults
        
        metric_value = metrics[metric_name]["value"]
        threshold_value = threshold_config["value"]
        operator = threshold_config["operator"]
        
        fault_detected = False
        
        if operator == "greater_than" and metric_value > threshold_value:
            fault_detected = True
        elif operator == "less_than" and metric_value < threshold_value:
            fault_detected = True
        elif operator == "equals" and metric_value == threshold_value:
            fault_detected = True
        
        if fault_detected:
            fault = Fault(
                fault_id=f"{rule_name}_{datetime.now().timestamp()}",
                component=rule_config["component"],
                description=f"{metric_name} {operator} {threshold_value}, å½“å‰å€¼: {metric_value}",
                severity=FaultSeverity(rule_config.get("severity", 2)),
                detected_at=datetime.now(),
                metrics={metric_name: metric_value},
                affected_resources=rule_config.get("affected_resources", [])
            )
            faults.append(fault)
        
        return faults

class FaultRecoveryEngine:
    """æ•…éšœæ¢å¤å¼•æ“"""
    
    def __init__(self):
        self.recovery_strategies = {}
        self.execution_queue = asyncio.Queue()
        self.recovery_history = []
        self.kubernetes_client = KubernetesClient()
        
    async def register_recovery_strategy(self,
                                       strategy_name: str,
                                       strategy_config: Dict[str, Any]):
        """æ³¨å†Œæ¢å¤ç­–ç•¥"""
        
        self.recovery_strategies[strategy_name] = {
            "config": strategy_config,
            "enabled": True,
            "success_rate": 0.0,
            "execution_count": 0,
            "last_used": None
        }
        
        logging.info(f"æ³¨å†Œæ¢å¤ç­–ç•¥: {strategy_name}")
    
    async def recover_fault(self, fault: Fault) -> Dict[str, Any]:
        """æ‰§è¡Œæ•…éšœæ¢å¤"""
        
        # é€‰æ‹©æœ€ä½³æ¢å¤ç­–ç•¥
        strategy_name = await self._select_recovery_strategy(fault)
        
        if not strategy_name:
            return {
                "success": False,
                "error": "æœªæ‰¾åˆ°é€‚ç”¨çš„æ¢å¤ç­–ç•¥"
            }
        
        strategy_config = self.recovery_strategies[strategy_name]["config"]
        
        # æ‰§è¡Œæ¢å¤åŠ¨ä½œ
        recovery_result = await self._execute_recovery_actions(
            fault, strategy_config
        )
        
        # æ›´æ–°ç­–ç•¥ç»Ÿè®¡
        await self._update_strategy_stats(strategy_name, recovery_result["success"])
        
        # è®°å½•æ¢å¤å†å²
        recovery_record = {
            "fault_id": fault.fault_id,
            "strategy_name": strategy_name,
            "recovery_result": recovery_result,
            "timestamp": datetime.now()
        }
        self.recovery_history.append(recovery_record)
        
        return recovery_result
    
    async def _select_recovery_strategy(self, fault: Fault) -> Optional[str]:
        """é€‰æ‹©æ¢å¤ç­–ç•¥"""
        
        applicable_strategies = []
        
        for strategy_name, strategy_info in self.recovery_strategies.items():
            if not strategy_info["enabled"]:
                continue
            
            strategy_config = strategy_info["config"]
            
            # æ£€æŸ¥é€‚ç”¨æ¡ä»¶
            if await self._is_strategy_applicable(fault, strategy_config):
                applicable_strategies.append({
                    "name": strategy_name,
                    "priority": strategy_config.get("priority", 5),
                    "success_rate": strategy_info["success_rate"]
                })
        
        if not applicable_strategies:
            return None
        
        # æŒ‰ä¼˜å…ˆçº§å’ŒæˆåŠŸç‡æ’åº
        applicable_strategies.sort(
            key=lambda x: (x["priority"], x["success_rate"]),
            reverse=True
        )
        
        return applicable_strategies[0]["name"]
    
    async def _is_strategy_applicable(self,
                                    fault: Fault,
                                    strategy_config: Dict[str, Any]) -> bool:
        """æ£€æŸ¥ç­–ç•¥æ˜¯å¦é€‚ç”¨"""
        
        # æ£€æŸ¥æ•…éšœä¸¥é‡ç¨‹åº¦
        min_severity = strategy_config.get("min_severity", 1)
        if fault.severity.value < min_severity:
            return False
        
        # æ£€æŸ¥ç»„ä»¶åŒ¹é…
        target_components = strategy_config.get("target_components", [])
        if target_components and fault.component not in target_components:
            return False
        
        # æ£€æŸ¥æ•…éšœç±»å‹
        fault_types = strategy_config.get("fault_types", [])
        if fault_types and not any(ft in fault.description.lower() for ft in fault_types):
            return False
        
        return True
    
    async def _execute_recovery_actions(self,
                                      fault: Fault,
                                      strategy_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ¢å¤åŠ¨ä½œ"""
        
        actions = strategy_config["actions"]
        results = []
        
        for action_config in actions:
            action_type = RecoveryAction(action_config["type"])
            
            try:
                if action_type == RecoveryAction.RESTART_SERVICE:
                    result = await self._restart_service(action_config, fault)
                elif action_type == RecoveryAction.SCALE_OUT:
                    result = await self._scale_out_service(action_config, fault)
                elif action_type == RecoveryAction.FAILOVER:
                    result = await self._failover_service(action_config, fault)
                elif action_type == RecoveryAction.ROLLBACK:
                    result = await self._rollback_deployment(action_config, fault)
                elif action_type == RecoveryAction.ISOLATE_NODE:
                    result = await self._isolate_node(action_config, fault)
                else:
                    result = {"success": False, "error": f"æœªæ”¯æŒçš„æ¢å¤åŠ¨ä½œ: {action_type}"}
                
                results.append({
                    "action": action_type.value,
                    "result": result
                })
                
                # å¦‚æœåŠ¨ä½œå¤±è´¥ä¸”é…ç½®ä¸ºåœæ­¢æ‰§è¡Œï¼Œåˆ™é€€å‡º
                if not result["success"] and action_config.get("stop_on_failure", False):
                    break
                
            except Exception as e:
                error_result = {
                    "action": action_type.value,
                    "result": {"success": False, "error": str(e)}
                }
                results.append(error_result)
                
                if action_config.get("stop_on_failure", False):
                    break
        
        # è®¡ç®—æ•´ä½“æˆåŠŸç‡
        successful_actions = sum(1 for r in results if r["result"]["success"])
        success_rate = successful_actions / len(results) if results else 0
        
        return {
            "success": success_rate >= 0.5,  # 50%ä»¥ä¸ŠæˆåŠŸæ‰ç®—æˆåŠŸ
            "success_rate": success_rate,
            "actions": results,
            "execution_time": datetime.now()
        }
    
    async def _restart_service(self,
                             action_config: Dict[str, Any],
                             fault: Fault) -> Dict[str, Any]:
        """é‡å¯æœåŠ¡"""
        
        service_name = action_config["service_name"]
        namespace = action_config.get("namespace", "intelligent-environment")
        
        try:
            # è·å–éƒ¨ç½²
            deployment = await self.kubernetes_client.get_deployment(service_name, namespace)
            
            if not deployment:
                return {"success": False, "error": f"éƒ¨ç½² {service_name} ä¸å­˜åœ¨"}
            
            # æ‰§è¡Œæ»šåŠ¨é‡å¯
            restart_result = await self.kubernetes_client.restart_deployment(
                service_name, namespace
            )
            
            # ç­‰å¾…é‡å¯å®Œæˆ
            await self.kubernetes_client.wait_for_deployment_ready(
                service_name, namespace, timeout=300
            )
            
            return {
                "success": True,
                "message": f"æœåŠ¡ {service_name} é‡å¯æˆåŠŸ",
                "details": restart_result
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"é‡å¯æœåŠ¡å¤±è´¥: {str(e)}"
            }
    
    async def _scale_out_service(self,
                               action_config: Dict[str, Any],
                               fault: Fault) -> Dict[str, Any]:
        """æ‰©å®¹æœåŠ¡"""
        
        service_name = action_config["service_name"]
        namespace = action_config.get("namespace", "intelligent-environment")
        scale_factor = action_config.get("scale_factor", 2)
        max_replicas = action_config.get("max_replicas", 10)
        
        try:
            # è·å–å½“å‰å‰¯æœ¬æ•°
            current_replicas = await self.kubernetes_client.get_deployment_replicas(
                service_name, namespace
            )
            
            # è®¡ç®—æ–°çš„å‰¯æœ¬æ•°
            new_replicas = min(current_replicas * scale_factor, max_replicas)
            
            if new_replicas == current_replicas:
                return {
                    "success": True,
                    "message": f"æœåŠ¡ {service_name} å·²è¾¾åˆ°æœ€å¤§å‰¯æœ¬æ•°",
                    "current_replicas": current_replicas
                }
            
            # æ‰§è¡Œæ‰©å®¹
            scale_result = await self.kubernetes_client.scale_deployment(
                service_name, namespace, new_replicas
            )
            
            # ç­‰å¾…æ‰©å®¹å®Œæˆ
            await self.kubernetes_client.wait_for_deployment_ready(
                service_name, namespace, timeout=300
            )
            
            return {
                "success": True,
                "message": f"æœåŠ¡ {service_name} æ‰©å®¹æˆåŠŸ",
                "old_replicas": current_replicas,
                "new_replicas": new_replicas,
                "details": scale_result
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"æœåŠ¡æ‰©å®¹å¤±è´¥: {str(e)}"
            }

# æ•…éšœæ¢å¤ç­–ç•¥é…ç½®ç¤ºä¾‹
fault_recovery_strategies = {
    "resource_scheduler_recovery": {
        "config": {
            "priority": 9,
            "min_severity": 3,
            "target_components": ["resource-scheduler"],
            "fault_types": ["high_latency", "service_unavailable"],
            "actions": [
                {
                    "type": "restart_service",
                    "service_name": "resource-scheduler",
                    "namespace": "intelligent-environment",
                    "stop_on_failure": False
                },
                {
                    "type": "scale_out",
                    "service_name": "resource-scheduler", 
                    "namespace": "intelligent-environment",
                    "scale_factor": 2,
                    "max_replicas": 5,
                    "stop_on_failure": True
                }
            ]
        }
    },
    
    "environment_manager_recovery": {
        "config": {
            "priority": 8,
            "min_severity": 3,
            "target_components": ["environment-manager"],
            "fault_types": ["memory_leak", "cpu_spike", "deadlock"],
            "actions": [
                {
                    "type": "restart_service",
                    "service_name": "environment-manager",
                    "namespace": "intelligent-environment",
                    "stop_on_failure": False
                }
            ]
        }
    }
}
```

## æŒç»­é›†æˆéƒ¨ç½²

### GitLab CI/CDæµæ°´çº¿

```yaml
# file: .gitlab-ci.yml
stages:
  - validate
  - build
  - test
  - security-scan
  - deploy-dev
  - integration-test
  - deploy-staging
  - performance-test
  - deploy-production
  - post-deployment

variables:
  DOCKER_REGISTRY: "registry.example.com"
  KUBERNETES_NAMESPACE: "intelligent-environment"
  HELM_CHART_PATH: "helm-charts/intelligent-environment"

# éªŒè¯é˜¶æ®µ
validate-terraform:
  stage: validate
  image: hashicorp/terraform:latest
  script:
    - cd infrastructure
    - terraform fmt -check
    - terraform validate
    - terraform plan -detailed-exitcode
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main"'

validate-kubernetes:
  stage: validate
  image: alpine/k8s:latest
  script:
    - kubectl --dry-run=client apply -f kubernetes/
    - helm template $HELM_CHART_PATH --validate
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main"'

lint-python:
  stage: validate
  image: python:3.11
  before_script:
    - pip install flake8 black pylint
  script:
    - flake8 scripts/ services/
    - black --check scripts/ services/
    - pylint scripts/ services/
  rules:
    - changes:
        - "**/*.py"

# æ„å»ºé˜¶æ®µ
build-images:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - |
      for component in resource-scheduler environment-manager security-controller; do
        echo "Building $component..."
        docker build -t $DOCKER_REGISTRY/intelligent-environment/$component:$CI_COMMIT_SHA \
                     -t $DOCKER_REGISTRY/intelligent-environment/$component:latest \
                     -f docker/$component/Dockerfile .
        docker push $DOCKER_REGISTRY/intelligent-environment/$component:$CI_COMMIT_SHA
        docker push $DOCKER_REGISTRY/intelligent-environment/$component:latest
      done
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'

# æµ‹è¯•é˜¶æ®µ
unit-tests:
  stage: test
  image: python:3.11
  before_script:
    - pip install -r requirements-test.txt
  script:
    - python -m pytest tests/unit/ --cov=services --cov-report=xml
    - python -m pytest tests/integration/ --cov-append
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    expire_in: 1 week
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# å®‰å…¨æ‰«æ
security-scan:
  stage: security-scan
  image: securecodewarrior/docker-security-scan:latest
  script:
    - |
      for component in resource-scheduler environment-manager security-controller; do
        docker pull $DOCKER_REGISTRY/intelligent-environment/$component:$CI_COMMIT_SHA
        trivy image $DOCKER_REGISTRY/intelligent-environment/$component:$CI_COMMIT_SHA
      done
    - |
      # æ‰«æåŸºç¡€è®¾æ–½ä»£ç 
      checkov -f infrastructure/
    - |
      # æ‰«æKubernetesé…ç½®
      kube-score score kubernetes/**/*.yaml
  artifacts:
    reports:
      security: security-report.json
    expire_in: 1 week
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# å¼€å‘ç¯å¢ƒéƒ¨ç½²
deploy-dev:
  stage: deploy-dev
  image: alpine/k8s:latest
  environment:
    name: development
    url: https://dev.intelligent-env.example.com
  before_script:
    - kubectl config use-context development
  script:
    - |
      helm upgrade --install intelligent-environment $HELM_CHART_PATH \
        --namespace $KUBERNETES_NAMESPACE \
        --create-namespace \
        --set environment=development \
        --set image.tag=$CI_COMMIT_SHA \
        --set ingress.hosts[0].host=dev.intelligent-env.example.com \
        --wait --timeout=10m
  rules:
    - if: '$CI_COMMIT_BRANCH == "develop"'

# é›†æˆæµ‹è¯•
integration-tests:
  stage: integration-test
  image: postman/newman:latest
  dependencies:
    - deploy-dev
  script:
    - newman run tests/integration/api-tests.json \
        --environment tests/integration/dev-environment.json \
        --reporters cli,junit \
        --reporter-junit-export integration-test-results.xml
  artifacts:
    reports:
      junit: integration-test-results.xml
    expire_in: 1 week
  rules:
    - if: '$CI_COMMIT_BRANCH == "develop"'

# é¢„ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
deploy-staging:
  stage: deploy-staging
  image: alpine/k8s:latest
  environment:
    name: staging
    url: https://staging.intelligent-env.example.com
  before_script:
    - kubectl config use-context staging
  script:
    - |
      # ä½¿ç”¨è“ç»¿éƒ¨ç½²ç­–ç•¥
      helm upgrade --install intelligent-environment-blue $HELM_CHART_PATH \
        --namespace ${KUBERNETES_NAMESPACE}-blue \
        --create-namespace \
        --set environment=staging \
        --set image.tag=$CI_COMMIT_SHA \
        --set ingress.hosts[0].host=staging-blue.intelligent-env.example.com \
        --wait --timeout=15m
      
      # å¥åº·æ£€æŸ¥
      curl -f https://staging-blue.intelligent-env.example.com/health || exit 1
      
      # åˆ‡æ¢æµé‡
      kubectl patch service intelligent-environment-service \
        --namespace $KUBERNETES_NAMESPACE \
        --patch '{"spec":{"selector":{"version":"blue"}}}'
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# æ€§èƒ½æµ‹è¯•
performance-tests:
  stage: performance-test
  image: loadimpact/k6:latest
  dependencies:
    - deploy-staging
  script:
    - k6 run --out json=performance-results.json tests/performance/load-test.js
  artifacts:
    reports:
      performance: performance-results.json
    expire_in: 1 week
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
deploy-production:
  stage: deploy-production
  image: alpine/k8s:latest
  environment:
    name: production
    url: https://intelligent-env.example.com
  before_script:
    - kubectl config use-context production
  script:
    - |
      # é‡‘ä¸é›€éƒ¨ç½²ç­–ç•¥
      helm upgrade --install intelligent-environment $HELM_CHART_PATH \
        --namespace $KUBERNETES_NAMESPACE \
        --set environment=production \
        --set image.tag=$CI_COMMIT_SHA \
        --set autoscaling.enabled=true \
        --set autoscaling.minReplicas=5 \
        --set autoscaling.maxReplicas=20 \
        --set monitoring.enabled=true \
        --wait --timeout=20m
      
      # é€æ­¥å¢åŠ æ–°ç‰ˆæœ¬æµé‡
      kubectl patch deployment intelligent-environment \
        --patch '{"spec":{"strategy":{"rollingUpdate":{"maxSurge":"10%","maxUnavailable":"0%"}}}}'
  when: manual
  only:
    - main
  allow_failure: false

# éƒ¨ç½²åéªŒè¯
post-deployment-verification:
  stage: post-deployment
  image: curlimages/curl:latest
  dependencies:
    - deploy-production
  script:
    - |
      # APIå¥åº·æ£€æŸ¥
      curl -f https://intelligent-env.example.com/health
      
      # åŠŸèƒ½éªŒè¯
      curl -f https://intelligent-env.example.com/api/v1/scheduler/status
      curl -f https://intelligent-env.example.com/api/v1/environment/status
      
      # æ€§èƒ½ç›‘æ§æ£€æŸ¥
      curl -f https://intelligent-env.example.com/metrics
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: on_success
```

## æœ¬èŠ‚æ€»ç»“

æœ¬èŠ‚æ·±å…¥ä»‹ç»äº†æ™ºèƒ½ç¯å¢ƒå±‚çš„å·¥ç¨‹åŒ–å®è·µï¼š

### ğŸ¯ æ ¸å¿ƒå·¥ç¨‹å®è·µ

1. **åŸºç¡€è®¾æ–½å³ä»£ç ï¼ˆIaCï¼‰**ï¼š
   - ä½¿ç”¨Terraformç®¡ç†äº‘åŸºç¡€è®¾æ–½
   - å®ç°åŸºç¡€è®¾æ–½çš„ç‰ˆæœ¬æ§åˆ¶å’Œè‡ªåŠ¨åŒ–éƒ¨ç½²
   - æ”¯æŒå¤šç¯å¢ƒé…ç½®å’Œå®‰å…¨ç­–ç•¥

2. **å®¹å™¨ç¼–æ’ä¸éƒ¨ç½²**ï¼š
   - Kubernetesé›†ç¾¤ç®¡ç†å’ŒèŠ‚ç‚¹é…ç½®
   - Helm Chartæ¨¡æ¿åŒ–éƒ¨ç½²
   - IstioæœåŠ¡ç½‘æ ¼æµé‡ç®¡ç†

3. **é…ç½®ç®¡ç†è‡ªåŠ¨åŒ–**ï¼š
   - ConfigMapå’ŒSecretçš„ç»Ÿä¸€ç®¡ç†
   - é…ç½®éªŒè¯å’Œå®Œæ•´æ€§æ£€æŸ¥
   - åŠ¨æ€é…ç½®æ›´æ–°æœºåˆ¶

### ğŸ”§ å…³é”®æŠ€æœ¯å®ç°

- **æ™ºèƒ½ç¯å¢ƒå®šä¹‰**ï¼šå£°æ˜å¼çš„åŸºç¡€è®¾æ–½é…ç½®
- **æ•…éšœæ£€æµ‹ä¸æ¢å¤**ï¼šè‡ªåŠ¨åŒ–çš„æ•…éšœå¤„ç†æœºåˆ¶
- **CI/CDæµæ°´çº¿**ï¼šå®Œæ•´çš„æŒç»­é›†æˆéƒ¨ç½²æµç¨‹
- **å¤šç¯å¢ƒç®¡ç†**ï¼šå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒçš„ç»Ÿä¸€ç®¡ç†

### ğŸš€ å·¥ç¨‹åŒ–ä»·å€¼

- **è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜**ï¼šå‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜éƒ¨ç½²æ•ˆç‡
- **ä¸€è‡´æ€§ä¿è¯**ï¼šç¡®ä¿ä¸åŒç¯å¢ƒçš„é…ç½®ä¸€è‡´æ€§
- **å¿«é€Ÿæ•…éšœæ¢å¤**ï¼šè‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤ç³»ç»Ÿæ•…éšœ
- **å¯è§‚æµ‹æ€§å¼º**ï¼šå…¨é¢çš„ç›‘æ§å’Œæ—¥å¿—è®°å½•

---

**ä¸‹ä¸€æ­¥å­¦ä¹ **ï¼šå®Œæˆäº†å·¥ç¨‹åŒ–å®è·µçš„å­¦ä¹ åï¼Œæˆ‘ä»¬å°†ç»§ç»­å­¦ä¹ ç¯å¢ƒç›‘æ§ä¸æ™ºèƒ½æ²»ç†ï¼Œäº†è§£å¦‚ä½•å»ºç«‹å…¨é¢çš„è¿ç»´ç›‘æ§ä½“ç³»ã€‚

> **ğŸ’¡ å·¥ç¨‹åŒ–è¦è¯€**ï¼šå·¥ç¨‹åŒ–å®è·µçš„å…³é”®åœ¨äºè‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–ã€‚é€šè¿‡åŸºç¡€è®¾æ–½å³ä»£ç ã€è‡ªåŠ¨åŒ–éƒ¨ç½²å’Œæ•…éšœæ¢å¤æœºåˆ¶ï¼Œå°†è¿ç»´å·¥ä½œä»è¢«åŠ¨å“åº”è½¬å˜ä¸ºä¸»åŠ¨ç®¡ç†ï¼Œæé«˜ç³»ç»Ÿçš„å¯é æ€§å’Œè¿ç»´æ•ˆç‡ã€‚
