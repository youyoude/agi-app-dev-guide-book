# 4.4.5 智能环境层的工程化实践

> "理论指导实践，实践检验理论。智能环境层的工程化实践，是将设计理念转化为可运行、可扩展、可维护系统的关键桥梁。"

## 🎯 本节学习目标

完成本节学习后，您将能够：
- ✅ 掌握基础设施即代码（IaC）的设计和实现
- ✅ 实现容器编排和云原生部署策略
- ✅ 构建自动化配置管理和故障恢复机制
- ✅ 建立持续集成部署的完整流水线

## 基础设施即代码（IaC）

### Terraform智能环境定义

将智能环境层的基础设施用代码的方式定义和管理：

```hcl
# 智能环境层主配置
# file: infrastructure/main.tf

terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

# 智能环境层VPC配置
resource "aws_vpc" "intelligent_environment" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name        = "intelligent-environment-vpc"
    Environment = var.environment
    Purpose     = "agi-application-infrastructure"
  }
}

# 多可用区子网配置
resource "aws_subnet" "environment_subnets" {
  count = length(var.availability_zones)
  
  vpc_id                  = aws_vpc.intelligent_environment.id
  cidr_block              = cidrsubnet(var.vpc_cidr, 8, count.index + 1)
  availability_zone       = var.availability_zones[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = "intelligent-environment-subnet-${count.index + 1}"
    Type = "public"
    "kubernetes.io/cluster/${var.cluster_name}" = "shared"
  }
}

# EKS集群配置
resource "aws_eks_cluster" "intelligent_environment" {
  name     = var.cluster_name
  role_arn = aws_iam_role.eks_cluster_role.arn
  version  = var.kubernetes_version
  
  vpc_config {
    subnet_ids              = aws_subnet.environment_subnets[*].id
    endpoint_private_access = true
    endpoint_public_access  = true
    public_access_cidrs     = var.allowed_cidrs
  }
  
  enabled_cluster_log_types = [
    "api", "audit", "authenticator", "controllerManager", "scheduler"
  ]
  
  depends_on = [
    aws_iam_role_policy_attachment.eks_cluster_policy,
    aws_iam_role_policy_attachment.eks_vpc_resource_controller,
  ]
  
  tags = {
    Environment = var.environment
    Purpose     = "agi-intelligent-environment"
  }
}

# 智能环境节点组配置
resource "aws_eks_node_group" "environment_nodes" {
  cluster_name    = aws_eks_cluster.intelligent_environment.name
  node_group_name = "intelligent-environment-nodes"
  node_role_arn   = aws_iam_role.eks_node_group_role.arn
  subnet_ids      = aws_subnet.environment_subnets[*].id
  
  scaling_config {
    desired_size = var.node_desired_size
    max_size     = var.node_max_size
    min_size     = var.node_min_size
  }
  
  update_config {
    max_unavailable_percentage = 25
  }
  
  instance_types = var.node_instance_types
  capacity_type  = "SPOT"  # 使用Spot实例降低成本
  
  # 智能环境专用标签
  labels = {
    "node-type"           = "intelligent-environment"
    "workload-isolation" = "enabled"
    "auto-scaling"       = "enabled"
  }
  
  # 污点配置，专用于智能环境工作负载
  taint {
    key    = "intelligent-environment"
    value  = "dedicated"
    effect = "NO_SCHEDULE"
  }
  
  depends_on = [
    aws_iam_role_policy_attachment.eks_worker_node_policy,
    aws_iam_role_policy_attachment.eks_cni_policy,
    aws_iam_role_policy_attachment.eks_container_registry_policy,
  ]
}

# GPU节点组（用于AI推理工作负载）
resource "aws_eks_node_group" "gpu_nodes" {
  count = var.enable_gpu_nodes ? 1 : 0
  
  cluster_name    = aws_eks_cluster.intelligent_environment.name
  node_group_name = "gpu-inference-nodes"
  node_role_arn   = aws_iam_role.eks_node_group_role.arn
  subnet_ids      = aws_subnet.environment_subnets[*].id
  
  scaling_config {
    desired_size = var.gpu_node_desired_size
    max_size     = var.gpu_node_max_size
    min_size     = 0
  }
  
  instance_types = ["p3.2xlarge", "g4dn.xlarge"]  # GPU实例类型
  
  labels = {
    "node-type"        = "gpu-inference"
    "accelerator"      = "nvidia-tesla"
    "workload-type"    = "ml-inference"
  }
  
  taint {
    key    = "nvidia.com/gpu"
    value  = "present"
    effect = "NO_SCHEDULE"
  }
}
```

### 变量和配置管理

```hcl
# file: infrastructure/variables.tf

variable "environment" {
  description = "环境名称"
  type        = string
  default     = "development"
  
  validation {
    condition     = contains(["development", "staging", "production"], var.environment)
    error_message = "环境必须是development、staging或production之一。"
  }
}

variable "vpc_cidr" {
  description = "VPC CIDR块"
  type        = string
  default     = "10.0.0.0/16"
}

variable "availability_zones" {
  description = "可用区列表"
  type        = list(string)
  default     = ["us-west-2a", "us-west-2b", "us-west-2c"]
}

variable "cluster_name" {
  description = "EKS集群名称"
  type        = string
  default     = "intelligent-environment-cluster"
}

variable "kubernetes_version" {
  description = "Kubernetes版本"
  type        = string
  default     = "1.28"
}

variable "node_instance_types" {
  description = "节点实例类型"
  type        = list(string)
  default     = ["t3.medium", "t3.large", "c5.large"]
}

variable "intelligent_environment_config" {
  description = "智能环境层配置"
  type = object({
    resource_scheduler = object({
      enable_prediction     = bool
      scheduling_interval   = number
      optimization_strategy = string
    })
    security_policies = object({
      zero_trust_enabled    = bool
      isolation_level       = string
      audit_logging        = bool
    })
    monitoring = object({
      enable_detailed_metrics = bool
      log_retention_days      = number
      alerting_enabled        = bool
    })
  })
  
  default = {
    resource_scheduler = {
      enable_prediction     = true
      scheduling_interval   = 30
      optimization_strategy = "multi-objective"
    }
    security_policies = {
      zero_trust_enabled = true
      isolation_level    = "strict"
      audit_logging     = true
    }
    monitoring = {
      enable_detailed_metrics = true
      log_retention_days      = 30
      alerting_enabled        = true
    }
  }
}
```

### 智能环境层应用定义

```yaml
# file: kubernetes/intelligent-environment/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: intelligent-environment
  labels:
    name: intelligent-environment
    purpose: agi-application-infrastructure
  annotations:
    scheduler.alpha.kubernetes.io/preferred-zone: multi-zone
    security-policy.kubernetes.io/isolation-level: strict

---
# 资源调度器部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resource-scheduler
  namespace: intelligent-environment
  labels:
    component: resource-scheduler
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      component: resource-scheduler
  template:
    metadata:
      labels:
        component: resource-scheduler
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: resource-scheduler
      tolerations:
      - key: intelligent-environment
        operator: Equal
        value: dedicated
        effect: NoSchedule
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: component
                  operator: In
                  values: ["resource-scheduler"]
              topologyKey: kubernetes.io/hostname
      containers:
      - name: scheduler
        image: intelligent-environment/resource-scheduler:v1.0.0
        ports:
        - containerPort: 8080
          name: http-metrics
        - containerPort: 9090
          name: grpc-api
        env:
        - name: ENVIRONMENT
          value: "{{ .Values.environment }}"
        - name: LOG_LEVEL
          value: "INFO"
        - name: SCHEDULER_INTERVAL
          value: "30s"
        - name: PREDICTION_ENABLED
          value: "true"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 3
        volumeMounts:
        - name: config-volume
          mountPath: /etc/scheduler
          readOnly: true
        - name: tls-certs
          mountPath: /etc/tls
          readOnly: true
      volumes:
      - name: config-volume
        configMap:
          name: scheduler-config
      - name: tls-certs
        secret:
          secretName: scheduler-tls

---
# 环境管理器部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: environment-manager
  namespace: intelligent-environment
spec:
  replicas: 2
  selector:
    matchLabels:
      component: environment-manager
  template:
    metadata:
      labels:
        component: environment-manager
        version: v1.0.0
    spec:
      serviceAccountName: environment-manager
      containers:
      - name: manager
        image: intelligent-environment/environment-manager:v1.0.0
        ports:
        - containerPort: 8081
          name: http-api
        env:
        - name: ISOLATION_LEVEL
          value: "strict"
        - name: SECURITY_POLICIES_ENABLED
          value: "true"
        resources:
          requests:
            cpu: 200m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
          readOnlyRootFilesystem: true
```

## 容器编排实践

### Helm Chart智能环境部署

```yaml
# file: helm-charts/intelligent-environment/Chart.yaml
apiVersion: v2
name: intelligent-environment
description: 智能环境层 Helm Chart
type: application
version: 1.0.0
appVersion: "1.0.0"
keywords:
  - agi
  - intelligent-environment
  - resource-scheduling
  - security
home: https://github.com/joyagent/intelligent-environment
sources:
  - https://github.com/joyagent/intelligent-environment
maintainers:
  - name: AI Team
    email: agi-team@example.com

dependencies:
  - name: prometheus
    version: "15.x"
    repository: "https://prometheus-community.github.io/helm-charts"
    condition: monitoring.prometheus.enabled
  - name: grafana
    version: "6.x"
    repository: "https://grafana.github.io/helm-charts"
    condition: monitoring.grafana.enabled
  - name: cert-manager
    version: "v1.13.x"
    repository: "https://charts.jetstack.io"
    condition: security.certManager.enabled
```

```yaml
# file: helm-charts/intelligent-environment/values.yaml
# 默认配置值

global:
  imageRegistry: ""
  imagePullSecrets: []
  storageClass: "gp2"

environment: development
replicaCount: 3

image:
  repository: intelligent-environment
  pullPolicy: IfNotPresent
  tag: "v1.0.0"

service:
  type: ClusterIP
  ports:
    http: 8080
    grpc: 9090
    metrics: 8081

ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: intelligent-env.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: intelligent-environment-tls
      hosts:
        - intelligent-env.example.com

# 资源调度器配置
resourceScheduler:
  enabled: true
  config:
    schedulingInterval: "30s"
    predictionEnabled: true
    optimizationStrategy: "multi-objective"
    objectives:
      resourceUtilization: 0.3
      responseTime: 0.25
      fairness: 0.2
      energyEfficiency: 0.15
      costOptimization: 0.1
  
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 4Gi

# 环境管理器配置
environmentManager:
  enabled: true
  isolationLevel: "strict"
  securityPolicies:
    zeroTrustEnabled: true
    auditLogging: true
  
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi

# 安全控制配置
security:
  podSecurityPolicy:
    enabled: true
  networkPolicies:
    enabled: true
  certManager:
    enabled: true
    issuer: "letsencrypt-prod"
  
  rbac:
    create: true
    serviceAccountName: intelligent-environment

# 监控配置
monitoring:
  prometheus:
    enabled: true
    serviceMonitor:
      enabled: true
      interval: 30s
  grafana:
    enabled: true
    dashboards:
      enabled: true
  alerts:
    enabled: true
    rules:
      - name: ResourceScheduler
        rules:
          - alert: HighSchedulingLatency
            expr: scheduler_latency_seconds > 5
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: "资源调度延迟过高"
              description: "资源调度延迟超过5秒，影响用户体验"

# 持久化存储配置  
persistence:
  enabled: true
  accessMode: ReadWriteOnce
  size: 50Gi
  annotations: {}

# 自动扩缩容配置
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60

# 节点亲和性配置
nodeAffinity:
  preferredDuringSchedulingIgnoredDuringExecution:
  - weight: 100
    preference:
      matchExpressions:
      - key: node-type
        operator: In
        values: ["intelligent-environment"]

# 容忍度配置
tolerations:
- key: intelligent-environment
  operator: Equal
  value: dedicated
  effect: NoSchedule
```

### Istio服务网格配置

```yaml
# file: service-mesh/intelligent-environment-mesh.yaml
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: intelligent-environment-mesh
  namespace: istio-system
spec:
  values:
    pilot:
      env:
        EXTERNAL_ISTIOD: false
    global:
      meshID: intelligent-environment
      multiCluster:
        clusterName: intelligent-environment-cluster
      network: network1
  components:
    pilot:
      k8s:
        resources:
          requests:
            cpu: 500m
            memory: 2048Mi
          limits:
            cpu: 1000m
            memory: 4096Mi
        hpaSpec:
          minReplicas: 2
          maxReplicas: 5
          scaleTargetRef:
            apiVersion: apps/v1
            kind: Deployment
            name: istiod
          metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 80

---
# 智能环境命名空间服务网格配置
apiVersion: v1
kind: Namespace
metadata:
  name: intelligent-environment
  labels:
    istio-injection: enabled
    security-policy: strict
    network-policy: enabled

---
# 流量管理策略
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: intelligent-environment-destination
  namespace: intelligent-environment
spec:
  host: "*.intelligent-environment.svc.cluster.local"
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL
    loadBalancer:
      simple: LEAST_CONN
    connectionPool:
      tcp:
        maxConnections: 100
        connectTimeout: 30s
      http:
        http1MaxPendingRequests: 100
        maxRequestsPerConnection: 10
        maxRetries: 3
    circuitBreaker:
      consecutiveErrors: 3
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50

---
# 安全策略
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: intelligent-environment
spec:
  mtls:
    mode: STRICT

---
# 授权策略
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: intelligent-environment-authz
  namespace: intelligent-environment
spec:
  rules:
  - from:
    - source:
        namespaces: ["intelligent-environment"]
    to:
    - operation:
        methods: ["GET", "POST", "PUT", "DELETE"]
    when:
    - key: request.headers[authorization]
      values: ["Bearer *"]
```

## 配置管理自动化

### ConfigMap和Secret管理

```python
"""
智能环境配置管理自动化脚本
file: scripts/config-management.py
"""

import yaml
import json
import base64
import kubernetes
from kubernetes import client, config
from typing import Dict, List, Any, Optional
import asyncio
import logging
from pathlib import Path

class IntelligentEnvironmentConfigManager:
    """智能环境配置管理器"""
    
    def __init__(self, kubeconfig_path: Optional[str] = None):
        if kubeconfig_path:
            config.load_kube_config(config_file=kubeconfig_path)
        else:
            config.load_incluster_config()
        
        self.v1 = client.CoreV1Api()
        self.namespace = "intelligent-environment"
        self.logger = logging.getLogger(__name__)
        
    async def deploy_configurations(self, config_dir: str) -> Dict[str, Any]:
        """部署配置文件"""
        
        config_path = Path(config_dir)
        results = {
            "configmaps": [],
            "secrets": [],
            "errors": []
        }
        
        # 处理ConfigMap文件
        configmap_files = list(config_path.glob("configmaps/*.yaml"))
        for file_path in configmap_files:
            try:
                result = await self._deploy_configmap(file_path)
                results["configmaps"].append(result)
            except Exception as e:
                error_info = {
                    "file": str(file_path),
                    "error": str(e),
                    "type": "configmap"
                }
                results["errors"].append(error_info)
        
        # 处理Secret文件
        secret_files = list(config_path.glob("secrets/*.yaml"))
        for file_path in secret_files:
            try:
                result = await self._deploy_secret(file_path)
                results["secrets"].append(result)
            except Exception as e:
                error_info = {
                    "file": str(file_path),
                    "error": str(e),
                    "type": "secret"
                }
                results["errors"].append(error_info)
        
        return results
    
    async def _deploy_configmap(self, file_path: Path) -> Dict[str, Any]:
        """部署ConfigMap"""
        
        with open(file_path, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        
        configmap_name = config_data["metadata"]["name"]
        
        # 检查ConfigMap是否存在
        try:
            existing_cm = self.v1.read_namespaced_config_map(
                name=configmap_name, 
                namespace=self.namespace
            )
            
            # 更新现有ConfigMap
            existing_cm.data = config_data.get("data", {})
            updated_cm = self.v1.replace_namespaced_config_map(
                name=configmap_name,
                namespace=self.namespace,
                body=existing_cm
            )
            
            self.logger.info(f"Updated ConfigMap: {configmap_name}")
            return {
                "name": configmap_name,
                "action": "updated",
                "resource_version": updated_cm.metadata.resource_version
            }
            
        except client.ApiException as e:
            if e.status == 404:
                # 创建新ConfigMap
                configmap = client.V1ConfigMap(
                    api_version="v1",
                    kind="ConfigMap",
                    metadata=client.V1ObjectMeta(
                        name=configmap_name,
                        namespace=self.namespace,
                        labels=config_data["metadata"].get("labels", {}),
                        annotations=config_data["metadata"].get("annotations", {})
                    ),
                    data=config_data.get("data", {})
                )
                
                created_cm = self.v1.create_namespaced_config_map(
                    namespace=self.namespace,
                    body=configmap
                )
                
                self.logger.info(f"Created ConfigMap: {configmap_name}")
                return {
                    "name": configmap_name,
                    "action": "created",
                    "resource_version": created_cm.metadata.resource_version
                }
            else:
                raise
    
    async def _deploy_secret(self, file_path: Path) -> Dict[str, Any]:
        """部署Secret"""
        
        with open(file_path, 'r', encoding='utf-8') as f:
            secret_data = yaml.safe_load(f)
        
        secret_name = secret_data["metadata"]["name"]
        
        # 处理Secret数据编码
        encoded_data = {}
        raw_data = secret_data.get("data", {})
        
        for key, value in raw_data.items():
            if isinstance(value, str):
                # 如果值还未编码，进行base64编码
                if not self._is_base64(value):
                    encoded_data[key] = base64.b64encode(value.encode()).decode()
                else:
                    encoded_data[key] = value
        
        try:
            existing_secret = self.v1.read_namespaced_secret(
                name=secret_name,
                namespace=self.namespace
            )
            
            # 更新现有Secret
            existing_secret.data = encoded_data
            updated_secret = self.v1.replace_namespaced_secret(
                name=secret_name,
                namespace=self.namespace,
                body=existing_secret
            )
            
            self.logger.info(f"Updated Secret: {secret_name}")
            return {
                "name": secret_name,
                "action": "updated",
                "resource_version": updated_secret.metadata.resource_version
            }
            
        except client.ApiException as e:
            if e.status == 404:
                # 创建新Secret
                secret = client.V1Secret(
                    api_version="v1",
                    kind="Secret",
                    metadata=client.V1ObjectMeta(
                        name=secret_name,
                        namespace=self.namespace,
                        labels=secret_data["metadata"].get("labels", {}),
                        annotations=secret_data["metadata"].get("annotations", {})
                    ),
                    type=secret_data.get("type", "Opaque"),
                    data=encoded_data
                )
                
                created_secret = self.v1.create_namespaced_secret(
                    namespace=self.namespace,
                    body=secret
                )
                
                self.logger.info(f"Created Secret: {secret_name}")
                return {
                    "name": secret_name,
                    "action": "created",
                    "resource_version": created_secret.metadata.resource_version
                }
            else:
                raise
    
    def _is_base64(self, s: str) -> bool:
        """检查字符串是否为base64编码"""
        try:
            return base64.b64encode(base64.b64decode(s)).decode() == s
        except:
            return False
    
    async def validate_configurations(self) -> Dict[str, Any]:
        """验证配置完整性"""
        
        validation_results = {
            "configmaps": {"valid": [], "invalid": []},
            "secrets": {"valid": [], "invalid": []},
            "summary": {"total": 0, "valid": 0, "invalid": 0}
        }
        
        # 验证ConfigMaps
        configmaps = self.v1.list_namespaced_config_map(namespace=self.namespace)
        for cm in configmaps.items:
            validation_result = await self._validate_configmap(cm)
            if validation_result["valid"]:
                validation_results["configmaps"]["valid"].append(validation_result)
            else:
                validation_results["configmaps"]["invalid"].append(validation_result)
        
        # 验证Secrets
        secrets = self.v1.list_namespaced_secret(namespace=self.namespace)
        for secret in secrets.items:
            validation_result = await self._validate_secret(secret)
            if validation_result["valid"]:
                validation_results["secrets"]["valid"].append(validation_result)
            else:
                validation_results["secrets"]["invalid"].append(validation_result)
        
        # 计算汇总信息
        total_valid = (len(validation_results["configmaps"]["valid"]) + 
                      len(validation_results["secrets"]["valid"]))
        total_invalid = (len(validation_results["configmaps"]["invalid"]) + 
                        len(validation_results["secrets"]["invalid"]))
        
        validation_results["summary"] = {
            "total": total_valid + total_invalid,
            "valid": total_valid,
            "invalid": total_invalid,
            "success_rate": total_valid / (total_valid + total_invalid) * 100 if (total_valid + total_invalid) > 0 else 100
        }
        
        return validation_results
    
    async def _validate_configmap(self, configmap) -> Dict[str, Any]:
        """验证ConfigMap"""
        
        validation_result = {
            "name": configmap.metadata.name,
            "type": "ConfigMap",
            "valid": True,
            "issues": []
        }
        
        # 检查必需的标签
        required_labels = ["app", "component", "version"]
        labels = configmap.metadata.labels or {}
        
        for label in required_labels:
            if label not in labels:
                validation_result["issues"].append(f"缺少必需标签: {label}")
        
        # 检查数据完整性
        data = configmap.data or {}
        if not data:
            validation_result["issues"].append("ConfigMap数据为空")
        
        # 验证配置文件格式
        for key, value in data.items():
            if key.endswith(('.yaml', '.yml')):
                try:
                    yaml.safe_load(value)
                except yaml.YAMLError as e:
                    validation_result["issues"].append(f"YAML格式错误 in {key}: {str(e)}")
            elif key.endswith('.json'):
                try:
                    json.loads(value)
                except json.JSONDecodeError as e:
                    validation_result["issues"].append(f"JSON格式错误 in {key}: {str(e)}")
        
        validation_result["valid"] = len(validation_result["issues"]) == 0
        return validation_result

# 配置文件示例
intelligent_environment_configs = {
    "scheduler_config.yaml": """
apiVersion: v1
kind: ConfigMap
metadata:
  name: scheduler-config
  namespace: intelligent-environment
  labels:
    app: intelligent-environment
    component: resource-scheduler
    version: v1.0.0
data:
  scheduler.yaml: |
    scheduler:
      interval: 30s
      prediction:
        enabled: true
        window: 300s
        algorithm: "lstm"
      optimization:
        strategy: "multi-objective"
        objectives:
          resource_utilization: 0.3
          response_time: 0.25
          fairness: 0.2
          energy_efficiency: 0.15
          cost_optimization: 0.1
      policies:
        cpu_overcommit_ratio: 1.5
        memory_overcommit_ratio: 1.2
        gpu_sharing_enabled: true
    """,
    
    "environment_manager_config.yaml": """
apiVersion: v1
kind: ConfigMap
metadata:
  name: environment-manager-config
  namespace: intelligent-environment
  labels:
    app: intelligent-environment
    component: environment-manager
    version: v1.0.0
data:
  manager.yaml: |
    environment_manager:
      isolation:
        level: "strict"
        network_policies: true
        pod_security_policies: true
      security:
        zero_trust: true
        audit_logging: true
        threat_detection: true
      resources:
        default_limits:
          cpu: "1000m"
          memory: "2Gi"
        quota_enforcement: true
    """
}

## 故障恢复机制

### 自动故障检测与恢复

```python
"""
智能环境故障检测与自动恢复系统
file: services/fault-recovery.py
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
import json

class FaultSeverity(Enum):
    """故障严重程度"""
    INFO = 1
    WARNING = 2
    ERROR = 3
    CRITICAL = 4
    EMERGENCY = 5

class RecoveryAction(Enum):
    """恢复动作类型"""
    RESTART_SERVICE = "restart_service"
    SCALE_OUT = "scale_out"
    FAILOVER = "failover"
    ROLLBACK = "rollback"
    ISOLATE_NODE = "isolate_node"
    ALERT_ADMIN = "alert_admin"

@dataclass
class Fault:
    """故障信息"""
    fault_id: str
    component: str
    description: str
    severity: FaultSeverity
    detected_at: datetime
    metrics: Dict[str, Any]
    affected_resources: List[str]
    
class FaultDetector:
    """故障检测器"""
    
    def __init__(self):
        self.detection_rules = {}
        self.metrics_collector = MetricsCollector()
        self.threshold_manager = ThresholdManager()
        self.anomaly_detector = AnomalyDetector()
        
    async def register_detection_rule(self, 
                                    rule_name: str,
                                    rule_config: Dict[str, Any]):
        """注册故障检测规则"""
        
        self.detection_rules[rule_name] = {
            "config": rule_config,
            "enabled": True,
            "last_check": None,
            "detection_count": 0
        }
        
        logging.info(f"注册故障检测规则: {rule_name}")
    
    async def detect_faults(self) -> List[Fault]:
        """执行故障检测"""
        
        detected_faults = []
        current_metrics = await self.metrics_collector.collect_all_metrics()
        
        for rule_name, rule_info in self.detection_rules.items():
            if not rule_info["enabled"]:
                continue
            
            rule_config = rule_info["config"]
            
            try:
                # 基于规则的故障检测
                rule_faults = await self._apply_detection_rule(
                    rule_name, rule_config, current_metrics
                )
                detected_faults.extend(rule_faults)
                
                # 基于异常检测的故障发现
                anomaly_faults = await self._detect_anomalies(
                    rule_name, rule_config, current_metrics
                )
                detected_faults.extend(anomaly_faults)
                
                # 更新规则状态
                rule_info["last_check"] = datetime.now()
                rule_info["detection_count"] += len(rule_faults) + len(anomaly_faults)
                
            except Exception as e:
                logging.error(f"故障检测规则 {rule_name} 执行失败: {str(e)}")
                continue
        
        return detected_faults
    
    async def _apply_detection_rule(self,
                                  rule_name: str,
                                  rule_config: Dict[str, Any],
                                  metrics: Dict[str, Any]) -> List[Fault]:
        """应用检测规则"""
        
        faults = []
        rule_type = rule_config["type"]
        
        if rule_type == "threshold":
            faults = await self._threshold_detection(rule_name, rule_config, metrics)
        elif rule_type == "pattern":
            faults = await self._pattern_detection(rule_name, rule_config, metrics)
        elif rule_type == "correlation":
            faults = await self._correlation_detection(rule_name, rule_config, metrics)
        
        return faults
    
    async def _threshold_detection(self,
                                 rule_name: str,
                                 rule_config: Dict[str, Any],
                                 metrics: Dict[str, Any]) -> List[Fault]:
        """阈值检测"""
        
        faults = []
        metric_name = rule_config["metric"]
        threshold_config = rule_config["threshold"]
        
        if metric_name not in metrics:
            return faults
        
        metric_value = metrics[metric_name]["value"]
        threshold_value = threshold_config["value"]
        operator = threshold_config["operator"]
        
        fault_detected = False
        
        if operator == "greater_than" and metric_value > threshold_value:
            fault_detected = True
        elif operator == "less_than" and metric_value < threshold_value:
            fault_detected = True
        elif operator == "equals" and metric_value == threshold_value:
            fault_detected = True
        
        if fault_detected:
            fault = Fault(
                fault_id=f"{rule_name}_{datetime.now().timestamp()}",
                component=rule_config["component"],
                description=f"{metric_name} {operator} {threshold_value}, 当前值: {metric_value}",
                severity=FaultSeverity(rule_config.get("severity", 2)),
                detected_at=datetime.now(),
                metrics={metric_name: metric_value},
                affected_resources=rule_config.get("affected_resources", [])
            )
            faults.append(fault)
        
        return faults

class FaultRecoveryEngine:
    """故障恢复引擎"""
    
    def __init__(self):
        self.recovery_strategies = {}
        self.execution_queue = asyncio.Queue()
        self.recovery_history = []
        self.kubernetes_client = KubernetesClient()
        
    async def register_recovery_strategy(self,
                                       strategy_name: str,
                                       strategy_config: Dict[str, Any]):
        """注册恢复策略"""
        
        self.recovery_strategies[strategy_name] = {
            "config": strategy_config,
            "enabled": True,
            "success_rate": 0.0,
            "execution_count": 0,
            "last_used": None
        }
        
        logging.info(f"注册恢复策略: {strategy_name}")
    
    async def recover_fault(self, fault: Fault) -> Dict[str, Any]:
        """执行故障恢复"""
        
        # 选择最佳恢复策略
        strategy_name = await self._select_recovery_strategy(fault)
        
        if not strategy_name:
            return {
                "success": False,
                "error": "未找到适用的恢复策略"
            }
        
        strategy_config = self.recovery_strategies[strategy_name]["config"]
        
        # 执行恢复动作
        recovery_result = await self._execute_recovery_actions(
            fault, strategy_config
        )
        
        # 更新策略统计
        await self._update_strategy_stats(strategy_name, recovery_result["success"])
        
        # 记录恢复历史
        recovery_record = {
            "fault_id": fault.fault_id,
            "strategy_name": strategy_name,
            "recovery_result": recovery_result,
            "timestamp": datetime.now()
        }
        self.recovery_history.append(recovery_record)
        
        return recovery_result
    
    async def _select_recovery_strategy(self, fault: Fault) -> Optional[str]:
        """选择恢复策略"""
        
        applicable_strategies = []
        
        for strategy_name, strategy_info in self.recovery_strategies.items():
            if not strategy_info["enabled"]:
                continue
            
            strategy_config = strategy_info["config"]
            
            # 检查适用条件
            if await self._is_strategy_applicable(fault, strategy_config):
                applicable_strategies.append({
                    "name": strategy_name,
                    "priority": strategy_config.get("priority", 5),
                    "success_rate": strategy_info["success_rate"]
                })
        
        if not applicable_strategies:
            return None
        
        # 按优先级和成功率排序
        applicable_strategies.sort(
            key=lambda x: (x["priority"], x["success_rate"]),
            reverse=True
        )
        
        return applicable_strategies[0]["name"]
    
    async def _is_strategy_applicable(self,
                                    fault: Fault,
                                    strategy_config: Dict[str, Any]) -> bool:
        """检查策略是否适用"""
        
        # 检查故障严重程度
        min_severity = strategy_config.get("min_severity", 1)
        if fault.severity.value < min_severity:
            return False
        
        # 检查组件匹配
        target_components = strategy_config.get("target_components", [])
        if target_components and fault.component not in target_components:
            return False
        
        # 检查故障类型
        fault_types = strategy_config.get("fault_types", [])
        if fault_types and not any(ft in fault.description.lower() for ft in fault_types):
            return False
        
        return True
    
    async def _execute_recovery_actions(self,
                                      fault: Fault,
                                      strategy_config: Dict[str, Any]) -> Dict[str, Any]:
        """执行恢复动作"""
        
        actions = strategy_config["actions"]
        results = []
        
        for action_config in actions:
            action_type = RecoveryAction(action_config["type"])
            
            try:
                if action_type == RecoveryAction.RESTART_SERVICE:
                    result = await self._restart_service(action_config, fault)
                elif action_type == RecoveryAction.SCALE_OUT:
                    result = await self._scale_out_service(action_config, fault)
                elif action_type == RecoveryAction.FAILOVER:
                    result = await self._failover_service(action_config, fault)
                elif action_type == RecoveryAction.ROLLBACK:
                    result = await self._rollback_deployment(action_config, fault)
                elif action_type == RecoveryAction.ISOLATE_NODE:
                    result = await self._isolate_node(action_config, fault)
                else:
                    result = {"success": False, "error": f"未支持的恢复动作: {action_type}"}
                
                results.append({
                    "action": action_type.value,
                    "result": result
                })
                
                # 如果动作失败且配置为停止执行，则退出
                if not result["success"] and action_config.get("stop_on_failure", False):
                    break
                
            except Exception as e:
                error_result = {
                    "action": action_type.value,
                    "result": {"success": False, "error": str(e)}
                }
                results.append(error_result)
                
                if action_config.get("stop_on_failure", False):
                    break
        
        # 计算整体成功率
        successful_actions = sum(1 for r in results if r["result"]["success"])
        success_rate = successful_actions / len(results) if results else 0
        
        return {
            "success": success_rate >= 0.5,  # 50%以上成功才算成功
            "success_rate": success_rate,
            "actions": results,
            "execution_time": datetime.now()
        }
    
    async def _restart_service(self,
                             action_config: Dict[str, Any],
                             fault: Fault) -> Dict[str, Any]:
        """重启服务"""
        
        service_name = action_config["service_name"]
        namespace = action_config.get("namespace", "intelligent-environment")
        
        try:
            # 获取部署
            deployment = await self.kubernetes_client.get_deployment(service_name, namespace)
            
            if not deployment:
                return {"success": False, "error": f"部署 {service_name} 不存在"}
            
            # 执行滚动重启
            restart_result = await self.kubernetes_client.restart_deployment(
                service_name, namespace
            )
            
            # 等待重启完成
            await self.kubernetes_client.wait_for_deployment_ready(
                service_name, namespace, timeout=300
            )
            
            return {
                "success": True,
                "message": f"服务 {service_name} 重启成功",
                "details": restart_result
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"重启服务失败: {str(e)}"
            }
    
    async def _scale_out_service(self,
                               action_config: Dict[str, Any],
                               fault: Fault) -> Dict[str, Any]:
        """扩容服务"""
        
        service_name = action_config["service_name"]
        namespace = action_config.get("namespace", "intelligent-environment")
        scale_factor = action_config.get("scale_factor", 2)
        max_replicas = action_config.get("max_replicas", 10)
        
        try:
            # 获取当前副本数
            current_replicas = await self.kubernetes_client.get_deployment_replicas(
                service_name, namespace
            )
            
            # 计算新的副本数
            new_replicas = min(current_replicas * scale_factor, max_replicas)
            
            if new_replicas == current_replicas:
                return {
                    "success": True,
                    "message": f"服务 {service_name} 已达到最大副本数",
                    "current_replicas": current_replicas
                }
            
            # 执行扩容
            scale_result = await self.kubernetes_client.scale_deployment(
                service_name, namespace, new_replicas
            )
            
            # 等待扩容完成
            await self.kubernetes_client.wait_for_deployment_ready(
                service_name, namespace, timeout=300
            )
            
            return {
                "success": True,
                "message": f"服务 {service_name} 扩容成功",
                "old_replicas": current_replicas,
                "new_replicas": new_replicas,
                "details": scale_result
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"服务扩容失败: {str(e)}"
            }

# 故障恢复策略配置示例
fault_recovery_strategies = {
    "resource_scheduler_recovery": {
        "config": {
            "priority": 9,
            "min_severity": 3,
            "target_components": ["resource-scheduler"],
            "fault_types": ["high_latency", "service_unavailable"],
            "actions": [
                {
                    "type": "restart_service",
                    "service_name": "resource-scheduler",
                    "namespace": "intelligent-environment",
                    "stop_on_failure": False
                },
                {
                    "type": "scale_out",
                    "service_name": "resource-scheduler", 
                    "namespace": "intelligent-environment",
                    "scale_factor": 2,
                    "max_replicas": 5,
                    "stop_on_failure": True
                }
            ]
        }
    },
    
    "environment_manager_recovery": {
        "config": {
            "priority": 8,
            "min_severity": 3,
            "target_components": ["environment-manager"],
            "fault_types": ["memory_leak", "cpu_spike", "deadlock"],
            "actions": [
                {
                    "type": "restart_service",
                    "service_name": "environment-manager",
                    "namespace": "intelligent-environment",
                    "stop_on_failure": False
                }
            ]
        }
    }
}
```

## 持续集成部署

### GitLab CI/CD流水线

```yaml
# file: .gitlab-ci.yml
stages:
  - validate
  - build
  - test
  - security-scan
  - deploy-dev
  - integration-test
  - deploy-staging
  - performance-test
  - deploy-production
  - post-deployment

variables:
  DOCKER_REGISTRY: "registry.example.com"
  KUBERNETES_NAMESPACE: "intelligent-environment"
  HELM_CHART_PATH: "helm-charts/intelligent-environment"

# 验证阶段
validate-terraform:
  stage: validate
  image: hashicorp/terraform:latest
  script:
    - cd infrastructure
    - terraform fmt -check
    - terraform validate
    - terraform plan -detailed-exitcode
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main"'

validate-kubernetes:
  stage: validate
  image: alpine/k8s:latest
  script:
    - kubectl --dry-run=client apply -f kubernetes/
    - helm template $HELM_CHART_PATH --validate
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main"'

lint-python:
  stage: validate
  image: python:3.11
  before_script:
    - pip install flake8 black pylint
  script:
    - flake8 scripts/ services/
    - black --check scripts/ services/
    - pylint scripts/ services/
  rules:
    - changes:
        - "**/*.py"

# 构建阶段
build-images:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - |
      for component in resource-scheduler environment-manager security-controller; do
        echo "Building $component..."
        docker build -t $DOCKER_REGISTRY/intelligent-environment/$component:$CI_COMMIT_SHA \
                     -t $DOCKER_REGISTRY/intelligent-environment/$component:latest \
                     -f docker/$component/Dockerfile .
        docker push $DOCKER_REGISTRY/intelligent-environment/$component:$CI_COMMIT_SHA
        docker push $DOCKER_REGISTRY/intelligent-environment/$component:latest
      done
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'

# 测试阶段
unit-tests:
  stage: test
  image: python:3.11
  before_script:
    - pip install -r requirements-test.txt
  script:
    - python -m pytest tests/unit/ --cov=services --cov-report=xml
    - python -m pytest tests/integration/ --cov-append
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    expire_in: 1 week
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# 安全扫描
security-scan:
  stage: security-scan
  image: securecodewarrior/docker-security-scan:latest
  script:
    - |
      for component in resource-scheduler environment-manager security-controller; do
        docker pull $DOCKER_REGISTRY/intelligent-environment/$component:$CI_COMMIT_SHA
        trivy image $DOCKER_REGISTRY/intelligent-environment/$component:$CI_COMMIT_SHA
      done
    - |
      # 扫描基础设施代码
      checkov -f infrastructure/
    - |
      # 扫描Kubernetes配置
      kube-score score kubernetes/**/*.yaml
  artifacts:
    reports:
      security: security-report.json
    expire_in: 1 week
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# 开发环境部署
deploy-dev:
  stage: deploy-dev
  image: alpine/k8s:latest
  environment:
    name: development
    url: https://dev.intelligent-env.example.com
  before_script:
    - kubectl config use-context development
  script:
    - |
      helm upgrade --install intelligent-environment $HELM_CHART_PATH \
        --namespace $KUBERNETES_NAMESPACE \
        --create-namespace \
        --set environment=development \
        --set image.tag=$CI_COMMIT_SHA \
        --set ingress.hosts[0].host=dev.intelligent-env.example.com \
        --wait --timeout=10m
  rules:
    - if: '$CI_COMMIT_BRANCH == "develop"'

# 集成测试
integration-tests:
  stage: integration-test
  image: postman/newman:latest
  dependencies:
    - deploy-dev
  script:
    - newman run tests/integration/api-tests.json \
        --environment tests/integration/dev-environment.json \
        --reporters cli,junit \
        --reporter-junit-export integration-test-results.xml
  artifacts:
    reports:
      junit: integration-test-results.xml
    expire_in: 1 week
  rules:
    - if: '$CI_COMMIT_BRANCH == "develop"'

# 预生产环境部署
deploy-staging:
  stage: deploy-staging
  image: alpine/k8s:latest
  environment:
    name: staging
    url: https://staging.intelligent-env.example.com
  before_script:
    - kubectl config use-context staging
  script:
    - |
      # 使用蓝绿部署策略
      helm upgrade --install intelligent-environment-blue $HELM_CHART_PATH \
        --namespace ${KUBERNETES_NAMESPACE}-blue \
        --create-namespace \
        --set environment=staging \
        --set image.tag=$CI_COMMIT_SHA \
        --set ingress.hosts[0].host=staging-blue.intelligent-env.example.com \
        --wait --timeout=15m
      
      # 健康检查
      curl -f https://staging-blue.intelligent-env.example.com/health || exit 1
      
      # 切换流量
      kubectl patch service intelligent-environment-service \
        --namespace $KUBERNETES_NAMESPACE \
        --patch '{"spec":{"selector":{"version":"blue"}}}'
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# 性能测试
performance-tests:
  stage: performance-test
  image: loadimpact/k6:latest
  dependencies:
    - deploy-staging
  script:
    - k6 run --out json=performance-results.json tests/performance/load-test.js
  artifacts:
    reports:
      performance: performance-results.json
    expire_in: 1 week
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# 生产环境部署
deploy-production:
  stage: deploy-production
  image: alpine/k8s:latest
  environment:
    name: production
    url: https://intelligent-env.example.com
  before_script:
    - kubectl config use-context production
  script:
    - |
      # 金丝雀部署策略
      helm upgrade --install intelligent-environment $HELM_CHART_PATH \
        --namespace $KUBERNETES_NAMESPACE \
        --set environment=production \
        --set image.tag=$CI_COMMIT_SHA \
        --set autoscaling.enabled=true \
        --set autoscaling.minReplicas=5 \
        --set autoscaling.maxReplicas=20 \
        --set monitoring.enabled=true \
        --wait --timeout=20m
      
      # 逐步增加新版本流量
      kubectl patch deployment intelligent-environment \
        --patch '{"spec":{"strategy":{"rollingUpdate":{"maxSurge":"10%","maxUnavailable":"0%"}}}}'
  when: manual
  only:
    - main
  allow_failure: false

# 部署后验证
post-deployment-verification:
  stage: post-deployment
  image: curlimages/curl:latest
  dependencies:
    - deploy-production
  script:
    - |
      # API健康检查
      curl -f https://intelligent-env.example.com/health
      
      # 功能验证
      curl -f https://intelligent-env.example.com/api/v1/scheduler/status
      curl -f https://intelligent-env.example.com/api/v1/environment/status
      
      # 性能监控检查
      curl -f https://intelligent-env.example.com/metrics
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: on_success
```

## 本节总结

本节深入介绍了智能环境层的工程化实践：

### 🎯 核心工程实践

1. **基础设施即代码（IaC）**：
   - 使用Terraform管理云基础设施
   - 实现基础设施的版本控制和自动化部署
   - 支持多环境配置和安全策略

2. **容器编排与部署**：
   - Kubernetes集群管理和节点配置
   - Helm Chart模板化部署
   - Istio服务网格流量管理

3. **配置管理自动化**：
   - ConfigMap和Secret的统一管理
   - 配置验证和完整性检查
   - 动态配置更新机制

### 🔧 关键技术实现

- **智能环境定义**：声明式的基础设施配置
- **故障检测与恢复**：自动化的故障处理机制
- **CI/CD流水线**：完整的持续集成部署流程
- **多环境管理**：开发、测试、生产环境的统一管理

### 🚀 工程化价值

- **自动化程度高**：减少人工干预，提高部署效率
- **一致性保证**：确保不同环境的配置一致性
- **快速故障恢复**：自动检测和修复系统故障
- **可观测性强**：全面的监控和日志记录

---

**下一步学习**：完成了工程化实践的学习后，我们将继续学习环境监控与智能治理，了解如何建立全面的运维监控体系。

> **💡 工程化要诀**：工程化实践的关键在于自动化和标准化。通过基础设施即代码、自动化部署和故障恢复机制，将运维工作从被动响应转变为主动管理，提高系统的可靠性和运维效率。
