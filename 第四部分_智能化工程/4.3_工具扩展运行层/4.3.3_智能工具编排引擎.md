# 4.3.3 æ™ºèƒ½å·¥å…·ç¼–æ’å¼•æ“

> "æ™ºèƒ½ç¼–æ’å¼•æ“æ˜¯å·¥å…·ä»é™æ€è°ƒç”¨å‡çº§ä¸ºåŠ¨æ€ååŒçš„å…³é”®æŠ€æœ¯ï¼Œå®ƒè®©å·¥å…·ä¸å†æ˜¯å­¤ç«‹çš„åŠŸèƒ½å•å…ƒï¼Œè€Œæ˜¯ååŒå·¥ä½œçš„æ™ºèƒ½å›¢é˜Ÿã€‚"

## ğŸ¯ æœ¬èŠ‚å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬èŠ‚å­¦ä¹ åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- âœ… è®¾è®¡åŸºäºä»»åŠ¡è¯­ä¹‰çš„æ™ºèƒ½å·¥å…·é€‰æ‹©ç®—æ³•
- âœ… å®ç°åŠ¨æ€å·¥å…·é“¾æ„å»ºå’Œæ‰§è¡Œè°ƒåº¦æœºåˆ¶
- âœ… æ„å»ºæ”¯æŒå¹¶å‘æ‰§è¡Œçš„å·¥å…·ç¼–æ’ç³»ç»Ÿ
- âœ… å»ºç«‹å·¥å…·æ‰§è¡ŒçŠ¶æ€ç®¡ç†å’Œå¼‚å¸¸å¤„ç†æœºåˆ¶

## æ™ºèƒ½ç¼–æ’å¼•æ“æ¦‚è¿°

### æ ¸å¿ƒæ¶æ„è®¾è®¡

æ™ºèƒ½ç¼–æ’å¼•æ“ä½œä¸ºå·¥å…·æ‰©å±•è¿è¡Œå±‚çš„æ ¸å¿ƒè°ƒåº¦ä¸­å¿ƒï¼Œè´Ÿè´£å°†æ™ºèƒ½æ€è€ƒå±‚çš„æ‰§è¡ŒæŒ‡ä»¤è½¬åŒ–ä¸ºå…·ä½“çš„å·¥å…·æ‰§è¡Œè®¡åˆ’ï¼š

```mermaid
graph TB
    subgraph "æ™ºèƒ½ç¼–æ’å¼•æ“æ¶æ„"
        ORCHESTRATOR[âš¡ æ™ºèƒ½ç¼–æ’å¼•æ“<br/>Intelligent Orchestration Engine]
        
        subgraph "æ ¸å¿ƒç»„ä»¶"
            ANALYZER[ğŸ” ä»»åŠ¡åˆ†æå™¨<br/>Task Analyzer]
            PLANNER[ğŸ“‹ æ‰§è¡Œè§„åˆ’å™¨<br/>Execution Planner]
            SELECTOR[ğŸ¯ å·¥å…·é€‰æ‹©å™¨<br/>Tool Selector]
            SCHEDULER[â° è°ƒåº¦ç®¡ç†å™¨<br/>Schedule Manager]
            MONITOR[ğŸ“Š æ‰§è¡Œç›‘æ§å™¨<br/>Execution Monitor]
        end
        
        ORCHESTRATOR --> ANALYZER
        ORCHESTRATOR --> PLANNER
        ORCHESTRATOR --> SELECTOR
        ORCHESTRATOR --> SCHEDULER
        ORCHESTRATOR --> MONITOR
    end
    
    subgraph "è¾“å…¥è¾“å‡º"
        THINKING_LAYER[ğŸ§  æ™ºèƒ½æ€è€ƒå±‚]
        TOOL_REGISTRY[ğŸ›ï¸ å·¥å…·æ³¨å†Œä¸­å¿ƒ]
        TOOLS[ğŸ”§ å·¥å…·å®ä¾‹]
        RESULTS[ğŸ“Š æ‰§è¡Œç»“æœ]
    end
    
    THINKING_LAYER -->|æ‰§è¡ŒæŒ‡ä»¤| ORCHESTRATOR
    ORCHESTRATOR -->|å·¥å…·æŸ¥è¯¢| TOOL_REGISTRY
    ORCHESTRATOR -->|æ‰§è¡Œè°ƒç”¨| TOOLS
    TOOLS -->|æ‰§è¡Œç»“æœ| ORCHESTRATOR
    ORCHESTRATOR -->|çŠ¶æ€åé¦ˆ| THINKING_LAYER
```

### ç¼–æ’å¼•æ“çš„æ ¸å¿ƒèƒ½åŠ›

#### 1. æ™ºèƒ½ä»»åŠ¡ç†è§£
- **è¯­ä¹‰è§£æ**ï¼šæ·±åº¦ç†è§£ä»»åŠ¡çš„æ‰§è¡Œæ„å›¾å’Œçº¦æŸæ¡ä»¶
- **å¤æ‚åº¦è¯„ä¼°**ï¼šè¯„ä¼°ä»»åŠ¡çš„æ‰§è¡Œéš¾åº¦å’Œèµ„æºéœ€æ±‚
- **ä¾èµ–åˆ†æ**ï¼šè¯†åˆ«ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»å’Œæ‰§è¡Œé¡ºåº

#### 2. åŠ¨æ€å·¥å…·é€‰æ‹©
- **èƒ½åŠ›åŒ¹é…**ï¼šåŸºäºä»»åŠ¡éœ€æ±‚æ™ºèƒ½åŒ¹é…æœ€é€‚åˆçš„å·¥å…·
- **æ€§èƒ½ä¼˜åŒ–**ï¼šè€ƒè™‘å·¥å…·æ€§èƒ½å†å²å’Œå½“å‰è´Ÿè½½
- **æˆæœ¬è€ƒé‡**ï¼šå¹³è¡¡æ‰§è¡Œæ€§èƒ½å’Œèµ„æºæ¶ˆè€—

#### 3. æ™ºèƒ½æ‰§è¡Œè§„åˆ’
- **å¹¶å‘ä¼˜åŒ–**ï¼šè¯†åˆ«å¯å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡ç‰‡æ®µ
- **èµ„æºåˆ†é…**ï¼šåˆç†åˆ†é…è®¡ç®—å’Œå†…å­˜èµ„æº
- **å®¹é”™è®¾è®¡**ï¼šåˆ¶å®šå¼‚å¸¸å¤„ç†å’Œæ•…éšœæ¢å¤ç­–ç•¥

## ä»»åŠ¡åˆ†æä¸ç†è§£

### ä»»åŠ¡è¯­ä¹‰åˆ†æå™¨

```python
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import asyncio
from enum import Enum

class TaskComplexity(Enum):
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    VERY_COMPLEX = "very_complex"

@dataclass
class TaskAnalysisResult:
    """ä»»åŠ¡åˆ†æç»“æœ"""
    task_id: str
    complexity: TaskComplexity
    estimated_duration: float
    required_capabilities: List[str]
    resource_requirements: Dict[str, Any]
    dependencies: List[str]
    parallelizable_segments: List[Dict]
    risk_factors: List[str]

class TaskSemanticAnalyzer:
    """ä»»åŠ¡è¯­ä¹‰åˆ†æå™¨"""
    
    def __init__(self, llm_client, knowledge_base):
        self.llm = llm_client
        self.kb = knowledge_base
        self.complexity_classifier = ComplexityClassifier()
        self.dependency_analyzer = DependencyAnalyzer()
        
    async def analyze_task(self, task_description: str, context: Dict) -> TaskAnalysisResult:
        """åˆ†æä»»åŠ¡è¯­ä¹‰å’Œç‰¹å¾"""
        
        # 1. åŸºæœ¬è¯­ä¹‰è§£æ
        semantic_features = await self.extract_semantic_features(task_description)
        
        # 2. å¤æ‚åº¦è¯„ä¼°
        complexity = await self.assess_complexity(semantic_features, context)
        
        # 3. èƒ½åŠ›éœ€æ±‚åˆ†æ
        required_capabilities = await self.analyze_capability_requirements(semantic_features)
        
        # 4. èµ„æºéœ€æ±‚ä¼°ç®—
        resource_requirements = await self.estimate_resource_requirements(
            complexity, required_capabilities
        )
        
        # 5. ä¾èµ–å…³ç³»åˆ†æ
        dependencies = await self.analyze_dependencies(semantic_features, context)
        
        # 6. å¹¶è¡ŒåŒ–åˆ†æ
        parallelizable_segments = await self.identify_parallelizable_segments(
            semantic_features, dependencies
        )
        
        # 7. é£é™©å› ç´ è¯†åˆ«
        risk_factors = await self.identify_risk_factors(
            complexity, required_capabilities, dependencies
        )
        
        return TaskAnalysisResult(
            task_id=self.generate_task_id(),
            complexity=complexity,
            estimated_duration=self.estimate_duration(complexity, resource_requirements),
            required_capabilities=required_capabilities,
            resource_requirements=resource_requirements,
            dependencies=dependencies,
            parallelizable_segments=parallelizable_segments,
            risk_factors=risk_factors
        )
    
    async def extract_semantic_features(self, task_description: str) -> Dict:
        """æå–ä»»åŠ¡çš„è¯­ä¹‰ç‰¹å¾"""
        
        analysis_prompt = f"""
        åˆ†æä»¥ä¸‹ä»»åŠ¡çš„è¯­ä¹‰ç‰¹å¾ï¼š
        ä»»åŠ¡æè¿°ï¼š{task_description}
        
        è¯·è¯†åˆ«ï¼š
        1. æ ¸å¿ƒåŠ¨ä½œå’Œæ“ä½œç±»å‹
        2. æ¶‰åŠçš„æ•°æ®ç±»å‹å’Œæ ¼å¼
        3. è¾“å…¥è¾“å‡ºè¦æ±‚
        4. æ€§èƒ½å’Œè´¨é‡çº¦æŸ
        5. ç‰¹æ®Šè¦æ±‚å’Œé™åˆ¶æ¡ä»¶
        
        ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
        """
        
        result = await self.llm.generate(analysis_prompt)
        return self.parse_semantic_features(result)
    
    async def assess_complexity(self, semantic_features: Dict, context: Dict) -> TaskComplexity:
        """è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦"""
        
        complexity_factors = {
            'data_volume': semantic_features.get('data_volume', 'small'),
            'operation_types': len(semantic_features.get('operations', [])),
            'integration_points': len(semantic_features.get('external_services', [])),
            'constraint_complexity': len(semantic_features.get('constraints', [])),
            'output_complexity': semantic_features.get('output_complexity', 'simple')
        }
        
        # ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹è¯„ä¼°å¤æ‚åº¦
        complexity_score = await self.complexity_classifier.classify(
            complexity_factors, context
        )
        
        if complexity_score < 0.3:
            return TaskComplexity.SIMPLE
        elif complexity_score < 0.6:
            return TaskComplexity.MODERATE
        elif complexity_score < 0.8:
            return TaskComplexity.COMPLEX
        else:
            return TaskComplexity.VERY_COMPLEX
```

### ä¾èµ–å…³ç³»åˆ†æ

```python
class DependencyAnalyzer:
    """ä¾èµ–å…³ç³»åˆ†æå™¨"""
    
    def __init__(self):
        self.dependency_graph = DependencyGraph()
        self.cycle_detector = CycleDetector()
        
    async def analyze_dependencies(self, 
                                 semantic_features: Dict,
                                 context: Dict) -> List[str]:
        """åˆ†æä»»åŠ¡ä¾èµ–å…³ç³»"""
        
        dependencies = []
        
        # 1. æ•°æ®ä¾èµ–åˆ†æ
        data_dependencies = self.analyze_data_dependencies(semantic_features)
        dependencies.extend(data_dependencies)
        
        # 2. æœåŠ¡ä¾èµ–åˆ†æ
        service_dependencies = self.analyze_service_dependencies(semantic_features)
        dependencies.extend(service_dependencies)
        
        # 3. èµ„æºä¾èµ–åˆ†æ
        resource_dependencies = self.analyze_resource_dependencies(semantic_features)
        dependencies.extend(resource_dependencies)
        
        # 4. æ—¶åºä¾èµ–åˆ†æ
        temporal_dependencies = self.analyze_temporal_dependencies(semantic_features)
        dependencies.extend(temporal_dependencies)
        
        # 5. ç¯å½¢ä¾èµ–æ£€æµ‹
        if self.cycle_detector.has_cycles(dependencies):
            raise DependencyError("Circular dependency detected")
        
        return dependencies
    
    def analyze_data_dependencies(self, semantic_features: Dict) -> List[str]:
        """åˆ†ææ•°æ®ä¾èµ–"""
        
        data_dependencies = []
        
        input_data = semantic_features.get('input_data', [])
        for data_item in input_data:
            # æ£€æŸ¥æ•°æ®æ¥æº
            if 'source' in data_item and data_item['source'] != 'user_input':
                data_dependencies.append(f"data:{data_item['source']}")
            
            # æ£€æŸ¥æ•°æ®æ ¼å¼è½¬æ¢éœ€æ±‚
            if 'format_conversion' in data_item:
                data_dependencies.append(f"converter:{data_item['target_format']}")
        
        return data_dependencies
    
    def analyze_service_dependencies(self, semantic_features: Dict) -> List[str]:
        """åˆ†ææœåŠ¡ä¾èµ–"""
        
        service_dependencies = []
        
        external_services = semantic_features.get('external_services', [])
        for service in external_services:
            service_dependencies.append(f"service:{service['name']}")
            
            # æ£€æŸ¥è®¤è¯ä¾èµ–
            if service.get('requires_auth'):
                service_dependencies.append(f"auth:{service['auth_type']}")
        
        return service_dependencies
```

## æ™ºèƒ½å·¥å…·é€‰æ‹©ç®—æ³•

### å¤šç›®æ ‡ä¼˜åŒ–é€‰æ‹©å™¨

```python
class IntelligentToolSelector:
    """æ™ºèƒ½å·¥å…·é€‰æ‹©å™¨"""
    
    def __init__(self, tool_registry, performance_tracker):
        self.registry = tool_registry
        self.performance_tracker = performance_tracker
        self.selection_strategies = {
            'performance': PerformanceBasedStrategy(),
            'cost': CostBasedStrategy(),
            'reliability': ReliabilityBasedStrategy(),
            'compatibility': CompatibilityBasedStrategy()
        }
        
    async def select_tools(self, 
                          task_analysis: TaskAnalysisResult,
                          context: ExecutionContext) -> List[ToolSelection]:
        """æ™ºèƒ½é€‰æ‹©æ‰§è¡Œå·¥å…·"""
        
        selections = []
        
        for capability in task_analysis.required_capabilities:
            # 1. è·å–å€™é€‰å·¥å…·
            candidate_tools = await self.registry.find_tools_by_capability(capability)
            
            # 2. å¤šç­–ç•¥è¯„åˆ†
            scored_candidates = await self.score_candidates(
                candidate_tools, capability, context
            )
            
            # 3. å¤šç›®æ ‡ä¼˜åŒ–é€‰æ‹©
            selected_tool = await self.multi_objective_selection(
                scored_candidates, task_analysis, context
            )
            
            if selected_tool:
                selection = ToolSelection(
                    capability=capability,
                    selected_tool=selected_tool,
                    alternatives=scored_candidates[:3],  # ä¿ç•™å¤‡é€‰æ–¹æ¡ˆ
                    selection_reason=self.generate_selection_reason(selected_tool, scored_candidates)
                )
                selections.append(selection)
            else:
                # æ²¡æœ‰æ‰¾åˆ°åˆé€‚å·¥å…·ï¼Œéœ€è¦åˆ›é€ æ–°å·¥å…·
                selections.append(ToolSelection(
                    capability=capability,
                    selected_tool=None,
                    alternatives=[],
                    selection_reason="No suitable tool found, creation required"
                ))
        
        return selections
    
    async def score_candidates(self,
                             candidates: List[Tool],
                             capability: str,
                             context: ExecutionContext) -> List[ScoredTool]:
        """å¯¹å€™é€‰å·¥å…·è¿›è¡Œå¤šç»´åº¦è¯„åˆ†"""
        
        scored_tools = []
        
        for tool in candidates:
            scores = {}
            
            # å¹¶è¡Œæ‰§è¡Œå¤šç§ç­–ç•¥è¯„åˆ†
            scoring_tasks = [
                self.score_with_strategy(strategy_name, strategy, tool, capability, context)
                for strategy_name, strategy in self.selection_strategies.items()
            ]
            
            strategy_scores = await asyncio.gather(*scoring_tasks)
            
            for (strategy_name, _), score in zip(self.selection_strategies.items(), strategy_scores):
                scores[strategy_name] = score
            
            # è®¡ç®—ç»¼åˆå¾—åˆ†
            overall_score = self.calculate_overall_score(scores, context.preferences)
            
            scored_tool = ScoredTool(
                tool=tool,
                strategy_scores=scores,
                overall_score=overall_score
            )
            scored_tools.append(scored_tool)
        
        return sorted(scored_tools, key=lambda st: st.overall_score, reverse=True)
    
    async def multi_objective_selection(self,
                                      scored_candidates: List[ScoredTool],
                                      task_analysis: TaskAnalysisResult,
                                      context: ExecutionContext) -> Optional[Tool]:
        """å¤šç›®æ ‡ä¼˜åŒ–é€‰æ‹©æœ€ä½³å·¥å…·"""
        
        if not scored_candidates:
            return None
        
        # 1. è¿‡æ»¤ä¸æ»¡è¶³åŸºæœ¬è¦æ±‚çš„å·¥å…·
        filtered_candidates = self.filter_by_requirements(
            scored_candidates, task_analysis, context
        )
        
        if not filtered_candidates:
            return None
        
        # 2. å¸•ç´¯æ‰˜æœ€ä¼˜é€‰æ‹©
        pareto_optimal = self.find_pareto_optimal(filtered_candidates)
        
        # 3. æ ¹æ®ä¸Šä¸‹æ–‡åå¥½æœ€ç»ˆé€‰æ‹©
        final_selection = self.select_by_preferences(pareto_optimal, context.preferences)
        
        return final_selection.tool if final_selection else None
    
    def calculate_overall_score(self,
                              strategy_scores: Dict[str, float],
                              preferences: Dict[str, float]) -> float:
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        
        # é»˜è®¤æƒé‡
        default_weights = {
            'performance': 0.3,
            'cost': 0.2,
            'reliability': 0.3,
            'compatibility': 0.2
        }
        
        # æ ¹æ®åå¥½è°ƒæ•´æƒé‡
        weights = {
            strategy: default_weights.get(strategy, 0) * preferences.get(f"{strategy}_preference", 1.0)
            for strategy in strategy_scores.keys()
        }
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(weights.values())
        if total_weight > 0:
            weights = {k: v / total_weight for k, v in weights.items()}
        
        # è®¡ç®—åŠ æƒå¾—åˆ†
        overall_score = sum(
            weights.get(strategy, 0) * score
            for strategy, score in strategy_scores.items()
        )
        
        return min(overall_score, 1.0)
```

## åŠ¨æ€æ‰§è¡Œè§„åˆ’

### æ‰§è¡Œè®¡åˆ’ç”Ÿæˆå™¨

```python
class ExecutionPlanner:
    """æ‰§è¡Œè§„åˆ’å™¨"""
    
    def __init__(self):
        self.dag_builder = DAGBuilder()
        self.resource_optimizer = ResourceOptimizer()
        self.schedule_optimizer = ScheduleOptimizer()
        
    async def create_execution_plan(self,
                                  tool_selections: List[ToolSelection],
                                  task_analysis: TaskAnalysisResult,
                                  context: ExecutionContext) -> ExecutionPlan:
        """åˆ›å»ºæ‰§è¡Œè®¡åˆ’"""
        
        # 1. æ„å»ºæ‰§è¡ŒDAG
        execution_dag = await self.dag_builder.build_dag(
            tool_selections, task_analysis.dependencies
        )
        
        # 2. èµ„æºåˆ†é…ä¼˜åŒ–
        resource_allocation = await self.resource_optimizer.optimize_allocation(
            execution_dag, task_analysis.resource_requirements, context.resource_limits
        )
        
        # 3. æ‰§è¡Œè°ƒåº¦ä¼˜åŒ–
        execution_schedule = await self.schedule_optimizer.optimize_schedule(
            execution_dag, resource_allocation, context.time_constraints
        )
        
        # 4. ç”Ÿæˆæ‰§è¡Œé˜¶æ®µ
        execution_phases = self.generate_execution_phases(
            execution_dag, execution_schedule
        )
        
        # 5. åˆ¶å®šå®¹é”™ç­–ç•¥
        fault_tolerance_plan = self.create_fault_tolerance_plan(
            execution_phases, task_analysis.risk_factors
        )
        
        return ExecutionPlan(
            plan_id=self.generate_plan_id(),
            execution_dag=execution_dag,
            resource_allocation=resource_allocation,
            execution_schedule=execution_schedule,
            execution_phases=execution_phases,
            fault_tolerance_plan=fault_tolerance_plan,
            estimated_completion_time=execution_schedule.total_duration
        )
    
    def generate_execution_phases(self,
                                dag: ExecutionDAG,
                                schedule: ExecutionSchedule) -> List[ExecutionPhase]:
        """ç”Ÿæˆæ‰§è¡Œé˜¶æ®µ"""
        
        phases = []
        
        # æŒ‰æ‹“æ‰‘æ’åºåˆ†ç»„
        topological_groups = dag.get_topological_groups()
        
        for group_index, tool_group in enumerate(topological_groups):
            phase = ExecutionPhase(
                phase_id=f"phase_{group_index}",
                tools=tool_group,
                start_time=schedule.get_group_start_time(group_index),
                estimated_duration=schedule.get_group_duration(group_index),
                parallel_execution=len(tool_group) > 1,
                dependencies=[f"phase_{i}" for i in range(group_index)]
            )
            phases.append(phase)
        
        return phases
    
    def create_fault_tolerance_plan(self,
                                  execution_phases: List[ExecutionPhase],
                                  risk_factors: List[str]) -> FaultTolerancePlan:
        """åˆ›å»ºå®¹é”™è®¡åˆ’"""
        
        strategies = []
        
        for phase in execution_phases:
            phase_strategies = []
            
            # ä¸ºæ¯ä¸ªå·¥å…·åˆ¶å®šå®¹é”™ç­–ç•¥
            for tool in phase.tools:
                tool_strategy = self.create_tool_fault_strategy(tool, risk_factors)
                phase_strategies.append(tool_strategy)
            
            strategies.append(PhaseStrategy(
                phase_id=phase.phase_id,
                tool_strategies=phase_strategies,
                rollback_plan=self.create_rollback_plan(phase),
                retry_policy=self.create_retry_policy(phase)
            ))
        
        return FaultTolerancePlan(
            phase_strategies=strategies,
            global_timeout=sum(phase.estimated_duration for phase in execution_phases) * 1.5,
            circuit_breaker_config=self.create_circuit_breaker_config(risk_factors)
        )
```

## å¹¶å‘æ‰§è¡Œè°ƒåº¦

### è°ƒåº¦ç®¡ç†å™¨

```python
class ScheduleManager:
    """è°ƒåº¦ç®¡ç†å™¨"""
    
    def __init__(self, resource_pool):
        self.resource_pool = resource_pool
        self.active_executions = {}
        self.execution_queue = asyncio.Queue()
        self.worker_pool = WorkerPool(max_workers=10)
        
    async def execute_plan(self, execution_plan: ExecutionPlan) -> ExecutionResult:
        """æ‰§è¡Œè®¡åˆ’"""
        
        try:
            # 1. åˆå§‹åŒ–æ‰§è¡ŒçŠ¶æ€
            execution_state = ExecutionState(
                plan_id=execution_plan.plan_id,
                current_phase=0,
                completed_phases=[],
                failed_phases=[],
                start_time=datetime.utcnow()
            )
            
            self.active_executions[execution_plan.plan_id] = execution_state
            
            # 2. é€é˜¶æ®µæ‰§è¡Œ
            for phase in execution_plan.execution_phases:
                phase_result = await self.execute_phase(phase, execution_plan, execution_state)
                
                if phase_result.success:
                    execution_state.completed_phases.append(phase.phase_id)
                    execution_state.current_phase += 1
                else:
                    execution_state.failed_phases.append(phase.phase_id)
                    
                    # æ‰§è¡Œå®¹é”™ç­–ç•¥
                    recovery_result = await self.execute_fault_recovery(
                        phase, phase_result, execution_plan.fault_tolerance_plan
                    )
                    
                    if not recovery_result.recovered:
                        # æ— æ³•æ¢å¤ï¼Œæ‰§è¡Œå¤±è´¥
                        return ExecutionResult(
                            success=False,
                            error_message=f"Phase {phase.phase_id} failed and could not recover",
                            execution_state=execution_state
                        )
            
            # 3. æ‰§è¡ŒæˆåŠŸ
            execution_state.end_time = datetime.utcnow()
            execution_state.duration = (execution_state.end_time - execution_state.start_time).total_seconds()
            
            return ExecutionResult(
                success=True,
                execution_state=execution_state,
                results=self.collect_execution_results(execution_state)
            )
            
        except Exception as e:
            return ExecutionResult(
                success=False,
                error_message=str(e),
                execution_state=execution_state
            )
        finally:
            # æ¸…ç†æ‰§è¡ŒçŠ¶æ€
            if execution_plan.plan_id in self.active_executions:
                del self.active_executions[execution_plan.plan_id]
    
    async def execute_phase(self,
                          phase: ExecutionPhase,
                          execution_plan: ExecutionPlan,
                          execution_state: ExecutionState) -> PhaseResult:
        """æ‰§è¡Œå•ä¸ªé˜¶æ®µ"""
        
        if phase.parallel_execution and len(phase.tools) > 1:
            # å¹¶è¡Œæ‰§è¡Œ
            return await self.execute_parallel_phase(phase, execution_plan, execution_state)
        else:
            # ä¸²è¡Œæ‰§è¡Œ
            return await self.execute_sequential_phase(phase, execution_plan, execution_state)
    
    async def execute_parallel_phase(self,
                                   phase: ExecutionPhase,
                                   execution_plan: ExecutionPlan,
                                   execution_state: ExecutionState) -> PhaseResult:
        """å¹¶è¡Œæ‰§è¡Œé˜¶æ®µ"""
        
        # åˆ›å»ºå¹¶å‘æ‰§è¡Œä»»åŠ¡
        execution_tasks = []
        for tool in phase.tools:
            task = asyncio.create_task(
                self.execute_tool_with_monitoring(tool, execution_plan, execution_state)
            )
            execution_tasks.append(task)
        
        try:
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            tool_results = await asyncio.gather(*execution_tasks, return_exceptions=True)
            
            # åˆ†ææ‰§è¡Œç»“æœ
            successful_results = []
            failed_results = []
            
            for tool, result in zip(phase.tools, tool_results):
                if isinstance(result, Exception):
                    failed_results.append(ToolExecutionResult(
                        tool=tool,
                        success=False,
                        error=str(result)
                    ))
                else:
                    successful_results.append(result)
            
            # åˆ¤æ–­é˜¶æ®µæ˜¯å¦æˆåŠŸ
            success = len(failed_results) == 0
            
            return PhaseResult(
                phase_id=phase.phase_id,
                success=success,
                successful_tools=successful_results,
                failed_tools=failed_results,
                duration=(datetime.utcnow() - phase.start_time).total_seconds()
            )
            
        except Exception as e:
            return PhaseResult(
                phase_id=phase.phase_id,
                success=False,
                error_message=str(e)
            )
```

## æœ¬èŠ‚æ€»ç»“

æœ¬èŠ‚æ·±å…¥ä»‹ç»äº†æ™ºèƒ½å·¥å…·ç¼–æ’å¼•æ“çš„è®¾è®¡ä¸å®ç°ï¼š

### ğŸ¯ æ ¸å¿ƒæŠ€æœ¯ç‰¹ç‚¹
1. **æ™ºèƒ½ä»»åŠ¡ç†è§£**ï¼šåŸºäºLLMçš„è¯­ä¹‰åˆ†æå’Œå¤æ‚åº¦è¯„ä¼°
2. **å¤šç›®æ ‡å·¥å…·é€‰æ‹©**ï¼šç»¼åˆæ€§èƒ½ã€æˆæœ¬ã€å¯é æ€§çš„æ™ºèƒ½é€‰æ‹©
3. **åŠ¨æ€æ‰§è¡Œè§„åˆ’**ï¼šDAGæ„å»ºå’Œèµ„æºä¼˜åŒ–çš„æ‰§è¡Œè®¡åˆ’
4. **å¹¶å‘è°ƒåº¦ç®¡ç†**ï¼šæ”¯æŒå¹¶è¡Œå’Œä¸²è¡Œçš„çµæ´»æ‰§è¡Œè°ƒåº¦

### ğŸ”§ å…³é”®ç®—æ³•å®ç°
- ä»»åŠ¡è¯­ä¹‰åˆ†æå’Œå¤æ‚åº¦è¯„ä¼°ç®—æ³•
- å¤šç­–ç•¥å·¥å…·é€‰æ‹©å’Œå¸•ç´¯æ‰˜ä¼˜åŒ–ç®—æ³•
- DAGæ„å»ºå’Œæ‹“æ‰‘æ’åºè°ƒåº¦ç®—æ³•
- å®¹é”™æ¢å¤å’Œå¼‚å¸¸å¤„ç†ç®—æ³•

### ğŸš€ åˆ›æ–°ä¼˜åŠ¿
- **æ™ºèƒ½åŒ–**ï¼šä»è§„åˆ™ç¼–æ’å‡çº§ä¸ºAIé©±åŠ¨ç¼–æ’
- **è‡ªé€‚åº”**ï¼šåŠ¨æ€è°ƒæ•´æ‰§è¡Œç­–ç•¥å’Œèµ„æºåˆ†é…
- **é«˜æ•ˆæ€§**ï¼šå¹¶å‘æ‰§è¡Œå’Œèµ„æºä¼˜åŒ–æå‡æ€§èƒ½
- **å¯é æ€§**ï¼šå®Œå–„çš„å®¹é”™æœºåˆ¶å’Œå¼‚å¸¸å¤„ç†

---

**ä¸‹ä¸€æ­¥å­¦ä¹ **ï¼šæŒæ¡äº†æ™ºèƒ½ç¼–æ’çš„æ ¸å¿ƒæœºåˆ¶åï¼Œæˆ‘ä»¬å°†åœ¨4.3.4èŠ‚å­¦ä¹ å·¥å…·åˆ›é€ å¼•æ“çš„è®¾è®¡åŸç†ï¼Œäº†è§£å¦‚ä½•åŠ¨æ€ç”Ÿæˆæ»¡è¶³ç‰¹å®šéœ€æ±‚çš„æ–°å·¥å…·ã€‚

> **ğŸ’¡ å®è·µè¦ç‚¹**ï¼šæ™ºèƒ½ç¼–æ’çš„å…³é”®åœ¨äºå¹³è¡¡è‡ªåŠ¨åŒ–å’Œå¯æ§æ€§ï¼Œå»ºè®®åœ¨å®é™…åº”ç”¨ä¸­é€æ­¥å¢åŠ æ™ºèƒ½åŒ–ç¨‹åº¦ï¼Œç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é¢„æµ‹æ€§ã€‚
