# 2.2.7 性能监控与异步编程调优

## 学习目标

建立AI应用异步性能的监控体系，掌握异步编程的性能调优方法与问题诊断技巧。

## 2.2.7.1 异步性能监控指标体系

### 关键性能指标（KPIs）

在AI应用的异步编程中，需要监控以下关键指标：

1. **吞吐量指标**
   - 每秒处理的任务数（TPS/QPS）
   - 并发处理的任务数量
   - 任务完成率

2. **延迟指标**
   - 任务响应时间（P50、P95、P99）
   - 队列等待时间
   - 端到端处理延迟

3. **资源利用率**
   - CPU使用率
   - 内存占用率
   - 线程池利用率
   - 连接池使用率

4. **错误率指标**
   - 任务失败率
   - 超时率
   - 重试率

### 监控指标采集框架

```java
// AsyncMetricsCollector.java - 异步指标收集器
@Component
public class AsyncMetricsCollector {
    
    private final MeterRegistry meterRegistry;
    private final Timer.Sample currentSample;
    
    // 定义各种指标
    private final Counter taskStartCounter;
    private final Counter taskCompleteCounter;
    private final Counter taskFailureCounter;
    private final Timer taskProcessingTimer;
    private final Gauge activeTasksGauge;
    private final Gauge threadPoolUtilizationGauge;
    
    public AsyncMetricsCollector(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        initializeMetrics();
    }
    
    private void initializeMetrics() {
        taskStartCounter = Counter.builder("ai.task.started")
            .description("Total number of AI tasks started")
            .tag("service", "ai-processor")
            .register(meterRegistry);
        
        taskCompleteCounter = Counter.builder("ai.task.completed")
            .description("Total number of AI tasks completed")
            .tag("service", "ai-processor")
            .register(meterRegistry);
        
        taskFailureCounter = Counter.builder("ai.task.failed")
            .description("Total number of AI tasks failed")
            .tag("service", "ai-processor")
            .register(meterRegistry);
        
        taskProcessingTimer = Timer.builder("ai.task.processing.time")
            .description("AI task processing time")
            .tag("service", "ai-processor")
            .register(meterRegistry);
        
        activeTasksGauge = Gauge.builder("ai.task.active")
            .description("Number of currently active AI tasks")
            .register(meterRegistry, this, AsyncMetricsCollector::getActiveTaskCount);
        
        threadPoolUtilizationGauge = Gauge.builder("ai.threadpool.utilization")
            .description("Thread pool utilization percentage")
            .register(meterRegistry, this, AsyncMetricsCollector::getThreadPoolUtilization);
    }
    
    /**
     * 记录任务开始
     */
    public TaskMetricsContext recordTaskStart(String taskType) {
        taskStartCounter.increment(Tags.of("type", taskType));
        Timer.Sample sample = Timer.start(meterRegistry);
        
        return new TaskMetricsContext(taskType, sample);
    }
    
    /**
     * 记录任务完成
     */
    public void recordTaskComplete(TaskMetricsContext context) {
        taskCompleteCounter.increment(Tags.of("type", context.getTaskType()));
        context.getSample().stop(taskProcessingTimer.withTags("type", context.getTaskType()));
    }
    
    /**
     * 记录任务失败
     */
    public void recordTaskFailure(TaskMetricsContext context, String errorType) {
        taskFailureCounter.increment(Tags.of(
            "type", context.getTaskType(),
            "error", errorType
        ));
        context.getSample().stop(taskProcessingTimer.withTags("type", context.getTaskType()));
    }
    
    /**
     * 获取活跃任务数量
     */
    private double getActiveTaskCount() {
        // 从任务管理器获取活跃任务数
        return TaskManager.getInstance().getActiveTaskCount();
    }
    
    /**
     * 获取线程池利用率
     */
    private double getThreadPoolUtilization() {
        ThreadPoolExecutor executor = ThreadUtil.getExecutor();
        if (executor != null) {
            return (double) executor.getActiveCount() / executor.getMaximumPoolSize() * 100;
        }
        return 0;
    }
    
    /**
     * 记录自定义指标
     */
    public void recordCustomMetric(String metricName, double value, Tags tags) {
        meterRegistry.gauge(metricName, tags, value);
    }
}

// TaskMetricsContext.java - 任务指标上下文
public class TaskMetricsContext {
    private final String taskType;
    private final Timer.Sample sample;
    private final long startTime;
    
    public TaskMetricsContext(String taskType, Timer.Sample sample) {
        this.taskType = taskType;
        this.sample = sample;
        this.startTime = System.currentTimeMillis();
    }
    
    // getters...
}

// 使用示例
@Service
public class MonitoredAIService {
    
    private final AsyncMetricsCollector metricsCollector;
    
    public CompletableFuture<String> processAITaskAsync(AITask task) {
        TaskMetricsContext context = metricsCollector.recordTaskStart(task.getType());
        
        return CompletableFuture.supplyAsync(() -> {
            try {
                // AI处理逻辑
                String result = performAIProcessing(task);
                metricsCollector.recordTaskComplete(context);
                return result;
                
            } catch (Exception e) {
                metricsCollector.recordTaskFailure(context, e.getClass().getSimpleName());
                throw e;
            }
        });
    }
}
```

### Python异步性能监控

```python
# async_metrics.py - Python异步性能监控
import asyncio
import time
import psutil
import logging
from typing import Dict, Any, Optional
from dataclasses import dataclass
from collections import defaultdict, deque
import threading

@dataclass
class TaskMetrics:
    task_id: str
    task_type: str
    start_time: float
    end_time: Optional[float] = None
    success: bool = True
    error_type: Optional[str] = None

class AsyncMetricsCollector:
    """异步指标收集器"""
    
    def __init__(self, collection_interval: int = 10):
        self.collection_interval = collection_interval
        self.active_tasks: Dict[str, TaskMetrics] = {}
        self.completed_tasks: deque = deque(maxlen=10000)  # 保留最近10000个任务
        
        # 统计指标
        self.task_counters = defaultdict(int)
        self.error_counters = defaultdict(int)
        self.response_times = defaultdict(list)
        
        self.running = False
        self._lock = threading.Lock()
    
    async def start_collection(self):
        """开始指标收集"""
        self.running = True
        logger.info("Started async metrics collection")
        
        while self.running:
            try:
                await self._collect_metrics()
                await asyncio.sleep(self.collection_interval)
            except Exception as e:
                logger.error(f"Metrics collection error: {e}")
                await asyncio.sleep(1)
    
    def record_task_start(self, task_id: str, task_type: str) -> TaskMetrics:
        """记录任务开始"""
        metrics = TaskMetrics(
            task_id=task_id,
            task_type=task_type,
            start_time=time.time()
        )
        
        with self._lock:
            self.active_tasks[task_id] = metrics
            self.task_counters[f"{task_type}_started"] += 1
        
        return metrics
    
    def record_task_complete(self, task_id: str, success: bool = True, error_type: str = None):
        """记录任务完成"""
        with self._lock:
            if task_id in self.active_tasks:
                metrics = self.active_tasks[task_id]
                metrics.end_time = time.time()
                metrics.success = success
                metrics.error_type = error_type
                
                # 更新统计
                task_type = metrics.task_type
                if success:
                    self.task_counters[f"{task_type}_completed"] += 1
                else:
                    self.task_counters[f"{task_type}_failed"] += 1
                    self.error_counters[error_type] += 1
                
                # 记录响应时间
                response_time = metrics.end_time - metrics.start_time
                self.response_times[task_type].append(response_time)
                
                # 移动到完成队列
                self.completed_tasks.append(metrics)
                del self.active_tasks[task_id]
    
    async def _collect_metrics(self):
        """收集系统指标"""
        current_time = time.time()
        
        # 收集系统资源使用情况
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        
        # 收集任务指标
        with self._lock:
            active_count = len(self.active_tasks)
            task_stats = dict(self.task_counters)
        
        # 计算性能指标
        metrics_summary = {
            "timestamp": current_time,
            "system": {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "memory_used_mb": memory.used / (1024 * 1024),
                "memory_available_mb": memory.available / (1024 * 1024)
            },
            "tasks": {
                "active_count": active_count,
                "counters": task_stats,
                "response_times": self._calculate_response_time_stats()
            }
        }
        
        # 发送到监控系统
        await self._emit_metrics(metrics_summary)
    
    def _calculate_response_time_stats(self) -> Dict[str, Dict[str, float]]:
        """计算响应时间统计"""
        stats = {}
        
        for task_type, times in self.response_times.items():
            if times:
                sorted_times = sorted(times[-100:])  # 只使用最近100个样本
                count = len(sorted_times)
                
                stats[task_type] = {
                    "count": count,
                    "min": min(sorted_times),
                    "max": max(sorted_times),
                    "avg": sum(sorted_times) / count,
                    "p50": sorted_times[int(count * 0.5)],
                    "p95": sorted_times[int(count * 0.95)],
                    "p99": sorted_times[int(count * 0.99)]
                }
        
        return stats
    
    async def _emit_metrics(self, metrics: Dict[str, Any]):
        """发送指标到监控系统"""
        # 这里可以集成到Prometheus、InfluxDB等监控系统
        logger.debug(f"Metrics: {metrics}")
        
        # 如果CPU使用率过高，发送告警
        if metrics["system"]["cpu_percent"] > 80:
            await self._send_alert("High CPU usage", metrics["system"]["cpu_percent"])
        
        # 如果有大量失败任务，发送告警
        failed_tasks = sum(v for k, v in metrics["tasks"]["counters"].items() if "failed" in k)
        total_tasks = sum(v for k, v in metrics["tasks"]["counters"].items() if "completed" in k or "failed" in k)
        
        if total_tasks > 0 and failed_tasks / total_tasks > 0.1:  # 失败率超过10%
            await self._send_alert("High task failure rate", failed_tasks / total_tasks)
    
    async def _send_alert(self, message: str, value: float):
        """发送告警"""
        logger.warning(f"ALERT: {message} - {value}")
    
    def get_current_stats(self) -> Dict[str, Any]:
        """获取当前统计信息"""
        with self._lock:
            return {
                "active_tasks": len(self.active_tasks),
                "completed_tasks": len(self.completed_tasks),
                "task_counters": dict(self.task_counters),
                "error_counters": dict(self.error_counters),
                "response_time_stats": self._calculate_response_time_stats()
            }

# 监控装饰器
def monitor_async_task(task_type: str, metrics_collector: AsyncMetricsCollector):
    """异步任务监控装饰器"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            task_id = f"{task_type}_{int(time.time() * 1000)}"
            metrics_collector.record_task_start(task_id, task_type)
            
            try:
                result = await func(*args, **kwargs)
                metrics_collector.record_task_complete(task_id, success=True)
                return result
            except Exception as e:
                metrics_collector.record_task_complete(
                    task_id, 
                    success=False, 
                    error_type=e.__class__.__name__
                )
                raise
        
        return wrapper
    return decorator

# 使用示例
metrics_collector = AsyncMetricsCollector()

@monitor_async_task("code_interpreter", metrics_collector)
async def process_code_task(task_data):
    """处理代码任务"""
    await asyncio.sleep(2)  # 模拟处理时间
    return "Code executed successfully"

@monitor_async_task("deep_search", metrics_collector)
async def process_search_task(query):
    """处理搜索任务"""
    await asyncio.sleep(1)  # 模拟处理时间
    return f"Search results for: {query}"
```

## 2.2.7.2 性能瓶颈识别与分析

### 常见的异步编程性能瓶颈

1. **线程池配置不当**
   - 线程数量过少导致任务排队
   - 线程数量过多导致上下文切换开销
   - 工作队列配置不合理

2. **资源竞争**
   - 数据库连接池耗尽
   - 内存不足导致频繁GC
   - 磁盘I/O瓶颈

3. **异步链路问题**
   - CompletableFuture链过长
   - 异步回调地狱
   - 不合理的同步等待

### 性能分析工具集成

```java
// PerformanceAnalyzer.java - 性能分析器
@Component
public class PerformanceAnalyzer {
    
    private final MeterRegistry meterRegistry;
    private final ScheduledExecutorService analysisScheduler = Executors.newScheduledThreadPool(2);
    
    @PostConstruct
    public void startAnalysis() {
        // 每分钟分析一次性能
        analysisScheduler.scheduleAtFixedRate(this::analyzePerformance, 0, 60, TimeUnit.SECONDS);
        
        // 每10秒检查一次异常情况
        analysisScheduler.scheduleAtFixedRate(this::detectAnomalies, 0, 10, TimeUnit.SECONDS);
    }
    
    private void analyzePerformance() {
        try {
            PerformanceReport report = generatePerformanceReport();
            
            // 检查性能问题
            checkThreadPoolUtilization(report);
            checkMemoryUsage(report);
            checkResponseTimes(report);
            checkErrorRates(report);
            
            // 生成优化建议
            List<OptimizationSuggestion> suggestions = generateOptimizationSuggestions(report);
            
            if (!suggestions.isEmpty()) {
                logger.info("Performance optimization suggestions: {}", suggestions);
            }
            
        } catch (Exception e) {
            logger.error("Performance analysis failed", e);
        }
    }
    
    private PerformanceReport generatePerformanceReport() {
        MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();
        ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();
        
        return PerformanceReport.builder()
            .timestamp(System.currentTimeMillis())
            .heapMemoryUsage(memoryBean.getHeapMemoryUsage())
            .nonHeapMemoryUsage(memoryBean.getNonHeapMemoryUsage())
            .threadCount(threadBean.getThreadCount())
            .peakThreadCount(threadBean.getPeakThreadCount())
            .taskMetrics(getTaskMetrics())
            .build();
    }
    
    private void checkThreadPoolUtilization(PerformanceReport report) {
        ThreadPoolExecutor executor = ThreadUtil.getExecutor();
        if (executor != null) {
            double utilization = (double) executor.getActiveCount() / executor.getMaximumPoolSize();
            
            if (utilization > 0.9) {
                logger.warn("Thread pool utilization is high: {:.2f}%. Consider increasing pool size.", utilization * 100);
            } else if (utilization < 0.1) {
                logger.info("Thread pool utilization is low: {:.2f}%. Consider reducing pool size.", utilization * 100);
            }
            
            // 检查队列长度
            int queueSize = executor.getQueue().size();
            if (queueSize > 100) {
                logger.warn("Task queue size is large: {}. This may indicate thread pool bottleneck.", queueSize);
            }
        }
    }
    
    private void checkMemoryUsage(PerformanceReport report) {
        MemoryUsage heapUsage = report.getHeapMemoryUsage();
        double memoryUtilization = (double) heapUsage.getUsed() / heapUsage.getMax();
        
        if (memoryUtilization > 0.8) {
            logger.warn("Memory usage is high: {:.2f}%. Consider increasing heap size or optimizing memory usage.", 
                       memoryUtilization * 100);
        }
        
        // 检查GC压力
        List<GarbageCollectorMXBean> gcBeans = ManagementFactory.getGarbageCollectorMXBeans();
        for (GarbageCollectorMXBean gcBean : gcBeans) {
            long gcTime = gcBean.getCollectionTime();
            long gcCount = gcBean.getCollectionCount();
            
            if (gcCount > 0) {
                double avgGcTime = (double) gcTime / gcCount;
                if (avgGcTime > 100) { // 平均GC时间超过100ms
                    logger.warn("GC {} average time is high: {:.2f}ms", gcBean.getName(), avgGcTime);
                }
            }
        }
    }
    
    private void checkResponseTimes(PerformanceReport report) {
        Map<String, ResponseTimeStats> taskMetrics = report.getTaskMetrics();
        
        for (Map.Entry<String, ResponseTimeStats> entry : taskMetrics.entrySet()) {
            String taskType = entry.getKey();
            ResponseTimeStats stats = entry.getValue();
            
            if (stats.getP95() > 5000) { // P95响应时间超过5秒
                logger.warn("Task type {} has high P95 response time: {:.2f}ms", 
                           taskType, stats.getP95());
            }
            
            if (stats.getP99() > 10000) { // P99响应时间超过10秒
                logger.warn("Task type {} has very high P99 response time: {:.2f}ms", 
                           taskType, stats.getP99());
            }
        }
    }
    
    private List<OptimizationSuggestion> generateOptimizationSuggestions(PerformanceReport report) {
        List<OptimizationSuggestion> suggestions = new ArrayList<>();
        
        // 基于分析结果生成优化建议
        ThreadPoolExecutor executor = ThreadUtil.getExecutor();
        if (executor != null) {
            double utilization = (double) executor.getActiveCount() / executor.getMaximumPoolSize();
            
            if (utilization > 0.9) {
                suggestions.add(new OptimizationSuggestion(
                    "HIGH", 
                    "Thread Pool", 
                    "Increase thread pool size to handle high load"
                ));
            }
            
            if (executor.getQueue().size() > 50) {
                suggestions.add(new OptimizationSuggestion(
                    "MEDIUM", 
                    "Task Queue", 
                    "Consider using different queue strategy or increase processing capacity"
                ));
            }
        }
        
        return suggestions;
    }
    
    private void detectAnomalies() {
        // 检测异常情况，如死锁、内存泄漏等
        ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();
        long[] deadlockedThreads = threadBean.findDeadlockedThreads();
        
        if (deadlockedThreads != null && deadlockedThreads.length > 0) {
            logger.error("Detected {} deadlocked threads", deadlockedThreads.length);
            
            ThreadInfo[] threadInfos = threadBean.getThreadInfo(deadlockedThreads);
            for (ThreadInfo threadInfo : threadInfos) {
                logger.error("Deadlocked thread: {} - {}", threadInfo.getThreadName(), threadInfo.getThreadState());
            }
        }
    }
}
```

## 2.2.7.3 性能调优策略

### 线程池参数优化

```java
// OptimizedThreadPoolConfig.java - 优化的线程池配置
@Configuration
public class OptimizedThreadPoolConfig {
    
    @Value("${app.async.core-pool-size:10}")
    private int corePoolSize;
    
    @Value("${app.async.max-pool-size:50}")
    private int maxPoolSize;
    
    @Value("${app.async.queue-capacity:1000}")
    private int queueCapacity;
    
    @Value("${app.async.keep-alive-seconds:60}")
    private int keepAliveSeconds;
    
    @Bean("aiTaskExecutor")
    public TaskExecutor aiTaskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        
        // 核心配置
        executor.setCorePoolSize(corePoolSize);
        executor.setMaxPoolSize(maxPoolSize);
        executor.setQueueCapacity(queueCapacity);
        executor.setKeepAliveSeconds(keepAliveSeconds);
        
        // 线程命名
        executor.setThreadNamePrefix("AI-Task-");
        executor.setThreadGroupName("AI-Task-Group");
        
        // 拒绝策略：调用者运行，避免任务丢失
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        
        // 等待任务完成后再关闭
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.setAwaitTerminationSeconds(60);
        
        // 允许核心线程超时
        executor.setAllowCoreThreadTimeOut(true);
        
        executor.initialize();
        return executor;
    }
    
    @Bean("ioTaskExecutor")
    public TaskExecutor ioTaskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        
        // I/O密集型任务使用更多线程
        executor.setCorePoolSize(corePoolSize * 2);
        executor.setMaxPoolSize(maxPoolSize * 2);
        executor.setQueueCapacity(queueCapacity);
        executor.setKeepAliveSeconds(keepAliveSeconds);
        
        executor.setThreadNamePrefix("IO-Task-");
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        
        executor.initialize();
        return executor;
    }
    
    /**
     * 动态调整线程池参数
     */
    @Scheduled(fixedRate = 300000) // 每5分钟调整一次
    public void adjustThreadPoolParameters() {
        ThreadPoolTaskExecutor aiExecutor = (ThreadPoolTaskExecutor) aiTaskExecutor();
        ThreadPoolExecutor executor = aiExecutor.getThreadPoolExecutor();
        
        // 获取当前负载情况
        int activeCount = executor.getActiveCount();
        int queueSize = executor.getQueue().size();
        double utilization = (double) activeCount / executor.getMaximumPoolSize();
        
        // 动态调整策略
        if (utilization > 0.8 && queueSize > 100) {
            // 高负载时增加线程数
            int newMaxPoolSize = Math.min(executor.getMaximumPoolSize() + 10, 100);
            executor.setMaximumPoolSize(newMaxPoolSize);
            logger.info("Increased max pool size to {} due to high load", newMaxPoolSize);
            
        } else if (utilization < 0.3 && queueSize == 0) {
            // 低负载时减少线程数
            int newMaxPoolSize = Math.max(executor.getMaximumPoolSize() - 5, corePoolSize);
            executor.setMaximumPoolSize(newMaxPoolSize);
            logger.info("Decreased max pool size to {} due to low load", newMaxPoolSize);
        }
    }
}
```

### 内存优化策略

```java
// MemoryOptimizer.java - 内存优化器
@Component
public class MemoryOptimizer {
    
    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
    private final Map<String, SoftReference<Object>> cache = new ConcurrentHashMap<>();
    
    @PostConstruct
    public void startOptimization() {
        // 每分钟清理一次过期缓存
        scheduler.scheduleAtFixedRate(this::cleanupCache, 0, 60, TimeUnit.SECONDS);
        
        // 每10分钟执行一次内存优化
        scheduler.scheduleAtFixedRate(this::optimizeMemory, 0, 600, TimeUnit.SECONDS);
    }
    
    private void cleanupCache() {
        int removed = 0;
        Iterator<Map.Entry<String, SoftReference<Object>>> iterator = cache.entrySet().iterator();
        
        while (iterator.hasNext()) {
            Map.Entry<String, SoftReference<Object>> entry = iterator.next();
            if (entry.getValue().get() == null) {
                iterator.remove();
                removed++;
            }
        }
        
        if (removed > 0) {
            logger.debug("Cleaned up {} expired cache entries", removed);
        }
    }
    
    private void optimizeMemory() {
        MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();
        MemoryUsage heapUsage = memoryBean.getHeapMemoryUsage();
        
        double memoryUtilization = (double) heapUsage.getUsed() / heapUsage.getMax();
        
        if (memoryUtilization > 0.7) {
            logger.info("Memory utilization is high: {:.2f}%, triggering optimization", memoryUtilization * 100);
            
            // 清理软引用缓存
            cache.clear();
            
            // 建议JVM执行GC
            System.gc();
            
            // 等待GC完成后检查效果
            try {
                Thread.sleep(1000);
                MemoryUsage newHeapUsage = memoryBean.getHeapMemoryUsage();
                double newUtilization = (double) newHeapUsage.getUsed() / newHeapUsage.getMax();
                logger.info("Memory utilization after optimization: {:.2f}%", newUtilization * 100);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
    }
    
    /**
     * 内存友好的批处理
     */
    public <T, R> CompletableFuture<List<R>> processBatchMemoryEfficient(
            List<T> items, 
            Function<T, R> processor, 
            int batchSize) {
        
        return CompletableFuture.supplyAsync(() -> {
            List<R> results = new ArrayList<>();
            
            for (int i = 0; i < items.size(); i += batchSize) {
                int endIndex = Math.min(i + batchSize, items.size());
                List<T> batch = items.subList(i, endIndex);
                
                // 处理批次
                List<R> batchResults = batch.stream()
                    .map(processor)
                    .collect(Collectors.toList());
                
                results.addAll(batchResults);
                
                // 检查内存使用情况
                if ((i + batchSize) % (batchSize * 10) == 0) {
                    checkMemoryAndPause();
                }
            }
            
            return results;
        });
    }
    
    private void checkMemoryAndPause() {
        MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();
        MemoryUsage heapUsage = memoryBean.getHeapMemoryUsage();
        double memoryUtilization = (double) heapUsage.getUsed() / heapUsage.getMax();
        
        if (memoryUtilization > 0.8) {
            logger.info("High memory usage detected during batch processing: {:.2f}%, pausing...", 
                       memoryUtilization * 100);
            
            try {
                Thread.sleep(1000); // 暂停1秒让GC有机会运行
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
    }
}
```

### Python异步性能调优

```python
# async_optimizer.py - Python异步性能优化器
import asyncio
import psutil
import gc
import time
import logging
from typing import Any, Callable, List, Optional
from concurrent.futures import ThreadPoolExecutor
import weakref

class AsyncPerformanceOptimizer:
    """异步性能优化器"""
    
    def __init__(self):
        self.executor_pool_size = self._calculate_optimal_threads()
        self.executor = ThreadPoolExecutor(max_workers=self.executor_pool_size)
        self.semaphore = asyncio.Semaphore(self.executor_pool_size * 2)
        
        # 弱引用缓存，自动清理
        self.cache = weakref.WeakValueDictionary()
        
        # 性能统计
        self.task_stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'total_processing_time': 0.0
        }
        
    def _calculate_optimal_threads(self) -> int:
        """计算最优线程数"""
        cpu_count = psutil.cpu_count()
        
        # I/O密集型任务使用更多线程
        optimal_threads = min(cpu_count * 2, 20)
        
        logger.info(f"Calculated optimal thread count: {optimal_threads}")
        return optimal_threads
    
    async def optimize_concurrent_execution(self, 
                                          tasks: List[Callable],
                                          max_concurrency: Optional[int] = None) -> List[Any]:
        """优化并发执行"""
        if max_concurrency is None:
            max_concurrency = self.executor_pool_size
        
        semaphore = asyncio.Semaphore(max_concurrency)
        
        async def execute_with_semaphore(task):
            async with semaphore:
                start_time = time.time()
                try:
                    if asyncio.iscoroutinefunction(task):
                        result = await task()
                    else:
                        # CPU密集型任务放到线程池
                        loop = asyncio.get_event_loop()
                        result = await loop.run_in_executor(self.executor, task)
                    
                    # 更新统计
                    self.task_stats['completed_tasks'] += 1
                    self.task_stats['total_processing_time'] += time.time() - start_time
                    
                    return result
                    
                except Exception as e:
                    self.task_stats['failed_tasks'] += 1
                    logger.error(f"Task execution failed: {e}")
                    return None
        
        self.task_stats['total_tasks'] += len(tasks)
        
        # 执行任务
        results = await asyncio.gather(
            *[execute_with_semaphore(task) for task in tasks],
            return_exceptions=True
        )
        
        return [r for r in results if r is not None and not isinstance(r, Exception)]
    
    async def memory_efficient_batch_processing(self,
                                              items: List[Any],
                                              processor: Callable,
                                              batch_size: int = 100) -> List[Any]:
        """内存高效的批处理"""
        results = []
        
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            
            # 检查内存使用情况
            memory_percent = psutil.virtual_memory().percent
            if memory_percent > 80:
                logger.warning(f"High memory usage: {memory_percent}%. Triggering GC...")
                gc.collect()
                await asyncio.sleep(0.1)  # 让GC有时间运行
            
            # 处理批次
            if asyncio.iscoroutinefunction(processor):
                batch_results = await asyncio.gather(
                    *[processor(item) for item in batch],
                    return_exceptions=True
                )
            else:
                # 并行处理CPU密集型任务
                loop = asyncio.get_event_loop()
                batch_results = await asyncio.gather(
                    *[loop.run_in_executor(self.executor, processor, item) for item in batch],
                    return_exceptions=True
                )
            
            # 过滤异常结果
            valid_results = [r for r in batch_results if not isinstance(r, Exception)]
            results.extend(valid_results)
            
            # 在批次间暂停以避免过载
            if i + batch_size < len(items):
                await asyncio.sleep(0.01)
        
        return results
    
    async def adaptive_rate_limiting(self, 
                                   task_generator: Callable,
                                   initial_rate: float = 10.0) -> Any:
        """自适应速率限制"""
        current_rate = initial_rate
        last_adjustment = time.time()
        error_count = 0
        success_count = 0
        
        while True:
            start_time = time.time()
            
            try:
                # 执行任务
                result = await task_generator()
                success_count += 1
                error_count = 0  # 重置错误计数
                
                # 成功时逐渐增加速率
                if success_count > 10 and time.time() - last_adjustment > 10:
                    current_rate = min(current_rate * 1.1, 50.0)
                    last_adjustment = time.time()
                    logger.debug(f"Increased rate to {current_rate}")
                
                yield result
                
            except Exception as e:
                error_count += 1
                logger.warning(f"Task failed: {e}")
                
                # 错误时降低速率
                if error_count > 3:
                    current_rate = max(current_rate * 0.5, 1.0)
                    last_adjustment = time.time()
                    error_count = 0
                    logger.warning(f"Decreased rate to {current_rate} due to errors")
            
            # 根据当前速率控制执行频率
            elapsed = time.time() - start_time
            sleep_time = max(0, 1.0 / current_rate - elapsed)
            if sleep_time > 0:
                await asyncio.sleep(sleep_time)
    
    def get_performance_stats(self) -> dict:
        """获取性能统计"""
        total_tasks = self.task_stats['total_tasks']
        if total_tasks > 0:
            avg_processing_time = self.task_stats['total_processing_time'] / self.task_stats['completed_tasks']
            success_rate = self.task_stats['completed_tasks'] / total_tasks
        else:
            avg_processing_time = 0
            success_rate = 0
        
        return {
            'total_tasks': total_tasks,
            'completed_tasks': self.task_stats['completed_tasks'],
            'failed_tasks': self.task_stats['failed_tasks'],
            'success_rate': success_rate,
            'avg_processing_time': avg_processing_time,
            'current_memory_usage': psutil.virtual_memory().percent,
            'active_threads': self.executor._threads
        }
    
    async def optimize_resource_usage(self):
        """优化资源使用"""
        # 检查系统资源使用情况
        cpu_percent = psutil.cpu_percent(interval=1)
        memory_percent = psutil.virtual_memory().percent
        
        # 动态调整并发度
        if cpu_percent > 80:
            # CPU使用率高，减少并发
            new_size = max(self.executor_pool_size // 2, 1)
            logger.info(f"High CPU usage, reducing concurrency to {new_size}")
        elif cpu_percent < 30 and memory_percent < 60:
            # 资源充足，可以增加并发
            new_size = min(self.executor_pool_size * 2, 50)
            logger.info(f"Low resource usage, increasing concurrency to {new_size}")
        else:
            return
        
        # 重新创建线程池
        old_executor = self.executor
        self.executor = ThreadPoolExecutor(max_workers=new_size)
        self.executor_pool_size = new_size
        
        # 关闭旧的线程池
        old_executor.shutdown(wait=False)
    
    def cleanup(self):
        """清理资源"""
        self.executor.shutdown(wait=True)
        self.cache.clear()
        gc.collect()
```

## 2.2.7.4 APM工具集成

### 集成Prometheus监控

```java
// PrometheusMetricsConfiguration.java - Prometheus指标配置
@Configuration
public class PrometheusMetricsConfiguration {
    
    @Bean
    public MeterRegistryCustomizer<PrometheusMeterRegistry> prometheusCustomizer() {
        return registry -> {
            registry.config()
                .commonTags("application", "ai-service", "environment", "production");
        };
    }
    
    @Bean
    public TimedAspect timedAspect(MeterRegistry registry) {
        return new TimedAspect(registry);
    }
    
    @Bean
    public CountedAspect countedAspect(MeterRegistry registry) {
        return new CountedAspect(registry);
    }
    
    @Component
    public static class CustomMetrics {
        
        private final Counter aiTaskCounter;
        private final Timer aiTaskTimer;
        private final Gauge threadPoolGauge;
        
        public CustomMetrics(MeterRegistry registry) {
            this.aiTaskCounter = Counter.builder("ai_tasks_total")
                .description("Total number of AI tasks")
                .tag("status", "unknown")
                .register(registry);
            
            this.aiTaskTimer = Timer.builder("ai_task_duration")
                .description("AI task processing duration")
                .register(registry);
            
            this.threadPoolGauge = Gauge.builder("thread_pool_utilization")
                .description("Thread pool utilization percentage")
                .register(registry, this, CustomMetrics::getThreadPoolUtilization);
        }
        
        public void recordTaskSuccess(String taskType) {
            aiTaskCounter.increment(Tags.of("type", taskType, "status", "success"));
        }
        
        public void recordTaskFailure(String taskType, String errorType) {
            aiTaskCounter.increment(Tags.of("type", taskType, "status", "failure", "error", errorType));
        }
        
        public Timer.Sample startTaskTimer() {
            return Timer.start();
        }
        
        public void stopTaskTimer(Timer.Sample sample, String taskType) {
            sample.stop(aiTaskTimer.withTags("type", taskType));
        }
        
        private double getThreadPoolUtilization() {
            ThreadPoolExecutor executor = ThreadUtil.getExecutor();
            return executor != null ? 
                (double) executor.getActiveCount() / executor.getMaximumPoolSize() * 100 : 0;
        }
    }
}
```

### Grafana仪表盘配置

```json
{
  "dashboard": {
    "id": null,
    "title": "AI Application Async Performance",
    "tags": ["ai", "async", "performance"],
    "timezone": "browser",
    "panels": [
      {
        "title": "AI Task Throughput",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(ai_tasks_total[5m])",
            "legendFormat": "{{type}} - {{status}}"
          }
        ],
        "yAxes": [
          {
            "label": "Tasks/sec"
          }
        ]
      },
      {
        "title": "Response Time Percentiles",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, ai_task_duration_bucket)",
            "legendFormat": "P50"
          },
          {
            "expr": "histogram_quantile(0.95, ai_task_duration_bucket)",
            "legendFormat": "P95"
          },
          {
            "expr": "histogram_quantile(0.99, ai_task_duration_bucket)",
            "legendFormat": "P99"
          }
        ]
      },
      {
        "title": "Thread Pool Utilization",
        "type": "singlestat",
        "targets": [
          {
            "expr": "thread_pool_utilization",
            "legendFormat": "Utilization %"
          }
        ],
        "thresholds": "70,90"
      },
      {
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "jvm_memory_used_bytes{area=\"heap\"}",
            "legendFormat": "Heap Used"
          },
          {
            "expr": "jvm_memory_max_bytes{area=\"heap\"}",
            "legendFormat": "Heap Max"
          }
        ]
      }
    ]
  }
}
```

## 小结

性能监控与异步编程调优是确保AI应用高效运行的关键环节。通过建立完善的指标体系、识别性能瓶颈、实施调优策略和集成APM工具，可以持续优化应用性能。

关键要点：
1. **全面监控**：建立覆盖吞吐量、延迟、资源利用率的指标体系
2. **智能分析**：自动识别性能瓶颈和异常情况
3. **动态调优**：根据负载情况自适应调整参数
4. **工具集成**：利用Prometheus、Grafana等专业工具
5. **持续优化**：建立性能优化的闭环流程

---

**性能调优建议：**
1. 定期分析性能报告，识别优化机会
2. 建立性能基线，监控性能回归
3. 结合业务场景进行针对性优化
4. 重视长期性能趋势分析
5. 建立性能优化的最佳实践库
