# 2.3.4 å·¥å…·è°ƒç”¨çŠ¶æ€æœºä¸å¼‚æ­¥æ‰§è¡Œç®¡ç†

## å­¦ä¹ ç›®æ ‡

ğŸ—ï¸ **æ¶æ„è®¾è®¡å±‚é¢**
- æŒæ¡å·¥å…·è°ƒç”¨çš„ç”Ÿå‘½å‘¨æœŸçŠ¶æ€ç®¡ç†ï¼ˆè°ƒç”¨å‰ã€æ‰§è¡Œä¸­ã€å®Œæˆåã€å¼‚å¸¸å¤„ç†ï¼‰
- ç†è§£å¼‚æ­¥æ‰§è¡Œç®¡ç†çš„çŠ¶æ€æœºè®¾è®¡æ¨¡å¼
- æŒæ¡å·¥å…·çŠ¶æ€æœºä¸AgentçŠ¶æ€æœºçš„åè°ƒæœºåˆ¶

âš™ï¸ **å·¥ç¨‹å®ç°å±‚é¢**
- å­¦ä¼šå®ç°ä»£ç è§£é‡Šå™¨çš„åˆ†æ­¥æ‰§è¡ŒçŠ¶æ€æœº
- ç†è§£æ·±åº¦æœç´¢å·¥å…·çš„å¤šè½®è¿­ä»£çŠ¶æ€æ§åˆ¶
- æŒæ¡å·¥å…·æ‰§è¡Œç»“æœçš„çŠ¶æ€æŒä¹…åŒ–ä¸ç¼“å­˜ç­–ç•¥

ğŸš€ **ä¼ä¸šçº§åº”ç”¨**
- æŒæ¡å·¥å…·æ‰§è¡Œçš„ç›‘æ§ã€å‘Šè­¦å’Œæ•…éšœæ¢å¤æœºåˆ¶
- ç†è§£é«˜å¹¶å‘åœºæ™¯ä¸‹çš„å·¥å…·çŠ¶æ€ç®¡ç†ç­–ç•¥

## å¼•è¨€

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†Agentçº§çŠ¶æ€æœºï¼ˆ2.3.2ï¼‰å’Œä»»åŠ¡æ‰§è¡ŒçŠ¶æ€æœºï¼ˆ2.3.3ï¼‰çš„è®¾è®¡ã€‚ç°åœ¨æˆ‘ä»¬å°†æ·±å…¥åˆ°æ›´ç»†ç²’åº¦çš„å±‚é¢â€”â€”å·¥å…·è°ƒç”¨çŠ¶æ€æœºï¼Œå®ƒæ˜¯æ•´ä¸ªAGIåº”ç”¨çŠ¶æ€ç®¡ç†ä½“ç³»ä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚

å·¥å…·è°ƒç”¨æ˜¯AIåº”ç”¨ä¸­æœ€å¤æ‚çš„å¼‚æ­¥æ“ä½œä¹‹ä¸€ï¼Œæ¶‰åŠå¤šç§å¤–éƒ¨ç³»ç»Ÿçš„äº¤äº’ã€é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ã€ä»¥åŠå¤æ‚çš„ç»“æœå¤„ç†é€»è¾‘ã€‚å®ƒä½“ç°äº†2.3.1ç« èŠ‚ä¸­æåˆ°çš„**çŠ¶æ€æœºåˆ†å±‚ä¸ç»„åˆ**è®¾è®¡åŸåˆ™ï¼šå·¥å…·çŠ¶æ€æœºä½œä¸ºå­çŠ¶æ€æœºï¼Œéœ€è¦ä¸AgentçŠ¶æ€æœºå’Œä»»åŠ¡çŠ¶æ€æœºåè°ƒå·¥ä½œã€‚

åœ¨JoyAgent-JDGenieé¡¹ç›®ä¸­ï¼Œå·¥å…·ç³»ç»Ÿæ”¯æŒä»£ç è§£é‡Šå™¨ã€æ·±åº¦æœç´¢ã€æ–‡ä»¶æ“ä½œç­‰å¤šç§å·¥å…·ï¼Œæ¯ç§å·¥å…·éƒ½æœ‰å…¶ç‹¬ç‰¹çš„æ‰§è¡Œæ¨¡å¼å’ŒçŠ¶æ€ç®¡ç†éœ€æ±‚ã€‚æœ¬èŠ‚å°†è¯¦ç»†åˆ†æå·¥å…·è°ƒç”¨çŠ¶æ€æœºçš„è®¾è®¡åŸç†å’Œå®ç°æ–¹æ¡ˆï¼Œå±•ç¤ºå¦‚ä½•åº”ç”¨å‰é¢å­¦åˆ°çš„SOLIDåŸåˆ™æ¥æ„å»ºå¯æ‰©å±•çš„å¼‚æ­¥æ‰§è¡Œç®¡ç†æ¶æ„ã€‚

## 1. å·¥å…·è°ƒç”¨ç”Ÿå‘½å‘¨æœŸçŠ¶æ€è®¾è®¡

åœ¨è®¾è®¡å·¥å…·è°ƒç”¨çŠ¶æ€æœºæ—¶ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘å·¥å…·æ‰§è¡Œçš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚ä¸åŒäºAgentçŠ¶æ€çš„4ä¸ªç®€å•çŠ¶æ€ï¼Œå·¥å…·æ‰§è¡Œéœ€è¦æ›´ç»†ç²’åº¦çš„çŠ¶æ€æ§åˆ¶ï¼Œä»¥æ”¯æŒå¼‚æ­¥æ‰§è¡Œã€æµå¼è¾“å‡ºã€é”™è¯¯é‡è¯•ç­‰é«˜çº§ç‰¹æ€§ã€‚è¿™æ­£ä½“ç°äº†2.3.1ç« èŠ‚ä¸­æåˆ°çš„**çŠ¶æ€ç²’åº¦é€‰æ‹©**åŸåˆ™ã€‚

### 1.1 å·¥å…·æ‰§è¡ŒçŠ¶æ€æšä¸¾

```java
/**
 * å·¥å…·æ‰§è¡ŒçŠ¶æ€æšä¸¾
 */
public enum ToolExecutionState {
    PENDING("pending"),         // å¾…æ‰§è¡Œï¼šå·¥å…·è°ƒç”¨è¯·æ±‚å·²åˆ›å»ºï¼Œç­‰å¾…æ‰§è¡Œ
    INITIALIZING("initializing"), // åˆå§‹åŒ–ä¸­ï¼šæ­£åœ¨å‡†å¤‡æ‰§è¡Œç¯å¢ƒ
    RUNNING("running"),         // æ‰§è¡Œä¸­ï¼šå·¥å…·æ­£åœ¨è¿è¡Œ
    STREAMING("streaming"),     // æµå¼è¾“å‡ºï¼šå·¥å…·äº§ç”Ÿå®æ—¶è¾“å‡º
    COMPLETED("completed"),     // å·²å®Œæˆï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸå®Œæ¯•
    FAILED("failed"),          // æ‰§è¡Œå¤±è´¥ï¼šå·¥å…·æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯
    TIMEOUT("timeout"),        // æ‰§è¡Œè¶…æ—¶ï¼šå·¥å…·æ‰§è¡Œè¶…è¿‡æœ€å¤§æ—¶é—´é™åˆ¶
    CANCELLED("cancelled"),    // å·²å–æ¶ˆï¼šå·¥å…·æ‰§è¡Œè¢«ç”¨æˆ·æˆ–ç³»ç»Ÿå–æ¶ˆ
    RETRYING("retrying");      // é‡è¯•ä¸­ï¼šå·¥å…·æ‰§è¡Œå¤±è´¥åæ­£åœ¨é‡è¯•
    
    private final String value;
    
    ToolExecutionState(String value) {
        this.value = value;
    }
    
    /**
     * åˆ¤æ–­æ˜¯å¦ä¸ºç»ˆæ€
     */
    public boolean isTerminal() {
        return this == COMPLETED || this == FAILED || 
               this == TIMEOUT || this == CANCELLED;
    }
    
    /**
     * åˆ¤æ–­æ˜¯å¦ä¸ºæ´»è·ƒçŠ¶æ€
     */
    public boolean isActive() {
        return this == RUNNING || this == STREAMING || this == RETRYING;
    }
}
```

### 1.2 å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡

```java
/**
 * å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡ - ç»´æŠ¤å·¥å…·æ‰§è¡Œè¿‡ç¨‹ä¸­çš„çŠ¶æ€ä¿¡æ¯
 */
@Data
@Builder
@AllArgsConstructor
@NoArgsConstructor
public class ToolExecutionContext {
    private String toolCallId;
    private String toolName;
    private String sessionId;
    private String requestId;
    
    // æ‰§è¡ŒçŠ¶æ€
    private ToolExecutionState state = ToolExecutionState.PENDING;
    private long startTime;
    private long endTime;
    private long lastUpdateTime;
    
    // æ‰§è¡Œå‚æ•°
    private Map<String, Object> parameters = new HashMap<>();
    private Map<String, Object> metadata = new HashMap<>();
    
    // æ‰§è¡Œç»“æœ
    private StringBuilder outputBuffer = new StringBuilder();
    private String finalResult;
    private String errorMessage;
    private Throwable exception;
    
    // æµå¼è¾“å‡ºæ§åˆ¶
    private boolean streamingEnabled = false;
    private volatile boolean cancelled = false;
    private CountDownLatch completionLatch = new CountDownLatch(1);
    
    // é‡è¯•æœºåˆ¶
    private int retryCount = 0;
    private int maxRetries = 3;
    private long retryDelay = 1000; // æ¯«ç§’
    
    /**
     * çº¿ç¨‹å®‰å…¨çš„çŠ¶æ€æ›´æ–°
     */
    public synchronized void updateState(ToolExecutionState newState) {
        ToolExecutionState oldState = this.state;
        this.state = newState;
        this.lastUpdateTime = System.currentTimeMillis();
        
        // å¤„ç†çŠ¶æ€è½¬æ¢çš„ç‰¹æ®Šé€»è¾‘
        handleStateTransition(oldState, newState);
        
        // é€šçŸ¥çŠ¶æ€å˜æ›´ç›‘å¬å™¨
        notifyStateListeners(oldState, newState);
    }
    
    /**
     * æ·»åŠ æµå¼è¾“å‡º
     */
    public synchronized void appendOutput(String output) {
        if (!cancelled && (state == ToolExecutionState.RUNNING || 
                          state == ToolExecutionState.STREAMING)) {
            outputBuffer.append(output);
            lastUpdateTime = System.currentTimeMillis();
            
            // é€šçŸ¥æµå¼è¾“å‡ºç›‘å¬å™¨
            notifyStreamListeners(output);
        }
    }
    
    /**
     * å®Œæˆå·¥å…·æ‰§è¡Œ
     */
    public void complete(String result) {
        this.finalResult = result;
        updateState(ToolExecutionState.COMPLETED);
        this.endTime = System.currentTimeMillis();
        completionLatch.countDown();
    }
    
    /**
     * æ ‡è®°å·¥å…·æ‰§è¡Œå¤±è´¥
     */
    public void fail(String error, Throwable exception) {
        this.errorMessage = error;
        this.exception = exception;
        updateState(ToolExecutionState.FAILED);
        this.endTime = System.currentTimeMillis();
        completionLatch.countDown();
    }
    
    /**
     * å–æ¶ˆå·¥å…·æ‰§è¡Œ
     */
    public void cancel() {
        this.cancelled = true;
        updateState(ToolExecutionState.CANCELLED);
        completionLatch.countDown();
    }
}
```

### 1.3 å·¥å…·è°ƒç”¨çŠ¶æ€æœºæ ¸å¿ƒæ¥å£

```java
/**
 * å·¥å…·è°ƒç”¨çŠ¶æ€æœºæ¥å£
 */
public interface ToolStateMachine {
    
    /**
     * æ‰§è¡Œå·¥å…·è°ƒç”¨
     */
    CompletableFuture<ToolResult> executeAsync(ToolCall toolCall);
    
    /**
     * æµå¼æ‰§è¡Œå·¥å…·è°ƒç”¨
     */
    Stream<ToolStreamResult> executeStream(ToolCall toolCall);
    
    /**
     * å–æ¶ˆå·¥å…·æ‰§è¡Œ
     */
    boolean cancelExecution(String toolCallId);
    
    /**
     * è·å–å·¥å…·æ‰§è¡ŒçŠ¶æ€
     */
    ToolExecutionState getExecutionState(String toolCallId);
    
    /**
     * è·å–å·¥å…·æ‰§è¡Œä¸Šä¸‹æ–‡
     */
    ToolExecutionContext getExecutionContext(String toolCallId);
}
```

## 2. ä»£ç è§£é‡Šå™¨çš„åˆ†æ­¥æ‰§è¡ŒçŠ¶æ€æœº

### 2.1 ä»£ç è§£é‡Šå™¨çŠ¶æ€æœºå®ç°

```python
class CodeInterpreterStateMachine:
    """ä»£ç è§£é‡Šå™¨çŠ¶æ€æœº - Pythonå®ç°"""
    
    class CodeState(Enum):
        PARSING = "parsing"           # ä»£ç è§£æé˜¶æ®µ
        VALIDATING = "validating"     # ä»£ç éªŒè¯é˜¶æ®µ
        PREPARING = "preparing"       # ç¯å¢ƒå‡†å¤‡é˜¶æ®µ
        EXECUTING = "executing"       # ä»£ç æ‰§è¡Œé˜¶æ®µ
        MONITORING = "monitoring"     # æ‰§è¡Œç›‘æ§é˜¶æ®µ
        COLLECTING = "collecting"     # ç»“æœæ”¶é›†é˜¶æ®µ
        COMPLETED = "completed"       # æ‰§è¡Œå®Œæˆ
        ERROR = "error"               # æ‰§è¡Œå‡ºé”™
    
    def __init__(self, task: str, max_steps: int = 10):
        self.task = task
        self.max_steps = max_steps
        self.current_step = 0
        self.state = self.CodeState.PARSING
        self.execution_context = {
            'variables': {},
            'imports': set(),
            'outputs': [],
            'errors': []
        }
        self.code_history = []
        self.result_buffer = []
    
    async def execute_step_stream(self) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œå•æ­¥å¹¶è¿”å›æµå¼ç»“æœ"""
        
        try:
            if self.state == self.CodeState.PARSING:
                yield from self._parse_code_stream()
                
            elif self.state == self.CodeState.VALIDATING:
                yield from self._validate_code_stream()
                
            elif self.state == self.CodeState.PREPARING:
                yield from self._prepare_environment_stream()
                
            elif self.state == self.CodeState.EXECUTING:
                yield from self._execute_code_stream()
                
            elif self.state == self.CodeState.MONITORING:
                yield from self._monitor_execution_stream()
                
            elif self.state == self.CodeState.COLLECTING:
                yield from self._collect_results_stream()
                
        except Exception as e:
            self.state = self.CodeState.ERROR
            yield json.dumps({
                "type": "error",
                "message": str(e),
                "step": self.current_step
            })
    
    async def _parse_code_stream(self) -> AsyncGenerator[str, None]:
        """è§£æä»£ç é˜¶æ®µ"""
        yield json.dumps({
            "type": "state_change",
            "from": "parsing",
            "to": "validating",
            "message": "å¼€å§‹è§£æä»£ç ..."
        })
        
        # è§£æä»£ç å—
        code_blocks = self._extract_code_blocks(self.task)
        
        if not code_blocks:
            self.state = self.CodeState.ERROR
            yield json.dumps({
                "type": "error",
                "message": "æœªæ‰¾åˆ°å¯æ‰§è¡Œçš„ä»£ç å—"
            })
            return
        
        self.execution_context['code_blocks'] = code_blocks
        self.state = self.CodeState.VALIDATING
        
        yield json.dumps({
            "type": "progress",
            "message": f"è§£æå®Œæˆï¼Œå‘ç° {len(code_blocks)} ä¸ªä»£ç å—",
            "code_blocks_count": len(code_blocks)
        })
    
    async def _execute_code_stream(self) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œä»£ç é˜¶æ®µ"""
        yield json.dumps({
            "type": "state_change",
            "from": "executing",
            "to": "monitoring",
            "message": "å¼€å§‹æ‰§è¡Œä»£ç ..."
        })
        
        code_blocks = self.execution_context['code_blocks']
        
        for i, code_block in enumerate(code_blocks):
            try:
                # æ‰§è¡Œå‰çŠ¶æ€é€šçŸ¥
                yield json.dumps({
                    "type": "code_execution_start",
                    "block_index": i,
                    "code": code_block,
                    "timestamp": time.time()
                })
                
                # æ‰§è¡Œä»£ç å—
                async for output in self._execute_single_block(code_block):
                    yield output
                
                # æ‰§è¡ŒåçŠ¶æ€é€šçŸ¥
                yield json.dumps({
                    "type": "code_execution_complete",
                    "block_index": i,
                    "timestamp": time.time()
                })
                
            except Exception as e:
                yield json.dumps({
                    "type": "code_execution_error",
                    "block_index": i,
                    "error": str(e),
                    "timestamp": time.time()
                })
                
                # æ ¹æ®é”™è¯¯ä¸¥é‡ç¨‹åº¦å†³å®šæ˜¯å¦ç»§ç»­
                if self._is_fatal_error(e):
                    self.state = self.CodeState.ERROR
                    return
        
        self.state = self.CodeState.COLLECTING
    
    async def _execute_single_block(self, code: str) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œå•ä¸ªä»£ç å—å¹¶å®æ—¶è¾“å‡ºç»“æœ"""
        
        # åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        local_vars = self.execution_context['variables'].copy()
        
        try:
            # ç¼–è¯‘ä»£ç 
            compiled_code = compile(code, '<string>', 'exec')
            
            # é‡å®šå‘æ ‡å‡†è¾“å‡º
            old_stdout = sys.stdout
            stdout_buffer = StringIO()
            sys.stdout = stdout_buffer
            
            try:
                # æ‰§è¡Œä»£ç 
                exec(compiled_code, globals(), local_vars)
                
                # è·å–è¾“å‡º
                output = stdout_buffer.getvalue()
                if output:
                    yield json.dumps({
                        "type": "stdout",
                        "content": output,
                        "timestamp": time.time()
                    })
                
                # æ›´æ–°æ‰§è¡Œä¸Šä¸‹æ–‡
                self.execution_context['variables'].update(local_vars)
                
                # æ£€æŸ¥æ–°åˆ›å»ºçš„å˜é‡
                for var_name, var_value in local_vars.items():
                    if var_name not in self.execution_context['variables']:
                        yield json.dumps({
                            "type": "variable_created",
                            "name": var_name,
                            "value": str(var_value),
                            "type": type(var_value).__name__
                        })
                
            finally:
                sys.stdout = old_stdout
                
        except Exception as e:
            yield json.dumps({
                "type": "execution_error",
                "error": str(e),
                "error_type": type(e).__name__,
                "traceback": traceback.format_exc()
            })
            raise e
```

### 2.2 ä»£ç è§£é‡Šå™¨å·¥å…·é›†æˆ

```java
/**
 * ä»£ç è§£é‡Šå™¨å·¥å…· - Javaåç«¯é›†æˆ
 */
@Component
public class CodeInterpreterTool extends BaseTool implements ToolStateMachine {
    
    @Override
    public CompletableFuture<ToolResult> executeAsync(ToolCall toolCall) {
        String toolCallId = toolCall.getId();
        ToolExecutionContext context = createExecutionContext(toolCall);
        
        return CompletableFuture.supplyAsync(() -> {
            try {
                // æ›´æ–°çŠ¶æ€ä¸ºåˆå§‹åŒ–ä¸­
                context.updateState(ToolExecutionState.INITIALIZING);
                
                // å‡†å¤‡æ‰§è¡Œå‚æ•°
                Map<String, Object> params = prepareExecutionParams(toolCall);
                String task = (String) params.get("task");
                List<String> fileNames = (List<String>) params.get("file_names");
                
                // æ›´æ–°çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
                context.updateState(ToolExecutionState.RUNNING);
                
                // è°ƒç”¨Pythonä»£ç è§£é‡Šå™¨
                String result = executeCodeInterpreterAgent(
                    task, fileNames, context.getRequestId());
                
                // æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
                context.complete(result);
                
                return ToolResult.success(toolCallId, result);
                
            } catch (Exception e) {
                log.error("Code interpreter execution failed", e);
                context.fail(e.getMessage(), e);
                return ToolResult.failure(toolCallId, e.getMessage());
            }
        });
    }
    
    @Override
    public Stream<ToolStreamResult> executeStream(ToolCall toolCall) {
        String toolCallId = toolCall.getId();
        ToolExecutionContext context = createExecutionContext(toolCall);
        
        return Stream.generate(() -> {
            try {
                // è°ƒç”¨æµå¼ä»£ç è§£é‡Šå™¨
                return callStreamingCodeInterpreter(toolCall, context);
            } catch (Exception e) {
                context.fail(e.getMessage(), e);
                return ToolStreamResult.error(toolCallId, e.getMessage());
            }
        })
        .takeWhile(result -> !result.isTerminal())
        .peek(result -> updateContextFromStreamResult(context, result));
    }
    
    /**
     * è°ƒç”¨æµå¼ä»£ç è§£é‡Šå™¨
     */
    private ToolStreamResult callStreamingCodeInterpreter(
            ToolCall toolCall, ToolExecutionContext context) {
        
        String toolCallId = toolCall.getId();
        
        try {
            // æ„å»ºè¯·æ±‚
            CodeInterpreterRequest request = buildCodeInterpreterRequest(toolCall);
            
            // å‘é€HTTPæµå¼è¯·æ±‚åˆ°PythonæœåŠ¡
            HttpResponse response = sendStreamRequest(request);
            
            if (response.getStatusCode() == 200) {
                String chunk = response.getBody();
                
                // è§£æå“åº”
                Map<String, Object> chunkData = parseStreamChunk(chunk);
                String type = (String) chunkData.get("type");
                
                // æ ¹æ®å“åº”ç±»å‹æ›´æ–°çŠ¶æ€
                switch (type) {
                    case "state_change":
                        updateStateFromChunk(context, chunkData);
                        return ToolStreamResult.stateChange(toolCallId, chunkData);
                        
                    case "stdout":
                        context.appendOutput((String) chunkData.get("content"));
                        return ToolStreamResult.output(toolCallId, chunkData);
                        
                    case "code_execution_start":
                        context.updateState(ToolExecutionState.RUNNING);
                        return ToolStreamResult.progress(toolCallId, chunkData);
                        
                    case "code_execution_complete":
                        return ToolStreamResult.progress(toolCallId, chunkData);
                        
                    case "final_result":
                        context.complete((String) chunkData.get("result"));
                        return ToolStreamResult.complete(toolCallId, chunkData);
                        
                    case "error":
                        context.fail((String) chunkData.get("message"), null);
                        return ToolStreamResult.error(toolCallId, 
                            (String) chunkData.get("message"));
                        
                    default:
                        return ToolStreamResult.unknown(toolCallId, chunkData);
                }
            } else {
                context.fail("HTTP request failed: " + response.getStatusCode(), null);
                return ToolStreamResult.error(toolCallId, 
                    "HTTP request failed: " + response.getStatusCode());
            }
            
        } catch (Exception e) {
            log.error("Streaming code interpreter call failed", e);
            context.fail(e.getMessage(), e);
            return ToolStreamResult.error(toolCallId, e.getMessage());
        }
    }
}
```

## 3. æ·±åº¦æœç´¢å·¥å…·çš„å¤šè½®è¿­ä»£çŠ¶æ€æ§åˆ¶

### 3.1 æ·±åº¦æœç´¢çŠ¶æ€æœºè®¾è®¡

```python
class DeepSearchStateMachine:
    """æ·±åº¦æœç´¢çŠ¶æ€æœº"""
    
    class SearchState(Enum):
        INITIALIZING = "initializing"     # åˆå§‹åŒ–æœç´¢
        DECOMPOSING = "decomposing"       # æŸ¥è¯¢åˆ†è§£
        SEARCHING = "searching"           # æ‰§è¡Œæœç´¢
        ANALYZING = "analyzing"           # ç»“æœåˆ†æ
        ITERATING = "iterating"           # è¿­ä»£æœç´¢
        SYNTHESIZING = "synthesizing"     # ç»“æœåˆæˆ
        COMPLETED = "completed"           # æœç´¢å®Œæˆ
        ERROR = "error"                   # æœç´¢å‡ºé”™
    
    def __init__(self, query: str, max_loop: int = 3):
        self.original_query = query
        self.max_loop = max_loop
        self.current_loop = 0
        self.state = self.SearchState.INITIALIZING
        
        # æœç´¢ä¸Šä¸‹æ–‡
        self.search_context = {
            'searched_queries': set(),
            'current_docs': [],
            'iteration_results': [],
            'synthesis_history': []
        }
    
    async def run(self, request_id: str = None, stream: bool = True) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œæ·±åº¦æœç´¢ä¸»å¾ªç¯"""
        
        self.current_loop = 1
        
        try:
            # åˆå§‹åŒ–é˜¶æ®µ
            self.state = self.SearchState.INITIALIZING
            yield self._create_state_message("å¼€å§‹æ·±åº¦æœç´¢...")
            
            while self.current_loop <= self.max_loop:
                log.info(f"{request_id} ç¬¬ {self.current_loop} è½®æ·±åº¦æœç´¢...")
                
                # æŸ¥è¯¢åˆ†è§£é˜¶æ®µ
                self.state = self.SearchState.DECOMPOSING
                yield self._create_state_message(f"ç¬¬ {self.current_loop} è½®ï¼šåˆ†è§£æŸ¥è¯¢")
                
                sub_queries = await self._decompose_query()
                yield self._create_progress_message("extend", sub_queries)
                
                # æœç´¢é˜¶æ®µ
                self.state = self.SearchState.SEARCHING
                yield self._create_state_message("æ‰§è¡Œå¹¶è¡Œæœç´¢...")
                
                searched_docs, docs_list = await self._search_queries_parallel(sub_queries)
                yield self._create_search_result_message(sub_queries, docs_list)
                
                # åˆ†æé˜¶æ®µ
                self.state = self.SearchState.ANALYZING
                yield self._create_state_message("åˆ†ææœç´¢ç»“æœ...")
                
                analysis_result = await self._analyze_search_results(searched_docs)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­è¿­ä»£
                if self._should_continue_search(analysis_result):
                    self.state = self.SearchState.ITERATING
                    yield self._create_state_message("å‡†å¤‡ä¸‹ä¸€è½®æœç´¢...")
                    
                    # æ›´æ–°æœç´¢ä¸Šä¸‹æ–‡
                    self._update_search_context(searched_docs, sub_queries, analysis_result)
                    self.current_loop += 1
                else:
                    break
            
            # åˆæˆé˜¶æ®µ
            self.state = self.SearchState.SYNTHESIZING
            yield self._create_state_message("åˆæˆæœ€ç»ˆç»“æœ...")
            
            final_result = await self._synthesize_final_result()
            
            # å®Œæˆ
            self.state = self.SearchState.COMPLETED
            yield self._create_final_result_message(final_result)
            
        except Exception as e:
            self.state = self.SearchState.ERROR
            log.error(f"Deep search failed: {str(e)}")
            yield self._create_error_message(str(e))
    
    async def _decompose_query(self) -> List[str]:
        """æŸ¥è¯¢åˆ†è§£ - å°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå­æŸ¥è¯¢"""
        
        # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½æŸ¥è¯¢åˆ†è§£
        decompose_prompt = f"""
        è¯·å°†ä»¥ä¸‹æŸ¥è¯¢åˆ†è§£ä¸º3-5ä¸ªæ›´å…·ä½“çš„å­æŸ¥è¯¢ï¼Œä»¥ä¾¿è¿›è¡Œæ·±åº¦æœç´¢ï¼š
        
        åŸå§‹æŸ¥è¯¢ï¼š{self.original_query}
        
        å·²æœç´¢çš„æŸ¥è¯¢ï¼š{list(self.search_context['searched_queries'])}
        
        è¯·è¿”å›JSONæ ¼å¼çš„å­æŸ¥è¯¢åˆ—è¡¨ã€‚
        """
        
        response = await self.llm.achat(decompose_prompt)
        
        try:
            sub_queries = json.loads(response.content).get("sub_queries", [])
            
            # è¿‡æ»¤å·²æœç´¢çš„æŸ¥è¯¢
            new_queries = [q for q in sub_queries 
                          if q not in self.search_context['searched_queries']]
            
            return new_queries[:5]  # é™åˆ¶å­æŸ¥è¯¢æ•°é‡
            
        except json.JSONDecodeError:
            log.warning("Failed to parse sub queries, using fallback")
            return [self.original_query]
    
    async def _search_queries_parallel(self, queries: List[str]) -> Tuple[List[Document], List[List[Document]]]:
        """å¹¶è¡Œæœç´¢å­æŸ¥è¯¢"""
        
        tasks = [self._search_single_query(query) for query in queries]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        all_docs = []
        docs_lists = []
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                log.error(f"Search failed for query '{queries[i]}': {result}")
                docs_lists.append([])
            else:
                docs = result
                all_docs.extend(docs)
                docs_lists.append(docs)
        
        # å»é‡
        unique_docs = self._deduplicate_documents(all_docs)
        
        return unique_docs, docs_lists
    
    async def _search_single_query(self, query: str) -> List[Document]:
        """æœç´¢å•ä¸ªæŸ¥è¯¢"""
        
        try:
            # è°ƒç”¨æœç´¢å¼•æ“
            search_results = await self.search_engine.search(query)
            
            # è½¬æ¢ä¸ºæ–‡æ¡£å¯¹è±¡
            documents = []
            for result in search_results:
                doc = Document(
                    title=result.get('title', ''),
                    content=result.get('content', ''),
                    url=result.get('url', ''),
                    source=result.get('source', 'web'),
                    relevance_score=result.get('score', 0.0)
                )
                documents.append(doc)
            
            return documents
            
        except Exception as e:
            log.error(f"Single query search failed: {query}", e)
            return []
    
    def _should_continue_search(self, analysis_result: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æœç´¢"""
        
        # æ£€æŸ¥ä¿¡æ¯å……åˆ†æ€§
        completeness_score = analysis_result.get('completeness_score', 0.0)
        if completeness_score < 0.7:
            return True
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªæ¢ç´¢çš„æ–¹å‘
        unexplored_areas = analysis_result.get('unexplored_areas', [])
        if len(unexplored_areas) > 0:
            return True
        
        # æ£€æŸ¥æœç´¢æ·±åº¦
        if self.current_loop < 2:  # è‡³å°‘æœç´¢2è½®
            return True
        
        return False
    
    def _create_state_message(self, message: str) -> str:
        """åˆ›å»ºçŠ¶æ€å˜æ›´æ¶ˆæ¯"""
        return json.dumps({
            "requestId": self.request_id,
            "state": self.state.value,
            "message": message,
            "loop": self.current_loop,
            "timestamp": time.time()
        }, ensure_ascii=False)
    
    def _create_search_result_message(self, queries: List[str], docs_lists: List[List[Document]]) -> str:
        """åˆ›å»ºæœç´¢ç»“æœæ¶ˆæ¯"""
        
        truncate_len = int(os.getenv("SINGLE_PAGE_MAX_SIZE", 200))
        
        return json.dumps({
            "requestId": self.request_id,
            "query": self.original_query,
            "searchResult": {
                "query": queries,
                "docs": [[doc.to_dict(truncate_len=truncate_len) for doc in docs] 
                        for docs in docs_lists]
            },
            "isFinal": False,
            "messageType": "search",
            "loop": self.current_loop
        }, ensure_ascii=False)
```

### 3.2 æ·±åº¦æœç´¢å·¥å…·çš„Javaé›†æˆ

```java
/**
 * æ·±åº¦æœç´¢å·¥å…·çŠ¶æ€æœº
 */
@Component
public class DeepSearchTool extends BaseTool implements ToolStateMachine {
    
    private final Map<String, ToolExecutionContext> executionContexts = 
        new ConcurrentHashMap<>();
    
    @Override
    public Stream<ToolStreamResult> executeStream(ToolCall toolCall) {
        String toolCallId = toolCall.getId();
        ToolExecutionContext context = createExecutionContext(toolCall);
        executionContexts.put(toolCallId, context);
        
        return Stream.generate(new DeepSearchStreamSupplier(toolCall, context))
            .takeWhile(result -> !result.isTerminal())
            .peek(result -> updateContextFromResult(context, result));
    }
    
    /**
     * æ·±åº¦æœç´¢æµå¼ä¾›åº”å™¨
     */
    private class DeepSearchStreamSupplier implements Supplier<ToolStreamResult> {
        private final ToolCall toolCall;
        private final ToolExecutionContext context;
        private final BlockingQueue<ToolStreamResult> resultQueue = 
            new LinkedBlockingQueue<>();
        private volatile boolean initialized = false;
        
        public DeepSearchStreamSupplier(ToolCall toolCall, ToolExecutionContext context) {
            this.toolCall = toolCall;
            this.context = context;
        }
        
        @Override
        public ToolStreamResult get() {
            if (!initialized) {
                initialize();
                initialized = true;
            }
            
            try {
                // ä»é˜Ÿåˆ—ä¸­è·å–ç»“æœï¼Œè¶…æ—¶æœºåˆ¶é˜²æ­¢æ— é™ç­‰å¾…
                ToolStreamResult result = resultQueue.poll(30, TimeUnit.SECONDS);
                
                if (result == null) {
                    // è¶…æ—¶å¤„ç†
                    context.updateState(ToolExecutionState.TIMEOUT);
                    return ToolStreamResult.timeout(toolCall.getId(), "Deep search timeout");
                }
                
                return result;
                
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                context.updateState(ToolExecutionState.CANCELLED);
                return ToolStreamResult.cancelled(toolCall.getId(), "Deep search interrupted");
            }
        }
        
        private void initialize() {
            // å¼‚æ­¥å¯åŠ¨æ·±åº¦æœç´¢
            CompletableFuture.runAsync(() -> {
                try {
                    context.updateState(ToolExecutionState.INITIALIZING);
                    
                    // è°ƒç”¨Pythonæ·±åº¦æœç´¢æœåŠ¡
                    executeDeepSearchAsync();
                    
                } catch (Exception e) {
                    log.error("Deep search initialization failed", e);
                    resultQueue.offer(ToolStreamResult.error(
                        toolCall.getId(), "Initialization failed: " + e.getMessage()));
                }
            });
        }
        
        private void executeDeepSearchAsync() {
            try {
                // æ„å»ºæ·±åº¦æœç´¢è¯·æ±‚
                DeepSearchRequest request = buildDeepSearchRequest();
                
                // å‘é€æµå¼HTTPè¯·æ±‚
                try (CloseableHttpClient httpClient = createHttpClient()) {
                    HttpPost httpPost = createStreamingRequest(request);
                    
                    httpClient.execute(httpPost, response -> {
                        processStreamingResponse(response);
                        return null;
                    });
                }
                
            } catch (Exception e) {
                log.error("Deep search execution failed", e);
                resultQueue.offer(ToolStreamResult.error(
                    toolCall.getId(), "Execution failed: " + e.getMessage()));
            }
        }
        
        private void processStreamingResponse(CloseableHttpResponse response) {
            try (BufferedReader reader = new BufferedReader(
                    new InputStreamReader(response.getEntity().getContent()))) {
                
                String line;
                while ((line = reader.readLine()) != null) {
                    if (context.isCancelled()) {
                        break;
                    }
                    
                    // è§£ææµå¼å“åº”
                    ToolStreamResult result = parseStreamingLine(line);
                    if (result != null) {
                        resultQueue.offer(result);
                        
                        // æ›´æ–°ä¸Šä¸‹æ–‡çŠ¶æ€
                        updateContextFromStreamResult(result);
                    }
                }
                
                // æœç´¢å®Œæˆ
                if (!context.isCancelled()) {
                    context.updateState(ToolExecutionState.COMPLETED);
                    resultQueue.offer(ToolStreamResult.complete(
                        toolCall.getId(), "Deep search completed"));
                }
                
            } catch (IOException e) {
                log.error("Error reading streaming response", e);
                resultQueue.offer(ToolStreamResult.error(
                    toolCall.getId(), "Response reading failed: " + e.getMessage()));
            }
        }
        
        private ToolStreamResult parseStreamingLine(String line) {
            try {
                Map<String, Object> data = objectMapper.readValue(line, Map.class);
                String messageType = (String) data.get("messageType");
                
                switch (messageType) {
                    case "extend":
                        context.updateState(ToolExecutionState.RUNNING);
                        return ToolStreamResult.progress(toolCall.getId(), data);
                        
                    case "search":
                        context.updateState(ToolExecutionState.STREAMING);
                        context.appendOutput("Search results: " + data.get("searchResult"));
                        return ToolStreamResult.data(toolCall.getId(), data);
                        
                    case "final_result":
                        String finalResult = (String) data.get("result");
                        context.complete(finalResult);
                        return ToolStreamResult.complete(toolCall.getId(), finalResult);
                        
                    case "error":
                        String error = (String) data.get("error");
                        context.fail(error, null);
                        return ToolStreamResult.error(toolCall.getId(), error);
                        
                    default:
                        return ToolStreamResult.unknown(toolCall.getId(), data);
                }
                
            } catch (Exception e) {
                log.error("Failed to parse streaming line: " + line, e);
                return null;
            }
        }
    }
}
```

## 4. å·¥å…·æ‰§è¡Œç»“æœçš„çŠ¶æ€æŒä¹…åŒ–ä¸ç¼“å­˜ç­–ç•¥

### 4.1 å·¥å…·æ‰§è¡Œç»“æœç¼“å­˜è®¾è®¡

```java
/**
 * å·¥å…·æ‰§è¡Œç»“æœç¼“å­˜ç®¡ç†å™¨
 */
@Component
public class ToolResultCacheManager {
    
    /**
     * ç¼“å­˜é¡¹æ•°æ®ç»“æ„
     */
    @Data
    @Builder
    public static class CacheItem {
        private String key;
        private ToolResult result;
        private long createTime;
        private long accessTime;
        private int accessCount;
        private long expirationTime;
        private Set<String> tags = new HashSet<>();
        
        public boolean isExpired() {
            return System.currentTimeMillis() > expirationTime;
        }
        
        public void updateAccess() {
            this.accessTime = System.currentTimeMillis();
            this.accessCount++;
        }
    }
    
    private final Map<String, CacheItem> cache = new ConcurrentHashMap<>();
    private final ScheduledExecutorService cleanupExecutor = 
        Executors.newSingleThreadScheduledExecutor();
    
    /**
     * ç”Ÿæˆç¼“å­˜é”®
     */
    public String generateCacheKey(ToolCall toolCall) {
        // åŸºäºå·¥å…·åç§°ã€å‚æ•°å’Œç‰ˆæœ¬ç”Ÿæˆå”¯ä¸€é”®
        StringBuilder keyBuilder = new StringBuilder()
            .append(toolCall.getName())
            .append(":")
            .append(toolCall.getArguments().hashCode());
        
        // å¯¹äºæŸäº›å·¥å…·ï¼Œå¯èƒ½éœ€è¦è€ƒè™‘æ—¶é—´æ•æ„Ÿæ€§
        if (isTimeSensitive(toolCall.getName())) {
            long timeWindow = getTimeWindow(toolCall.getName());
            long currentWindow = System.currentTimeMillis() / timeWindow;
            keyBuilder.append(":").append(currentWindow);
        }
        
        return DigestUtils.md5Hex(keyBuilder.toString());
    }
    
    /**
     * æ£€æŸ¥ç¼“å­˜
     */
    public Optional<ToolResult> getFromCache(String cacheKey) {
        CacheItem item = cache.get(cacheKey);
        
        if (item == null) {
            return Optional.empty();
        }
        
        // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if (item.isExpired()) {
            cache.remove(cacheKey);
            return Optional.empty();
        }
        
        // æ›´æ–°è®¿é—®ä¿¡æ¯
        item.updateAccess();
        
        log.debug("Cache hit for key: {}, access count: {}", 
            cacheKey, item.getAccessCount());
        
        return Optional.of(item.getResult());
    }
    
    /**
     * ä¿å­˜åˆ°ç¼“å­˜
     */
    public void saveToCache(String cacheKey, ToolResult result, Duration ttl) {
        long expirationTime = System.currentTimeMillis() + ttl.toMillis();
        
        CacheItem item = CacheItem.builder()
            .key(cacheKey)
            .result(result)
            .createTime(System.currentTimeMillis())
            .accessTime(System.currentTimeMillis())
            .accessCount(0)
            .expirationTime(expirationTime)
            .build();
        
        // æ ¹æ®å·¥å…·ç±»å‹æ·»åŠ æ ‡ç­¾
        item.getTags().add("tool:" + result.getToolName());
        
        cache.put(cacheKey, item);
        
        log.debug("Cached result for key: {}, expires at: {}", 
            cacheKey, new Date(expirationTime));
    }
    
    /**
     * æ™ºèƒ½ç¼“å­˜ç­–ç•¥åˆ¤æ–­
     */
    public boolean shouldCache(ToolCall toolCall, ToolResult result) {
        String toolName = toolCall.getName();
        
        // ä¸ç¼“å­˜å¤±è´¥çš„ç»“æœ
        if (!result.isSuccess()) {
            return false;
        }
        
        // ä¸ç¼“å­˜å®æ—¶æ€§è¦æ±‚é«˜çš„å·¥å…·
        if (isRealTimeRequired(toolName)) {
            return false;
        }
        
        // ä¸ç¼“å­˜åŒ…å«æ•æ„Ÿä¿¡æ¯çš„ç»“æœ
        if (containsSensitiveData(result)) {
            return false;
        }
        
        // ä¸ç¼“å­˜å¤ªå¤§çš„ç»“æœ
        if (result.getData().length() > MAX_CACHE_SIZE) {
            return false;
        }
        
        return true;
    }
    
    /**
     * è·å–ç¼“å­˜TTLç­–ç•¥
     */
    public Duration getCacheTTL(String toolName) {
        switch (toolName.toLowerCase()) {
            case "code_interpreter":
                return Duration.ofMinutes(30); // ä»£ç æ‰§è¡Œç»“æœç¼“å­˜30åˆ†é’Ÿ
                
            case "deep_search":
                return Duration.ofHours(2);    // æœç´¢ç»“æœç¼“å­˜2å°æ—¶
                
            case "file_operation":
                return Duration.ofMinutes(10); // æ–‡ä»¶æ“ä½œç¼“å­˜10åˆ†é’Ÿ
                
            case "web_scraping":
                return Duration.ofMinutes(15); // ç½‘é¡µæŠ“å–ç¼“å­˜15åˆ†é’Ÿ
                
            default:
                return Duration.ofMinutes(5);  // é»˜è®¤ç¼“å­˜5åˆ†é’Ÿ
        }
    }
    
    /**
     * ç¼“å­˜æ¸…ç†ä»»åŠ¡
     */
    @Scheduled(fixedRate = 300000) // æ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    public void cleanupExpiredCache() {
        int removedCount = 0;
        Iterator<Map.Entry<String, CacheItem>> iterator = cache.entrySet().iterator();
        
        while (iterator.hasNext()) {
            Map.Entry<String, CacheItem> entry = iterator.next();
            if (entry.getValue().isExpired()) {
                iterator.remove();
                removedCount++;
            }
        }
        
        if (removedCount > 0) {
            log.info("Cleaned up {} expired cache items", removedCount);
        }
    }
}
```

### 4.2 å·¥å…·æ‰§è¡ŒçŠ¶æ€æŒä¹…åŒ–

```java
/**
 * å·¥å…·æ‰§è¡ŒçŠ¶æ€æŒä¹…åŒ–ç®¡ç†å™¨
 */
@Component
public class ToolExecutionPersistenceManager {
    
    /**
     * æŒä¹…åŒ–çš„æ‰§è¡Œè®°å½•
     */
    @Data
    @Builder
    public static class ExecutionRecord {
        private String id;
        private String toolCallId;
        private String toolName;
        private String sessionId;
        private String requestId;
        
        // æ‰§è¡Œä¿¡æ¯
        private ToolExecutionState state;
        private Map<String, Object> parameters;
        private long startTime;
        private long endTime;
        private long duration;
        
        // ç»“æœä¿¡æ¯
        private String result;
        private String errorMessage;
        private List<String> outputHistory = new ArrayList<>();
        
        // å…ƒæ•°æ®
        private Map<String, Object> metadata = new HashMap<>();
        private long createTime;
        private long updateTime;
    }
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final String KEY_PREFIX = "tool_execution:";
    private final Duration DEFAULT_TTL = Duration.ofHours(24);
    
    /**
     * ä¿å­˜æ‰§è¡ŒçŠ¶æ€
     */
    public void saveExecutionState(ToolExecutionContext context) {
        ExecutionRecord record = buildExecutionRecord(context);
        
        String key = KEY_PREFIX + context.getToolCallId();
        
        try {
            redisTemplate.opsForValue().set(key, record, DEFAULT_TTL);
            log.debug("Saved execution state for tool call: {}", context.getToolCallId());
        } catch (Exception e) {
            log.error("Failed to save execution state", e);
        }
    }
    
    /**
     * åŠ è½½æ‰§è¡ŒçŠ¶æ€
     */
    public Optional<ExecutionRecord> loadExecutionState(String toolCallId) {
        String key = KEY_PREFIX + toolCallId;
        
        try {
            ExecutionRecord record = (ExecutionRecord) redisTemplate.opsForValue().get(key);
            return Optional.ofNullable(record);
        } catch (Exception e) {
            log.error("Failed to load execution state for tool call: " + toolCallId, e);
            return Optional.empty();
        }
    }
    
    /**
     * æ›´æ–°æ‰§è¡ŒçŠ¶æ€
     */
    public void updateExecutionState(String toolCallId, ToolExecutionState newState) {
        String key = KEY_PREFIX + toolCallId;
        
        try {
            ExecutionRecord record = (ExecutionRecord) redisTemplate.opsForValue().get(key);
            if (record != null) {
                record.setState(newState);
                record.setUpdateTime(System.currentTimeMillis());
                
                if (newState.isTerminal()) {
                    record.setEndTime(System.currentTimeMillis());
                    record.setDuration(record.getEndTime() - record.getStartTime());
                }
                
                redisTemplate.opsForValue().set(key, record, DEFAULT_TTL);
                log.debug("Updated execution state for tool call: {} to {}", 
                    toolCallId, newState);
            }
        } catch (Exception e) {
            log.error("Failed to update execution state", e);
        }
    }
    
    /**
     * è¿½åŠ è¾“å‡ºå†å²
     */
    public void appendOutputHistory(String toolCallId, String output) {
        String key = KEY_PREFIX + toolCallId;
        
        try {
            ExecutionRecord record = (ExecutionRecord) redisTemplate.opsForValue().get(key);
            if (record != null) {
                record.getOutputHistory().add(output);
                record.setUpdateTime(System.currentTimeMillis());
                
                // é™åˆ¶è¾“å‡ºå†å²é•¿åº¦ï¼Œé¿å…å ç”¨è¿‡å¤šå†…å­˜
                if (record.getOutputHistory().size() > 1000) {
                    record.getOutputHistory().remove(0);
                }
                
                redisTemplate.opsForValue().set(key, record, DEFAULT_TTL);
            }
        } catch (Exception e) {
            log.error("Failed to append output history", e);
        }
    }
    
    /**
     * è·å–ä¼šè¯çš„æ‰€æœ‰å·¥å…·æ‰§è¡Œè®°å½•
     */
    public List<ExecutionRecord> getSessionExecutionRecords(String sessionId) {
        Set<String> keys = redisTemplate.keys(KEY_PREFIX + "*");
        List<ExecutionRecord> records = new ArrayList<>();
        
        for (String key : keys) {
            try {
                ExecutionRecord record = (ExecutionRecord) redisTemplate.opsForValue().get(key);
                if (record != null && sessionId.equals(record.getSessionId())) {
                    records.add(record);
                }
            } catch (Exception e) {
                log.warn("Failed to load execution record for key: " + key, e);
            }
        }
        
        // æŒ‰åˆ›å»ºæ—¶é—´æ’åº
        records.sort(Comparator.comparingLong(ExecutionRecord::getCreateTime));
        
        return records;
    }
    
    private ExecutionRecord buildExecutionRecord(ToolExecutionContext context) {
        return ExecutionRecord.builder()
            .id(UUID.randomUUID().toString())
            .toolCallId(context.getToolCallId())
            .toolName(context.getToolName())
            .sessionId(context.getSessionId())
            .requestId(context.getRequestId())
            .state(context.getState())
            .parameters(new HashMap<>(context.getParameters()))
            .startTime(context.getStartTime())
            .endTime(context.getEndTime())
            .result(context.getFinalResult())
            .errorMessage(context.getErrorMessage())
            .outputHistory(new ArrayList<>(
                Arrays.asList(context.getOutputBuffer().toString().split("\n"))))
            .metadata(new HashMap<>(context.getMetadata()))
            .createTime(System.currentTimeMillis())
            .updateTime(System.currentTimeMillis())
            .build();
    }
}
```

## 5. å·¥å…·çŠ¶æ€æœºçš„ç›‘æ§ä¸è°ƒè¯•

### 5.1 å·¥å…·æ‰§è¡Œç›‘æ§ç³»ç»Ÿ

```java
/**
 * å·¥å…·æ‰§è¡Œç›‘æ§å™¨
 */
@Component
public class ToolExecutionMonitor {
    
    /**
     * å·¥å…·æ‰§è¡ŒæŒ‡æ ‡
     */
    @Data
    @Builder
    public static class ExecutionMetrics {
        private String toolName;
        private long totalExecutions;
        private long successfulExecutions;
        private long failedExecutions;
        private double successRate;
        private long averageExecutionTime;
        private long maxExecutionTime;
        private long minExecutionTime;
        private Map<String, Long> errorTypeCounts = new HashMap<>();
    }
    
    private final MeterRegistry meterRegistry;
    private final Map<String, ExecutionMetrics> toolMetrics = new ConcurrentHashMap<>();
    
    /**
     * è®°å½•å·¥å…·æ‰§è¡Œå¼€å§‹
     */
    public void recordExecutionStart(String toolName, String toolCallId) {
        Timer.Sample sample = Timer.start(meterRegistry);
        sample.stop(Timer.builder("tool.execution.duration")
            .tag("tool", toolName)
            .register(meterRegistry));
        
        meterRegistry.counter("tool.execution.total", "tool", toolName)
            .increment();
    }
    
    /**
     * è®°å½•å·¥å…·æ‰§è¡Œå®Œæˆ
     */
    public void recordExecutionComplete(String toolName, String toolCallId, 
                                       long executionTime, boolean success) {
        if (success) {
            meterRegistry.counter("tool.execution.success", "tool", toolName)
                .increment();
        } else {
            meterRegistry.counter("tool.execution.failure", "tool", toolName)
                .increment();
        }
        
        meterRegistry.timer("tool.execution.time", "tool", toolName)
            .record(executionTime, TimeUnit.MILLISECONDS);
        
        updateToolMetrics(toolName, executionTime, success, null);
    }
    
    /**
     * è®°å½•å·¥å…·æ‰§è¡Œé”™è¯¯
     */
    public void recordExecutionError(String toolName, String toolCallId, 
                                    String errorType, Throwable error) {
        meterRegistry.counter("tool.execution.error", 
            "tool", toolName, 
            "error_type", errorType)
            .increment();
        
        updateToolMetrics(toolName, 0, false, errorType);
    }
    
    private void updateToolMetrics(String toolName, long executionTime, 
                                  boolean success, String errorType) {
        toolMetrics.compute(toolName, (key, metrics) -> {
            if (metrics == null) {
                metrics = ExecutionMetrics.builder()
                    .toolName(toolName)
                    .totalExecutions(0)
                    .successfulExecutions(0)
                    .failedExecutions(0)
                    .averageExecutionTime(0)
                    .maxExecutionTime(0)
                    .minExecutionTime(Long.MAX_VALUE)
                    .build();
            }
            
            metrics.setTotalExecutions(metrics.getTotalExecutions() + 1);
            
            if (success) {
                metrics.setSuccessfulExecutions(metrics.getSuccessfulExecutions() + 1);
                
                // æ›´æ–°æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
                metrics.setMaxExecutionTime(Math.max(metrics.getMaxExecutionTime(), executionTime));
                metrics.setMinExecutionTime(Math.min(metrics.getMinExecutionTime(), executionTime));
                
                // æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´
                long totalTime = metrics.getAverageExecutionTime() * (metrics.getSuccessfulExecutions() - 1) + executionTime;
                metrics.setAverageExecutionTime(totalTime / metrics.getSuccessfulExecutions());
                
            } else {
                metrics.setFailedExecutions(metrics.getFailedExecutions() + 1);
                
                if (errorType != null) {
                    metrics.getErrorTypeCounts().merge(errorType, 1L, Long::sum);
                }
            }
            
            // æ›´æ–°æˆåŠŸç‡
            metrics.setSuccessRate((double) metrics.getSuccessfulExecutions() / 
                                  metrics.getTotalExecutions() * 100);
            
            return metrics;
        });
    }
    
    /**
     * è·å–å·¥å…·æ‰§è¡ŒæŠ¥å‘Š
     */
    public Map<String, ExecutionMetrics> getExecutionReport() {
        return new HashMap<>(toolMetrics);
    }
    
    /**
     * è·å–æ€§èƒ½å¼‚å¸¸çš„å·¥å…·åˆ—è¡¨
     */
    public List<String> getPerformanceAnomalies() {
        return toolMetrics.entrySet().stream()
            .filter(entry -> {
                ExecutionMetrics metrics = entry.getValue();
                // æˆåŠŸç‡ä½äº80%æˆ–å¹³å‡æ‰§è¡Œæ—¶é—´è¶…è¿‡30ç§’
                return metrics.getSuccessRate() < 80.0 || 
                       metrics.getAverageExecutionTime() > 30000;
            })
            .map(Map.Entry::getKey)
            .collect(Collectors.toList());
    }
}
```

## 6. å°ç»“

æœ¬èŠ‚æ·±å…¥æ¢è®¨äº†å·¥å…·è°ƒç”¨çŠ¶æ€æœºä¸å¼‚æ­¥æ‰§è¡Œç®¡ç†çš„å…³é”®æŠ€æœ¯ï¼š

1. **ç”Ÿå‘½å‘¨æœŸçŠ¶æ€è®¾è®¡**ï¼šå®šä¹‰äº†å®Œæ•´çš„å·¥å…·æ‰§è¡ŒçŠ¶æ€æšä¸¾å’Œè½¬æ¢è§„åˆ™
2. **ä»£ç è§£é‡Šå™¨çŠ¶æ€æœº**ï¼šå®ç°äº†åˆ†æ­¥æ‰§è¡Œçš„æµå¼çŠ¶æ€æ§åˆ¶æœºåˆ¶
3. **æ·±åº¦æœç´¢çŠ¶æ€æœº**ï¼šè®¾è®¡äº†å¤šè½®è¿­ä»£çš„æ™ºèƒ½æœç´¢çŠ¶æ€ç®¡ç†
4. **ç»“æœæŒä¹…åŒ–ç­–ç•¥**ï¼šå»ºç«‹äº†ç¼“å­˜å’ŒæŒä¹…åŒ–çš„ç»¼åˆè§£å†³æ–¹æ¡ˆ
5. **ç›‘æ§è°ƒè¯•ç³»ç»Ÿ**ï¼šæä¾›äº†å·¥å…·æ‰§è¡Œçš„å…¨æ–¹ä½ç›‘æ§å’Œæ€§èƒ½åˆ†æ

è¿™äº›æŠ€æœ¯ç¡®ä¿äº†AIåº”ç”¨ä¸­å·¥å…·è°ƒç”¨çš„å¯é æ€§ã€å¯è§‚æµ‹æ€§å’Œå¯ç»´æŠ¤æ€§ï¼Œä¸ºå¤æ‚çš„AIå·¥ä½œæµæä¾›äº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚

## å»¶ä¼¸æ€è€ƒ

1. å¦‚ä½•å®ç°å·¥å…·è°ƒç”¨çš„æ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œèµ„æºè°ƒåº¦ï¼Ÿ
2. å¦‚ä½•è®¾è®¡å·¥å…·æ‰§è¡Œçš„æ–­ç‚¹ç»­ä¼ å’Œå¢é‡æ›´æ–°æœºåˆ¶ï¼Ÿ
3. å¦‚ä½•ä¼˜åŒ–é•¿æ—¶é—´è¿è¡Œå·¥å…·çš„å†…å­˜ä½¿ç”¨å’Œåƒåœ¾å›æ”¶ï¼Ÿ
4. å¦‚ä½•å®ç°è·¨æœåŠ¡çš„å·¥å…·è°ƒç”¨çŠ¶æ€åŒæ­¥ï¼Ÿ

ä¸‹ä¸€èŠ‚æˆ‘ä»¬å°†æ¢è®¨å¤šAgentåä½œçš„åˆ†å¸ƒå¼çŠ¶æ€æœºè®¾è®¡ä¸å®ç°ã€‚
