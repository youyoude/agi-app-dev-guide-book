# 2.3.7 状态持久化与容错机制设计

## 学习目标

- 学会设计Agent状态的快照与恢复机制
- 掌握状态机的检查点（Checkpoint）设计模式
- 理解分布式状态存储的一致性保障
- 学会实现状态机的故障转移与自动恢复策略

## 引言

在企业级AI应用中，状态持久化与容错机制是系统可靠性的基石。AI任务通常执行时间较长，涉及复杂的多步骤处理流程，一旦系统出现故障，如果没有有效的状态持久化机制，将导致大量工作的重复执行。同时，分布式AI系统面临网络分区、节点宕机、数据不一致等挑战，需要设计完善的容错机制来保证系统的高可用性。

本节将深入探讨如何在AI应用中设计和实现可靠的状态持久化与容错机制。

## 1. 状态快照与恢复机制

### 1.1 状态快照设计原理

```java
/**
 * 状态快照的核心设计
 */
@Component
public class StateSnapshotManager {
    
    /**
     * 状态快照数据结构
     */
    @Data
    @Builder
    @AllArgsConstructor
    @NoArgsConstructor
    public static class StateSnapshot {
        private String snapshotId;
        private String stateMachineId;
        private String sessionId;
        private String requestId;
        
        // 状态信息
        private AgentState currentState;
        private Map<String, Object> stateData;
        private List<Message> memoryMessages;
        
        // 执行上下文
        private int currentStep;
        private int maxSteps;
        private String currentTask;
        private List<String> executionHistory;
        
        // 工具状态
        private Map<String, ToolExecutionContext> toolContexts;
        
        // 元数据
        private long createTime;
        private long version;
        private String checksum;
        private String nodeId;
        private Map<String, Object> metadata;
    }
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final String SNAPSHOT_PREFIX = "snapshot:";
    private final String SNAPSHOT_INDEX_PREFIX = "snapshot_index:";
    
    /**
     * 创建状态快照
     */
    public StateSnapshot createSnapshot(BaseAgent agent) {
        String snapshotId = generateSnapshotId(agent.getContext());
        
        StateSnapshot snapshot = StateSnapshot.builder()
            .snapshotId(snapshotId)
            .stateMachineId(agent.getName())
            .sessionId(agent.getContext().getSessionId())
            .requestId(agent.getContext().getRequestId())
            .currentState(agent.getState())
            .stateData(extractStateData(agent))
            .memoryMessages(new ArrayList<>(agent.getMemory().getMessages()))
            .currentStep(agent.getCurrentStep())
            .maxSteps(agent.getMaxSteps())
            .executionHistory(extractExecutionHistory(agent))
            .toolContexts(extractToolContexts(agent))
            .createTime(System.currentTimeMillis())
            .version(1L)
            .nodeId(getCurrentNodeId())
            .metadata(extractMetadata(agent))
            .build();
        
        // 计算校验和
        snapshot.setChecksum(calculateChecksum(snapshot));
        
        return snapshot;
    }
    
    /**
     * 保存快照到持久存储
     */
    public boolean saveSnapshot(StateSnapshot snapshot) {
        try {
            String key = SNAPSHOT_PREFIX + snapshot.getSnapshotId();
            
            // 保存快照数据
            redisTemplate.opsForValue().set(key, snapshot, Duration.ofHours(24));
            
            // 更新快照索引
            updateSnapshotIndex(snapshot);
            
            // 异步备份到其他存储
            backupSnapshotAsync(snapshot);
            
            log.info("State snapshot saved successfully: {}", snapshot.getSnapshotId());
            return true;
            
        } catch (Exception e) {
            log.error("Failed to save state snapshot: " + snapshot.getSnapshotId(), e);
            return false;
        }
    }
    
    /**
     * 从快照恢复Agent状态
     */
    public boolean restoreFromSnapshot(BaseAgent agent, String snapshotId) {
        try {
            StateSnapshot snapshot = loadSnapshot(snapshotId);
            if (snapshot == null) {
                log.warn("Snapshot not found: {}", snapshotId);
                return false;
            }
            
            // 验证快照完整性
            if (!validateSnapshot(snapshot)) {
                log.error("Snapshot validation failed: {}", snapshotId);
                return false;
            }
            
            // 恢复Agent状态
            restoreAgentState(agent, snapshot);
            
            log.info("Agent state restored from snapshot: {}", snapshotId);
            return true;
            
        } catch (Exception e) {
            log.error("Failed to restore from snapshot: " + snapshotId, e);
            return false;
        }
    }
    
    /**
     * 恢复Agent状态的详细实现
     */
    private void restoreAgentState(BaseAgent agent, StateSnapshot snapshot) {
        // 1. 恢复基本状态
        agent.setState(snapshot.getCurrentState());
        agent.setCurrentStep(snapshot.getCurrentStep());
        agent.setMaxSteps(snapshot.getMaxSteps());
        
        // 2. 恢复上下文数据
        AgentContext context = agent.getContext();
        context.getContextData().putAll(extractContextData(snapshot.getStateData()));
        
        // 3. 恢复内存状态
        Memory memory = agent.getMemory();
        memory.clear();
        memory.addMessages(snapshot.getMemoryMessages());
        
        // 4. 恢复工具执行上下文
        if (snapshot.getToolContexts() != null) {
            for (Map.Entry<String, ToolExecutionContext> entry : snapshot.getToolContexts().entrySet()) {
                restoreToolContext(agent, entry.getKey(), entry.getValue());
            }
        }
        
        // 5. 恢复执行历史
        if (snapshot.getExecutionHistory() != null) {
            restoreExecutionHistory(agent, snapshot.getExecutionHistory());
        }
        
        log.debug("Agent state restoration completed for: {}", agent.getName());
    }
    
    /**
     * 快照完整性验证
     */
    private boolean validateSnapshot(StateSnapshot snapshot) {
        // 1. 校验和验证
        String expectedChecksum = calculateChecksum(snapshot);
        if (!expectedChecksum.equals(snapshot.getChecksum())) {
            log.error("Checksum mismatch for snapshot: {}", snapshot.getSnapshotId());
            return false;
        }
        
        // 2. 必要字段检查
        if (snapshot.getCurrentState() == null || 
            snapshot.getStateMachineId() == null ||
            snapshot.getSessionId() == null) {
            log.error("Missing required fields in snapshot: {}", snapshot.getSnapshotId());
            return false;
        }
        
        // 3. 数据一致性检查
        if (snapshot.getCurrentStep() > snapshot.getMaxSteps()) {
            log.error("Invalid step data in snapshot: {}", snapshot.getSnapshotId());
            return false;
        }
        
        // 4. 时间戳合理性检查
        long currentTime = System.currentTimeMillis();
        if (snapshot.getCreateTime() > currentTime || 
            (currentTime - snapshot.getCreateTime()) > Duration.ofDays(7).toMillis()) {
            log.warn("Snapshot timestamp seems unreasonable: {}", snapshot.getSnapshotId());
        }
        
        return true;
    }
    
    /**
     * 计算快照校验和
     */
    private String calculateChecksum(StateSnapshot snapshot) {
        try {
            // 创建快照副本并清空校验和字段
            StateSnapshot copy = SerializationUtils.clone(snapshot);
            copy.setChecksum(null);
            
            // 序列化并计算SHA-256
            String json = objectMapper.writeValueAsString(copy);
            return DigestUtils.sha256Hex(json);
            
        } catch (Exception e) {
            log.error("Failed to calculate snapshot checksum", e);
            return "";
        }
    }
    
    /**
     * 更新快照索引
     */
    private void updateSnapshotIndex(StateSnapshot snapshot) {
        String indexKey = SNAPSHOT_INDEX_PREFIX + snapshot.getSessionId();
        
        SnapshotIndexEntry entry = SnapshotIndexEntry.builder()
            .snapshotId(snapshot.getSnapshotId())
            .stateMachineId(snapshot.getStateMachineId())
            .currentState(snapshot.getCurrentState().name())
            .createTime(snapshot.getCreateTime())
            .version(snapshot.getVersion())
            .build();
        
        // 使用Redis的有序集合维护快照索引
        redisTemplate.opsForZSet().add(indexKey, entry, snapshot.getCreateTime());
        
        // 只保留最近的10个快照
        redisTemplate.opsForZSet().removeRange(indexKey, 0, -11);
    }
}
```

### 1.2 增量快照优化

```java
/**
 * 增量快照管理器 - 优化存储空间和性能
 */
@Component
public class IncrementalSnapshotManager {
    
    /**
     * 增量快照数据结构
     */
    @Data
    @Builder
    public static class IncrementalSnapshot {
        private String snapshotId;
        private String baseSnapshotId;          // 基础快照ID
        private String stateMachineId;
        private long version;
        
        // 增量数据
        private Map<String, Object> changedFields;    // 变更的字段
        private List<String> removedFields;           // 删除的字段
        private List<Message> newMessages;            // 新增的消息
        private Map<String, Object> changedMetadata;  // 变更的元数据
        
        // 快照元信息
        private long createTime;
        private String changeDescription;
        private int changeCount;
        
        public boolean isEmpty() {
            return (changedFields == null || changedFields.isEmpty()) &&
                   (removedFields == null || removedFields.isEmpty()) &&
                   (newMessages == null || newMessages.isEmpty());
        }
    }
    
    /**
     * 创建增量快照
     */
    public IncrementalSnapshot createIncrementalSnapshot(StateSnapshot baseSnapshot, 
                                                        StateSnapshot currentSnapshot) {
        String incrementalId = generateIncrementalSnapshotId();
        
        // 比较两个快照的差异
        Map<String, Object> changedFields = findChangedFields(baseSnapshot, currentSnapshot);
        List<String> removedFields = findRemovedFields(baseSnapshot, currentSnapshot);
        List<Message> newMessages = findNewMessages(baseSnapshot, currentSnapshot);
        
        IncrementalSnapshot incremental = IncrementalSnapshot.builder()
            .snapshotId(incrementalId)
            .baseSnapshotId(baseSnapshot.getSnapshotId())
            .stateMachineId(currentSnapshot.getStateMachineId())
            .version(currentSnapshot.getVersion())
            .changedFields(changedFields)
            .removedFields(removedFields)
            .newMessages(newMessages)
            .createTime(System.currentTimeMillis())
            .changeCount(calculateChangeCount(changedFields, removedFields, newMessages))
            .build();
        
        // 生成变更描述
        incremental.setChangeDescription(generateChangeDescription(incremental));
        
        return incremental;
    }
    
    /**
     * 应用增量快照到基础快照
     */
    public StateSnapshot applyIncrementalSnapshot(StateSnapshot baseSnapshot, 
                                                 IncrementalSnapshot incremental) {
        // 复制基础快照
        StateSnapshot result = SerializationUtils.clone(baseSnapshot);
        result.setVersion(incremental.getVersion());
        result.setSnapshotId(generateSnapshotId(result));
        
        // 应用字段变更
        if (incremental.getChangedFields() != null) {
            result.getStateData().putAll(incremental.getChangedFields());
        }
        
        // 移除已删除的字段
        if (incremental.getRemovedFields() != null) {
            incremental.getRemovedFields().forEach(field -> 
                result.getStateData().remove(field));
        }
        
        // 添加新消息
        if (incremental.getNewMessages() != null) {
            result.getMemoryMessages().addAll(incremental.getNewMessages());
        }
        
        // 更新元数据
        if (incremental.getChangedMetadata() != null) {
            result.getMetadata().putAll(incremental.getChangedMetadata());
        }
        
        // 重新计算校验和
        result.setChecksum(calculateChecksum(result));
        
        return result;
    }
    
    /**
     * 智能快照策略 - 决定何时创建全量快照vs增量快照
     */
    public SnapshotStrategy determineSnapshotStrategy(String stateMachineId) {
        // 获取最近的快照信息
        List<SnapshotInfo> recentSnapshots = getRecentSnapshots(stateMachineId, 5);
        
        if (recentSnapshots.isEmpty()) {
            return SnapshotStrategy.FULL_SNAPSHOT;
        }
        
        // 分析增量快照链的长度
        int incrementalChainLength = countIncrementalChainLength(recentSnapshots);
        
        // 如果增量链太长，创建新的全量快照
        if (incrementalChainLength > 10) {
            return SnapshotStrategy.FULL_SNAPSHOT;
        }
        
        // 分析最近变更的大小
        double averageChangeSize = calculateAverageChangeSize(recentSnapshots);
        
        // 如果变更很大，创建全量快照
        if (averageChangeSize > 0.5) { // 50%的字段发生变更
            return SnapshotStrategy.FULL_SNAPSHOT;
        }
        
        return SnapshotStrategy.INCREMENTAL_SNAPSHOT;
    }
    
    public enum SnapshotStrategy {
        FULL_SNAPSHOT,
        INCREMENTAL_SNAPSHOT
    }
}
```

## 2. 检查点（Checkpoint）设计模式

### 2.1 自动检查点机制

```java
/**
 * 检查点管理器 - 自动创建和管理检查点
 */
@Component
public class CheckpointManager {
    
    /**
     * 检查点配置
     */
    @Data
    @Builder
    public static class CheckpointConfig {
        private boolean enabled = true;
        private Duration interval = Duration.ofMinutes(5);    // 检查点间隔
        private int maxCheckpoints = 20;                      // 最大检查点数量
        private CheckpointTrigger triggerStrategy;            // 触发策略
        private boolean compressOldCheckpoints = true;       // 压缩旧检查点
        private Duration compressionDelay = Duration.ofHours(1);
    }
    
    public enum CheckpointTrigger {
        TIME_BASED,      // 基于时间间隔
        STATE_BASED,     // 基于状态变化
        STEP_BASED,      // 基于执行步数
        HYBRID          // 混合策略
    }
    
    /**
     * 检查点数据结构
     */
    @Data
    @Builder
    public static class Checkpoint {
        private String checkpointId;
        private String stateMachineId;
        private String sessionId;
        private CheckpointType type;
        private StateSnapshot snapshot;
        private long createTime;
        private Map<String, Object> metadata;
        private boolean compressed;
        private long originalSize;
        private long compressedSize;
    }
    
    public enum CheckpointType {
        AUTOMATIC,       // 自动检查点
        MANUAL,         // 手动检查点
        MILESTONE,      // 里程碑检查点
        EMERGENCY       // 紧急检查点
    }
    
    private final Map<String, CheckpointConfig> configs = new ConcurrentHashMap<>();
    private final Map<String, ScheduledFuture<?>> scheduledTasks = new ConcurrentHashMap<>();
    private final ExecutorService checkpointExecutor = Executors.newFixedThreadPool(5);
    
    /**
     * 启动检查点管理
     */
    public void startCheckpointManagement(String stateMachineId, CheckpointConfig config) {
        configs.put(stateMachineId, config);
        
        if (config.isEnabled()) {
            scheduleAutomaticCheckpoints(stateMachineId, config);
            log.info("Checkpoint management started for: {}", stateMachineId);
        }
    }
    
    /**
     * 调度自动检查点创建
     */
    private void scheduleAutomaticCheckpoints(String stateMachineId, CheckpointConfig config) {
        ScheduledFuture<?> task = scheduledExecutorService.scheduleAtFixedRate(() -> {
            try {
                createAutomaticCheckpoint(stateMachineId, config.getTriggerStrategy());
            } catch (Exception e) {
                log.error("Failed to create automatic checkpoint for: " + stateMachineId, e);
            }
        }, config.getInterval().toMillis(), config.getInterval().toMillis(), TimeUnit.MILLISECONDS);
        
        scheduledTasks.put(stateMachineId, task);
    }
    
    /**
     * 创建自动检查点
     */
    private void createAutomaticCheckpoint(String stateMachineId, CheckpointTrigger trigger) {
        BaseAgent agent = getAgent(stateMachineId);
        if (agent == null) {
            log.warn("Agent not found for checkpoint creation: {}", stateMachineId);
            return;
        }
        
        // 检查是否需要创建检查点
        if (!shouldCreateCheckpoint(agent, trigger)) {
            log.debug("Skipping checkpoint creation for: {}", stateMachineId);
            return;
        }
        
        CompletableFuture.runAsync(() -> {
            try {
                Checkpoint checkpoint = createCheckpoint(agent, CheckpointType.AUTOMATIC);
                saveCheckpoint(checkpoint);
                
                // 异步清理旧检查点
                cleanupOldCheckpoints(stateMachineId);
                
                log.info("Automatic checkpoint created: {}", checkpoint.getCheckpointId());
                
            } catch (Exception e) {
                log.error("Failed to create automatic checkpoint", e);
            }
        }, checkpointExecutor);
    }
    
    /**
     * 检查点创建条件判断
     */
    private boolean shouldCreateCheckpoint(BaseAgent agent, CheckpointTrigger trigger) {
        switch (trigger) {
            case TIME_BASED:
                return isTimeForCheckpoint(agent);
                
            case STATE_BASED:
                return hasSignificantStateChange(agent);
                
            case STEP_BASED:
                return isStepMilestone(agent);
                
            case HYBRID:
                return isTimeForCheckpoint(agent) || 
                       hasSignificantStateChange(agent) || 
                       isStepMilestone(agent);
                
            default:
                return true;
        }
    }
    
    /**
     * 创建检查点
     */
    public Checkpoint createCheckpoint(BaseAgent agent, CheckpointType type) {
        String checkpointId = generateCheckpointId(agent);
        
        // 创建状态快照
        StateSnapshot snapshot = snapshotManager.createSnapshot(agent);
        
        Checkpoint checkpoint = Checkpoint.builder()
            .checkpointId(checkpointId)
            .stateMachineId(agent.getName())
            .sessionId(agent.getContext().getSessionId())
            .type(type)
            .snapshot(snapshot)
            .createTime(System.currentTimeMillis())
            .metadata(createCheckpointMetadata(agent, type))
            .compressed(false)
            .build();
        
        // 计算原始大小
        checkpoint.setOriginalSize(calculateCheckpointSize(checkpoint));
        
        return checkpoint;
    }
    
    /**
     * 保存检查点
     */
    public void saveCheckpoint(Checkpoint checkpoint) {
        try {
            String key = "checkpoint:" + checkpoint.getCheckpointId();
            
            // 保存检查点数据
            redisTemplate.opsForValue().set(key, checkpoint, Duration.ofDays(7));
            
            // 更新检查点索引
            updateCheckpointIndex(checkpoint);
            
            // 异步备份
            backupCheckpointAsync(checkpoint);
            
            log.debug("Checkpoint saved: {}", checkpoint.getCheckpointId());
            
        } catch (Exception e) {
            log.error("Failed to save checkpoint: " + checkpoint.getCheckpointId(), e);
            throw e;
        }
    }
    
    /**
     * 从检查点恢复
     */
    public boolean restoreFromCheckpoint(String stateMachineId, String checkpointId) {
        try {
            Checkpoint checkpoint = loadCheckpoint(checkpointId);
            if (checkpoint == null) {
                log.warn("Checkpoint not found: {}", checkpointId);
                return false;
            }
            
            // 如果检查点已压缩，先解压
            if (checkpoint.isCompressed()) {
                checkpoint = decompressCheckpoint(checkpoint);
            }
            
            // 获取Agent实例
            BaseAgent agent = getAgent(stateMachineId);
            if (agent == null) {
                log.error("Agent not found for checkpoint restore: {}", stateMachineId);
                return false;
            }
            
            // 从快照恢复状态
            boolean restored = snapshotManager.restoreFromSnapshot(agent, checkpoint.getSnapshot().getSnapshotId());
            
            if (restored) {
                log.info("Successfully restored from checkpoint: {}", checkpointId);
                
                // 记录恢复事件
                recordRecoveryEvent(stateMachineId, checkpointId);
            }
            
            return restored;
            
        } catch (Exception e) {
            log.error("Failed to restore from checkpoint: " + checkpointId, e);
            return false;
        }
    }
    
    /**
     * 清理旧检查点
     */
    private void cleanupOldCheckpoints(String stateMachineId) {
        CheckpointConfig config = configs.get(stateMachineId);
        if (config == null) return;
        
        try {
            // 获取该状态机的所有检查点
            List<Checkpoint> checkpoints = getCheckpointsByStateMachine(stateMachineId);
            
            // 按创建时间排序，保留最新的检查点
            checkpoints.sort((c1, c2) -> Long.compare(c2.getCreateTime(), c1.getCreateTime()));
            
            // 删除超出最大数量的检查点
            if (checkpoints.size() > config.getMaxCheckpoints()) {
                List<Checkpoint> toDelete = checkpoints.subList(config.getMaxCheckpoints(), checkpoints.size());
                
                for (Checkpoint checkpoint : toDelete) {
                    deleteCheckpoint(checkpoint.getCheckpointId());
                }
                
                log.info("Cleaned up {} old checkpoints for: {}", toDelete.size(), stateMachineId);
            }
            
            // 压缩旧检查点
            if (config.isCompressOldCheckpoints()) {
                compressOldCheckpoints(checkpoints, config.getCompressionDelay());
            }
            
        } catch (Exception e) {
            log.error("Failed to cleanup old checkpoints for: " + stateMachineId, e);
        }
    }
}
```

### 2.2 检查点压缩与优化

```java
/**
 * 检查点压缩管理器
 */
@Component
public class CheckpointCompressionManager {
    
    /**
     * 压缩算法枚举
     */
    public enum CompressionAlgorithm {
        GZIP("gzip", "java.util.zip.GZIPOutputStream"),
        LZ4("lz4", "net.jpountz.lz4.LZ4OutputStream"), 
        SNAPPY("snappy", "org.xerial.snappy.SnappyOutputStream");
        
        private final String name;
        private final String className;
        
        CompressionAlgorithm(String name, String className) {
            this.name = name;
            this.className = className;
        }
    }
    
    /**
     * 压缩检查点
     */
    public Checkpoint compressCheckpoint(Checkpoint checkpoint) {
        if (checkpoint.isCompressed()) {
            log.warn("Checkpoint is already compressed: {}", checkpoint.getCheckpointId());
            return checkpoint;
        }
        
        try {
            // 选择最优压缩算法
            CompressionAlgorithm algorithm = selectOptimalAlgorithm(checkpoint);
            
            // 序列化检查点数据
            byte[] originalData = serializeCheckpoint(checkpoint);
            
            // 执行压缩
            byte[] compressedData = compressData(originalData, algorithm);
            
            // 创建压缩后的检查点
            Checkpoint compressedCheckpoint = SerializationUtils.clone(checkpoint);
            compressedCheckpoint.setSnapshot(null); // 清除原始快照数据
            compressedCheckpoint.setCompressed(true);
            compressedCheckpoint.setOriginalSize(originalData.length);
            compressedCheckpoint.setCompressedSize(compressedData.length);
            
            // 保存压缩数据
            saveCompressedData(checkpoint.getCheckpointId(), compressedData, algorithm);
            
            double compressionRatio = (double) compressedData.length / originalData.length;
            log.info("Checkpoint compressed: {} (ratio: {:.2f})", 
                checkpoint.getCheckpointId(), compressionRatio);
            
            return compressedCheckpoint;
            
        } catch (Exception e) {
            log.error("Failed to compress checkpoint: " + checkpoint.getCheckpointId(), e);
            return checkpoint;
        }
    }
    
    /**
     * 解压检查点
     */
    public Checkpoint decompressCheckpoint(Checkpoint compressedCheckpoint) {
        if (!compressedCheckpoint.isCompressed()) {
            return compressedCheckpoint;
        }
        
        try {
            // 加载压缩数据
            CompressedCheckpointData compressedData = loadCompressedData(compressedCheckpoint.getCheckpointId());
            
            // 解压数据
            byte[] originalData = decompressData(compressedData.getData(), compressedData.getAlgorithm());
            
            // 反序列化检查点
            Checkpoint originalCheckpoint = deserializeCheckpoint(originalData);
            
            log.debug("Checkpoint decompressed: {}", compressedCheckpoint.getCheckpointId());
            
            return originalCheckpoint;
            
        } catch (Exception e) {
            log.error("Failed to decompress checkpoint: " + compressedCheckpoint.getCheckpointId(), e);
            throw new RuntimeException("Checkpoint decompression failed", e);
        }
    }
    
    /**
     * 选择最优压缩算法
     */
    private CompressionAlgorithm selectOptimalAlgorithm(Checkpoint checkpoint) {
        long checkpointSize = calculateCheckpointSize(checkpoint);
        
        // 根据数据大小选择算法
        if (checkpointSize < 1024 * 1024) { // < 1MB
            return CompressionAlgorithm.LZ4; // 快速压缩
        } else if (checkpointSize < 10 * 1024 * 1024) { // < 10MB
            return CompressionAlgorithm.SNAPPY; // 平衡压缩比和速度
        } else {
            return CompressionAlgorithm.GZIP; // 高压缩比
        }
    }
    
    /**
     * 数据压缩
     */
    private byte[] compressData(byte[] data, CompressionAlgorithm algorithm) throws IOException {
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        
        switch (algorithm) {
            case GZIP:
                try (GZIPOutputStream gzipOut = new GZIPOutputStream(baos)) {
                    gzipOut.write(data);
                }
                break;
                
            case LZ4:
                // LZ4压缩实现
                return compressWithLZ4(data);
                
            case SNAPPY:
                // Snappy压缩实现
                return compressWithSnappy(data);
        }
        
        return baos.toByteArray();
    }
    
    /**
     * 自适应压缩策略
     */
    public CompressedCheckpointData compressWithAdaptiveStrategy(Checkpoint checkpoint) {
        // 尝试不同的压缩算法，选择最优结果
        Map<CompressionAlgorithm, CompressedCheckpointData> results = new HashMap<>();
        
        byte[] originalData = serializeCheckpoint(checkpoint);
        
        for (CompressionAlgorithm algorithm : CompressionAlgorithm.values()) {
            try {
                long startTime = System.currentTimeMillis();
                byte[] compressed = compressData(originalData, algorithm);
                long compressionTime = System.currentTimeMillis() - startTime;
                
                results.put(algorithm, CompressedCheckpointData.builder()
                    .algorithm(algorithm)
                    .data(compressed)
                    .originalSize(originalData.length)
                    .compressedSize(compressed.length)
                    .compressionTime(compressionTime)
                    .build());
                    
            } catch (Exception e) {
                log.warn("Compression failed with algorithm: {}", algorithm, e);
            }
        }
        
        // 选择最优结果（综合考虑压缩比和压缩时间）
        return results.values().stream()
            .min((r1, r2) -> {
                double score1 = calculateCompressionScore(r1);
                double score2 = calculateCompressionScore(r2);
                return Double.compare(score1, score2);
            })
            .orElseThrow(() -> new RuntimeException("All compression algorithms failed"));
    }
    
    /**
     * 计算压缩得分（综合压缩比和性能）
     */
    private double calculateCompressionScore(CompressedCheckpointData data) {
        double compressionRatio = (double) data.getCompressedSize() / data.getOriginalSize();
        double timeWeight = data.getCompressionTime() / 1000.0; // 转换为秒
        
        // 综合得分：压缩比权重70%，时间权重30%
        return compressionRatio * 0.7 + timeWeight * 0.3;
    }
}
```

## 3. 分布式状态存储的一致性保障

### 3.1 分布式状态一致性协议

```java
/**
 * 分布式状态一致性管理器
 */
@Component
public class DistributedStateConsistencyManager {
    
    /**
     * 一致性级别定义
     */
    public enum ConsistencyLevel {
        EVENTUAL,    // 最终一致性
        STRONG,      // 强一致性
        BOUNDED,     // 有界一致性
        CAUSAL       // 因果一致性
    }
    
    /**
     * 分布式状态存储配置
     */
    @Data
    @Builder
    public static class DistributedStateConfig {
        private ConsistencyLevel consistencyLevel = ConsistencyLevel.EVENTUAL;
        private int replicationFactor = 3;           // 副本数量
        private Duration writeTimeout = Duration.ofSeconds(5);
        private Duration readTimeout = Duration.ofSeconds(3);
        private boolean enableVersionVectors = true;  // 启用版本向量
        private int maxRetries = 3;
    }
    
    /**
     * 版本向量用于跟踪分布式更新
     */
    @Data
    @Builder
    public static class VersionVector {
        private Map<String, Long> nodeVersions;
        private long timestamp;
        
        /**
         * 比较版本向量，确定因果关系
         */
        public CausalRelation compareTo(VersionVector other) {
            boolean thisGreater = false;
            boolean otherGreater = false;
            
            Set<String> allNodes = new HashSet<>();
            allNodes.addAll(this.nodeVersions.keySet());
            allNodes.addAll(other.nodeVersions.keySet());
            
            for (String node : allNodes) {
                long thisVersion = this.nodeVersions.getOrDefault(node, 0L);
                long otherVersion = other.nodeVersions.getOrDefault(node, 0L);
                
                if (thisVersion > otherVersion) {
                    thisGreater = true;
                } else if (thisVersion < otherVersion) {
                    otherGreater = true;
                }
            }
            
            if (thisGreater && !otherGreater) {
                return CausalRelation.AFTER;
            } else if (!thisGreater && otherGreater) {
                return CausalRelation.BEFORE;
            } else if (!thisGreater && !otherGreater) {
                return CausalRelation.EQUAL;
            } else {
                return CausalRelation.CONCURRENT;
            }
        }
    }
    
    public enum CausalRelation {
        BEFORE, AFTER, EQUAL, CONCURRENT
    }
    
    /**
     * 分布式状态写入（强一致性）
     */
    public CompletableFuture<Boolean> writeStateWithStrongConsistency(
            String stateId, Object state, DistributedStateConfig config) {
        
        return CompletableFuture.supplyAsync(() -> {
            try {
                // 1. 生成唯一的写入事务ID
                String transactionId = generateTransactionId();
                
                // 2. 准备阶段：向所有副本节点发送预写请求
                List<String> replicaNodes = selectReplicaNodes(stateId, config.getReplicationFactor());
                List<CompletableFuture<Boolean>> prepareFutures = replicaNodes.stream()
                    .map(node -> sendPrepareRequest(node, transactionId, stateId, state))
                    .collect(Collectors.toList());
                
                // 3. 等待所有副本确认准备就绪
                List<Boolean> prepareResults = prepareFutures.stream()
                    .map(future -> {
                        try {
                            return future.get(config.getWriteTimeout().toMillis(), TimeUnit.MILLISECONDS);
                        } catch (Exception e) {
                            log.error("Prepare phase failed for transaction: " + transactionId, e);
                            return false;
                        }
                    })
                    .collect(Collectors.toList());
                
                // 4. 检查是否所有副本都准备就绪
                boolean allPrepared = prepareResults.stream().allMatch(Boolean::booleanValue);
                
                if (allPrepared) {
                    // 5. 提交阶段：向所有副本发送提交请求
                    List<CompletableFuture<Boolean>> commitFutures = replicaNodes.stream()
                        .map(node -> sendCommitRequest(node, transactionId))
                        .collect(Collectors.toList());
                    
                    // 等待提交完成
                    boolean allCommitted = commitFutures.stream()
                        .allMatch(future -> {
                            try {
                                return future.get(config.getWriteTimeout().toMillis(), TimeUnit.MILLISECONDS);
                            } catch (Exception e) {
                                log.error("Commit phase failed for transaction: " + transactionId, e);
                                return false;
                            }
                        });
                    
                    if (allCommitted) {
                        log.info("Strong consistent write completed: {}", stateId);
                        return true;
                    } else {
                        log.error("Commit phase failed, rolling back transaction: {}", transactionId);
                        rollbackTransaction(transactionId, replicaNodes);
                        return false;
                    }
                } else {
                    // 6. 中止事务：有副本未准备就绪
                    log.warn("Not all replicas are ready, aborting transaction: {}", transactionId);
                    abortTransaction(transactionId, replicaNodes);
                    return false;
                }
                
            } catch (Exception e) {
                log.error("Strong consistent write failed for state: " + stateId, e);
                return false;
            }
        });
    }
    
    /**
     * 分布式状态读取（一致性读）
     */
    public CompletableFuture<Optional<Object>> readStateWithConsistency(
            String stateId, ConsistencyLevel level, DistributedStateConfig config) {
        
        return CompletableFuture.supplyAsync(() -> {
            try {
                switch (level) {
                    case STRONG:
                        return readWithStrongConsistency(stateId, config);
                    case BOUNDED:
                        return readWithBoundedConsistency(stateId, config);
                    case CAUSAL:
                        return readWithCausalConsistency(stateId, config);
                    case EVENTUAL:
                    default:
                        return readWithEventualConsistency(stateId, config);
                }
            } catch (Exception e) {
                log.error("Consistent read failed for state: " + stateId, e);
                return Optional.empty();
            }
        });
    }
    
    /**
     * 强一致性读取
     */
    private Optional<Object> readWithStrongConsistency(String stateId, DistributedStateConfig config) {
        // 从多数派副本读取，确保读取到最新值
        List<String> replicaNodes = selectReplicaNodes(stateId, config.getReplicationFactor());
        int majoritySize = replicaNodes.size() / 2 + 1;
        
        List<CompletableFuture<StateReadResult>> readFutures = replicaNodes.stream()
            .map(node -> readFromNode(node, stateId))
            .collect(Collectors.toList());
        
        // 收集读取结果
        List<StateReadResult> results = new ArrayList<>();
        for (int i = 0; i < readFutures.size() && results.size() < majoritySize; i++) {
            try {
                StateReadResult result = readFutures.get(i).get(
                    config.getReadTimeout().toMillis(), TimeUnit.MILLISECONDS);
                if (result != null && result.isSuccess()) {
                    results.add(result);
                }
            } catch (Exception e) {
                log.warn("Failed to read from replica node", e);
            }
        }
        
        if (results.size() < majoritySize) {
            log.error("Unable to achieve majority read for state: {}", stateId);
            return Optional.empty();
        }
        
        // 选择版本最高的结果
        return results.stream()
            .max(Comparator.comparing(StateReadResult::getVersion))
            .map(StateReadResult::getValue);
    }
    
    /**
     * 因果一致性读取
     */
    private Optional<Object> readWithCausalConsistency(String stateId, DistributedStateConfig config) {
        // 获取客户端的版本向量
        VersionVector clientVector = getCurrentClientVersionVector();
        
        List<String> replicaNodes = selectReplicaNodes(stateId, config.getReplicationFactor());
        
        // 寻找满足因果关系的副本
        for (String node : replicaNodes) {
            try {
                StateReadResult result = readFromNode(node, stateId)
                    .get(config.getReadTimeout().toMillis(), TimeUnit.MILLISECONDS);
                
                if (result != null && result.isSuccess()) {
                    VersionVector resultVector = result.getVersionVector();
                    
                    // 检查因果关系
                    if (resultVector.compareTo(clientVector) != CausalRelation.BEFORE) {
                        return Optional.of(result.getValue());
                    }
                }
            } catch (Exception e) {
                log.warn("Failed to read from node: {}", node, e);
            }
        }
        
        log.warn("No replica satisfies causal consistency for state: {}", stateId);
        return Optional.empty();
    }
    
    /**
     * 冲突检测与解决
     */
    public Object resolveConflict(String stateId, List<Object> conflictingValues) {
        // 获取冲突解决策略
        ConflictResolutionStrategy strategy = getConflictResolutionStrategy(stateId);
        
        switch (strategy) {
            case LAST_WRITER_WINS:
                return resolveWithLastWriterWins(conflictingValues);
                
            case MULTI_VALUE:
                return resolveWithMultiValue(conflictingValues);
                
            case CUSTOM:
                return resolveWithCustomLogic(stateId, conflictingValues);
                
            default:
                log.warn("Unknown conflict resolution strategy, using last writer wins");
                return resolveWithLastWriterWins(conflictingValues);
        }
    }
    
    public enum ConflictResolutionStrategy {
        LAST_WRITER_WINS,    // 最后写入获胜
        MULTI_VALUE,         // 保留多值
        CUSTOM              // 自定义解决逻辑
    }
}
```

### 3.2 网络分区处理

```java
/**
 * 网络分区处理器
 */
@Component
public class NetworkPartitionHandler {
    
    /**
     * 分区检测器
     */
    @Component
    public static class PartitionDetector {
        private final Map<String, NodeHealth> nodeHealthMap = new ConcurrentHashMap<>();
        private final ScheduledExecutorService detector = Executors.newSingleThreadScheduledExecutor();
        
        @Data
        @Builder
        public static class NodeHealth {
            private String nodeId;
            private boolean reachable;
            private long lastHeartbeat;
            private int consecutiveFailures;
            private Duration detectionTimeout = Duration.ofSeconds(30);
        }
        
        @PostConstruct
        public void startPartitionDetection() {
            detector.scheduleAtFixedRate(this::detectPartitions, 10, 10, TimeUnit.SECONDS);
        }
        
        /**
         * 检测网络分区
         */
        private void detectPartitions() {
            List<String> allNodes = getAllKnownNodes();
            Map<String, Set<String>> partitions = new HashMap<>();
            
            for (String node : allNodes) {
                try {
                    // 检查节点可达性
                    boolean reachable = pingNode(node);
                    updateNodeHealth(node, reachable);
                    
                    if (reachable) {
                        // 获取该节点能看到的其他节点
                        Set<String> visibleNodes = getVisibleNodes(node);
                        partitions.put(node, visibleNodes);
                    }
                } catch (Exception e) {
                    log.warn("Failed to check node health: {}", node, e);
                    updateNodeHealth(node, false);
                }
            }
            
            // 分析分区情况
            analyzePartitions(partitions);
        }
        
        /**
         * 分析分区情况
         */
        private void analyzePartitions(Map<String, Set<String>> nodeVisibility) {
            // 使用并查集算法检测分区
            UnionFind uf = new UnionFind(nodeVisibility.keySet());
            
            for (Map.Entry<String, Set<String>> entry : nodeVisibility.entrySet()) {
                String node = entry.getKey();
                Set<String> visibleNodes = entry.getValue();
                
                for (String visibleNode : visibleNodes) {
                    if (nodeVisibility.containsKey(visibleNode)) {
                        uf.union(node, visibleNode);
                    }
                }
            }
            
            // 获取分区信息
            Map<String, Set<String>> partitions = uf.getPartitions();
            
            if (partitions.size() > 1) {
                log.warn("Network partition detected: {} partitions", partitions.size());
                handleNetworkPartition(partitions);
            } else {
                log.debug("No network partition detected");
            }
        }
        
        /**
         * 处理网络分区
         */
        private void handleNetworkPartition(Map<String, Set<String>> partitions) {
            // 找到最大的分区作为主分区
            Set<String> majorityPartition = partitions.values().stream()
                .max(Comparator.comparing(Set::size))
                .orElse(new HashSet<>());
            
            String currentNode = getCurrentNodeId();
            boolean inMajorityPartition = majorityPartition.contains(currentNode);
            
            if (inMajorityPartition) {
                log.info("Current node is in majority partition, continuing normal operations");
                // 继续正常操作，但禁止与少数派分区通信
                blockMinorityPartitions(partitions, majorityPartition);
            } else {
                log.warn("Current node is in minority partition, entering read-only mode");
                // 进入只读模式，停止状态写入
                enterReadOnlyMode();
            }
            
            // 通知应用程序分区事件
            publishPartitionEvent(partitions, majorityPartition);
        }
        
        /**
         * 进入只读模式
         */
        private void enterReadOnlyMode() {
            // 停止状态写入操作
            stateWriteService.setReadOnlyMode(true);
            
            // 暂停检查点创建
            checkpointManager.pauseCheckpointCreation();
            
            // 记录分区事件
            auditLogger.logPartitionEvent("MINORITY_PARTITION_DETECTED", getCurrentNodeId());
        }
    }
    
    /**
     * 分区恢复处理
     */
    @Component
    public static class PartitionRecoveryHandler {
        
        /**
         * 检测分区恢复
         */
        public void handlePartitionRecovery() {
            log.info("Network partition recovery detected, starting state reconciliation");
            
            try {
                // 1. 恢复节点通信
                restoreNodeCommunication();
                
                // 2. 状态同步
                reconcileStates();
                
                // 3. 恢复正常操作
                resumeNormalOperations();
                
                log.info("Partition recovery completed successfully");
                
            } catch (Exception e) {
                log.error("Partition recovery failed", e);
                // 可能需要人工干预
                alertOperations("PARTITION_RECOVERY_FAILED", e.getMessage());
            }
        }
        
        /**
         * 状态协调
         */
        private void reconcileStates() {
            List<String> allNodes = getAllKnownNodes();
            
            // 收集所有节点的状态版本信息
            Map<String, Map<String, Long>> nodeStateVersions = new HashMap<>();
            
            for (String node : allNodes) {
                try {
                    Map<String, Long> stateVersions = getStateVersionsFromNode(node);
                    nodeStateVersions.put(node, stateVersions);
                } catch (Exception e) {
                    log.warn("Failed to get state versions from node: {}", node, e);
                }
            }
            
            // 找出需要同步的状态
            Set<String> statesToSync = findStatesNeedingSync(nodeStateVersions);
            
            // 执行状态同步
            for (String stateId : statesToSync) {
                try {
                    syncStateAcrossNodes(stateId, allNodes);
                } catch (Exception e) {
                    log.error("Failed to sync state: {}", stateId, e);
                }
            }
        }
        
        /**
         * 跨节点同步状态
         */
        private void syncStateAcrossNodes(String stateId, List<String> nodes) {
            // 收集所有版本的状态
            Map<Long, Object> stateVersions = new HashMap<>();
            
            for (String node : nodes) {
                try {
                    StateReadResult result = readStateFromNode(node, stateId);
                    if (result != null && result.isSuccess()) {
                        stateVersions.put(result.getVersion(), result.getValue());
                    }
                } catch (Exception e) {
                    log.warn("Failed to read state from node: {}", node, e);
                }
            }
            
            if (stateVersions.isEmpty()) {
                log.warn("No valid state versions found for: {}", stateId);
                return;
            }
            
            // 选择最新版本的状态
            Long latestVersion = Collections.max(stateVersions.keySet());
            Object latestState = stateVersions.get(latestVersion);
            
            // 将最新状态同步到所有节点
            for (String node : nodes) {
                try {
                    writeStateToNode(node, stateId, latestState, latestVersion);
                } catch (Exception e) {
                    log.error("Failed to sync state to node: {}", node, e);
                }
            }
            
            log.info("State synchronized across nodes: {} (version: {})", stateId, latestVersion);
        }
    }
}
```

## 4. 故障转移与自动恢复策略

### 4.1 故障检测与分类

```java
/**
 * 故障检测与分类系统
 */
@Component
public class FailureDetectionSystem {
    
    /**
     * 故障类型枚举
     */
    public enum FailureType {
        NODE_FAILURE("节点故障", FailureSeverity.HIGH),
        NETWORK_PARTITION("网络分区", FailureSeverity.HIGH),
        STATE_CORRUPTION("状态损坏", FailureSeverity.CRITICAL),
        PERFORMANCE_DEGRADATION("性能下降", FailureSeverity.MEDIUM),
        RESOURCE_EXHAUSTION("资源耗尽", FailureSeverity.HIGH),
        TIMEOUT("超时", FailureSeverity.MEDIUM),
        DATA_INCONSISTENCY("数据不一致", FailureSeverity.HIGH);
        
        private final String description;
        private final FailureSeverity severity;
        
        FailureType(String description, FailureSeverity severity) {
            this.description = description;
            this.severity = severity;
        }
    }
    
    public enum FailureSeverity {
        LOW, MEDIUM, HIGH, CRITICAL
    }
    
    /**
     * 故障事件
     */
    @Data
    @Builder
    public static class FailureEvent {
        private String eventId;
        private FailureType type;
        private FailureSeverity severity;
        private String affectedComponent;
        private String description;
        private Map<String, Object> context;
        private long detectionTime;
        private String detectingNode;
        private boolean resolved;
        private long resolutionTime;
    }
    
    private final Map<FailureType, FailureDetector> detectors = new HashMap<>();
    private final BlockingQueue<FailureEvent> failureQueue = new LinkedBlockingQueue<>();
    private final ExecutorService detectionExecutor = Executors.newFixedThreadPool(3);
    
    @PostConstruct
    public void initializeDetectors() {
        // 注册各种故障检测器
        detectors.put(FailureType.NODE_FAILURE, new NodeFailureDetector());
        detectors.put(FailureType.STATE_CORRUPTION, new StateCorruptionDetector());
        detectors.put(FailureType.PERFORMANCE_DEGRADATION, new PerformanceDegradationDetector());
        detectors.put(FailureType.RESOURCE_EXHAUSTION, new ResourceExhaustionDetector());
        
        // 启动故障检测
        startFailureDetection();
        
        // 启动故障处理
        startFailureHandling();
    }
    
    /**
     * 节点故障检测器
     */
    public static class NodeFailureDetector implements FailureDetector {
        
        @Override
        public List<FailureEvent> detectFailures() {
            List<FailureEvent> failures = new ArrayList<>();
            
            List<String> allNodes = getAllKnownNodes();
            for (String node : allNodes) {
                try {
                    boolean isHealthy = checkNodeHealth(node);
                    if (!isHealthy) {
                        failures.add(FailureEvent.builder()
                            .eventId(UUID.randomUUID().toString())
                            .type(FailureType.NODE_FAILURE)
                            .severity(FailureSeverity.HIGH)
                            .affectedComponent(node)
                            .description("Node is not responding to health checks")
                            .detectionTime(System.currentTimeMillis())
                            .detectingNode(getCurrentNodeId())
                            .build());
                    }
                } catch (Exception e) {
                    log.error("Error checking node health: {}", node, e);
                }
            }
            
            return failures;
        }
        
        private boolean checkNodeHealth(String node) {
            try {
                // 发送心跳请求
                CompletableFuture<Boolean> healthCheck = sendHeartbeat(node);
                return healthCheck.get(5, TimeUnit.SECONDS);
            } catch (Exception e) {
                return false;
            }
        }
    }
    
    /**
     * 状态损坏检测器
     */
    public static class StateCorruptionDetector implements FailureDetector {
        
        @Override
        public List<FailureEvent> detectFailures() {
            List<FailureEvent> failures = new ArrayList<>();
            
            // 获取所有活跃的状态机
            List<String> stateMachineIds = getActiveStateMachines();
            
            for (String stateMachineId : stateMachineIds) {
                try {
                    // 验证状态完整性
                    StateIntegrityResult result = validateStateIntegrity(stateMachineId);
                    
                    if (!result.isValid()) {
                        failures.add(FailureEvent.builder()
                            .eventId(UUID.randomUUID().toString())
                            .type(FailureType.STATE_CORRUPTION)
                            .severity(FailureSeverity.CRITICAL)
                            .affectedComponent(stateMachineId)
                            .description("State corruption detected: " + result.getErrorMessage())
                            .context(Map.of("validationDetails", result.getValidationDetails()))
                            .detectionTime(System.currentTimeMillis())
                            .detectingNode(getCurrentNodeId())
                            .build());
                    }
                } catch (Exception e) {
                    log.error("Error validating state integrity: {}", stateMachineId, e);
                }
            }
            
            return failures;
        }
        
        private StateIntegrityResult validateStateIntegrity(String stateMachineId) {
            try {
                // 加载状态数据
                StateSnapshot snapshot = snapshotManager.getCurrentSnapshot(stateMachineId);
                if (snapshot == null) {
                    return StateIntegrityResult.invalid("No snapshot found");
                }
                
                // 验证校验和
                String expectedChecksum = calculateChecksum(snapshot);
                if (!expectedChecksum.equals(snapshot.getChecksum())) {
                    return StateIntegrityResult.invalid("Checksum mismatch");
                }
                
                // 验证状态数据结构
                if (!validateStateStructure(snapshot)) {
                    return StateIntegrityResult.invalid("Invalid state structure");
                }
                
                // 验证状态转换历史
                if (!validateStateHistory(snapshot)) {
                    return StateIntegrityResult.invalid("Invalid state transition history");
                }
                
                return StateIntegrityResult.valid();
                
            } catch (Exception e) {
                return StateIntegrityResult.invalid("Validation error: " + e.getMessage());
            }
        }
    }
    
    /**
     * 启动故障检测
     */
    private void startFailureDetection() {
        ScheduledExecutorService detectionScheduler = Executors.newSingleThreadScheduledExecutor();
        
        detectionScheduler.scheduleAtFixedRate(() -> {
            for (Map.Entry<FailureType, FailureDetector> entry : detectors.entrySet()) {
                CompletableFuture.runAsync(() -> {
                    try {
                        List<FailureEvent> failures = entry.getValue().detectFailures();
                        failures.forEach(failureQueue::offer);
                    } catch (Exception e) {
                        log.error("Failure detection error for type: {}", entry.getKey(), e);
                    }
                }, detectionExecutor);
            }
        }, 10, 30, TimeUnit.SECONDS);
    }
    
    /**
     * 启动故障处理
     */
    private void startFailureHandling() {
        CompletableFuture.runAsync(() -> {
            while (!Thread.currentThread().isInterrupted()) {
                try {
                    FailureEvent failure = failureQueue.take();
                    handleFailure(failure);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    break;
                } catch (Exception e) {
                    log.error("Error handling failure event", e);
                }
            }
        });
    }
    
    /**
     * 处理故障事件
     */
    private void handleFailure(FailureEvent failure) {
        log.warn("Handling failure event: {} - {}", failure.getType(), failure.getDescription());
        
        try {
            // 根据故障类型选择恢复策略
            RecoveryStrategy strategy = selectRecoveryStrategy(failure);
            
            // 执行恢复操作
            RecoveryResult result = strategy.recover(failure);
            
            if (result.isSuccessful()) {
                failure.setResolved(true);
                failure.setResolutionTime(System.currentTimeMillis());
                log.info("Failure resolved successfully: {}", failure.getEventId());
            } else {
                log.error("Failure recovery failed: {} - {}", 
                    failure.getEventId(), result.getErrorMessage());
                
                // 升级故障处理
                escalateFailure(failure, result);
            }
            
        } catch (Exception e) {
            log.error("Exception during failure handling: " + failure.getEventId(), e);
            escalateFailure(failure, RecoveryResult.failure("Exception: " + e.getMessage()));
        }
    }
}
```

### 4.2 自动恢复策略实现

```java
/**
 * 自动恢复策略管理器
 */
@Component
public class AutoRecoveryStrategyManager {
    
    /**
     * 恢复策略接口
     */
    public interface RecoveryStrategy {
        RecoveryResult recover(FailureEvent failure);
        boolean canHandle(FailureType failureType);
        int getPriority(); // 优先级，数字越小优先级越高
    }
    
    /**
     * 恢复结果
     */
    @Data
    @Builder
    public static class RecoveryResult {
        private boolean successful;
        private String message;
        private String errorMessage;
        private Map<String, Object> metrics;
        private long recoveryTime;
        
        public static RecoveryResult success(String message) {
            return RecoveryResult.builder()
                .successful(true)
                .message(message)
                .recoveryTime(System.currentTimeMillis())
                .build();
        }
        
        public static RecoveryResult failure(String errorMessage) {
            return RecoveryResult.builder()
                .successful(false)
                .errorMessage(errorMessage)
                .recoveryTime(System.currentTimeMillis())
                .build();
        }
    }
    
    /**
     * 节点故障恢复策略
     */
    @Component
    public static class NodeFailureRecoveryStrategy implements RecoveryStrategy {
        
        @Override
        public RecoveryResult recover(FailureEvent failure) {
            String failedNode = failure.getAffectedComponent();
            
            try {
                log.info("Starting node failure recovery for: {}", failedNode);
                
                // 1. 将失败节点标记为不可用
                markNodeAsUnavailable(failedNode);
                
                // 2. 重新分配失败节点上的状态机
                List<String> affectedStateMachines = getStateMachinesOnNode(failedNode);
                
                Map<String, String> reassignmentResults = new HashMap<>();
                for (String stateMachineId : affectedStateMachines) {
                    try {
                        String targetNode = selectBestTargetNode(stateMachineId, failedNode);
                        boolean migrated = migrateStateMachine(stateMachineId, failedNode, targetNode);
                        
                        reassignmentResults.put(stateMachineId, migrated ? targetNode : "FAILED");
                        
                    } catch (Exception e) {
                        log.error("Failed to migrate state machine: {}", stateMachineId, e);
                        reassignmentResults.put(stateMachineId, "ERROR: " + e.getMessage());
                    }
                }
                
                // 3. 更新服务发现信息
                updateServiceDiscovery(failedNode, false);
                
                // 4. 通知其他组件
                notifyNodeFailure(failedNode, reassignmentResults);
                
                return RecoveryResult.success(
                    String.format("Node failure recovery completed: %d state machines reassigned", 
                        affectedStateMachines.size()))
                    .toBuilder()
                    .metrics(Map.of(
                        "failedNode", failedNode,
                        "reassignedStateMachines", reassignmentResults.size(),
                        "reassignmentDetails", reassignmentResults
                    ))
                    .build();
                
            } catch (Exception e) {
                log.error("Node failure recovery failed for: " + failedNode, e);
                return RecoveryResult.failure("Recovery failed: " + e.getMessage());
            }
        }
        
        /**
         * 迁移状态机到新节点
         */
        private boolean migrateStateMachine(String stateMachineId, String fromNode, String toNode) {
            try {
                // 1. 从失败节点获取最新的状态快照
                StateSnapshot snapshot = getLatestSnapshotFromBackup(stateMachineId);
                
                if (snapshot == null) {
                    log.warn("No snapshot found for state machine: {}", stateMachineId);
                    return false;
                }
                
                // 2. 在目标节点创建新的状态机实例
                boolean created = createStateMachineOnNode(toNode, stateMachineId, snapshot);
                
                if (!created) {
                    log.error("Failed to create state machine on target node: {}", toNode);
                    return false;
                }
                
                // 3. 更新路由信息
                updateRoutingTable(stateMachineId, fromNode, toNode);
                
                log.info("State machine migrated successfully: {} from {} to {}", 
                    stateMachineId, fromNode, toNode);
                
                return true;
                
            } catch (Exception e) {
                log.error("State machine migration failed: " + stateMachineId, e);
                return false;
            }
        }
        
        @Override
        public boolean canHandle(FailureType failureType) {
            return failureType == FailureType.NODE_FAILURE;
        }
        
        @Override
        public int getPriority() {
            return 1; // 高优先级
        }
    }
    
    /**
     * 状态损坏恢复策略
     */
    @Component
    public static class StateCorruptionRecoveryStrategy implements RecoveryStrategy {
        
        @Override
        public RecoveryResult recover(FailureEvent failure) {
            String stateMachineId = failure.getAffectedComponent();
            
            try {
                log.info("Starting state corruption recovery for: {}", stateMachineId);
                
                // 1. 停止受影响的状态机
                boolean stopped = stopStateMachine(stateMachineId);
                if (!stopped) {
                    return RecoveryResult.failure("Failed to stop corrupted state machine");
                }
                
                // 2. 尝试从检查点恢复
                RecoveryResult checkpointRecovery = recoverFromCheckpoint(stateMachineId);
                if (checkpointRecovery.isSuccessful()) {
                    return checkpointRecovery;
                }
                
                // 3. 尝试从副本节点恢复
                RecoveryResult replicaRecovery = recoverFromReplica(stateMachineId);
                if (replicaRecovery.isSuccessful()) {
                    return replicaRecovery;
                }
                
                // 4. 尝试从备份恢复
                RecoveryResult backupRecovery = recoverFromBackup(stateMachineId);
                if (backupRecovery.isSuccessful()) {
                    return backupRecovery;
                }
                
                // 5. 如果所有恢复方法都失败，创建新的状态机实例
                log.warn("All recovery methods failed, creating new instance: {}", stateMachineId);
                boolean newInstanceCreated = createNewStateMachineInstance(stateMachineId);
                
                if (newInstanceCreated) {
                    return RecoveryResult.success("New state machine instance created")
                        .toBuilder()
                        .message("WARNING: Previous state lost, created new instance")
                        .build();
                } else {
                    return RecoveryResult.failure("Failed to create new state machine instance");
                }
                
            } catch (Exception e) {
                log.error("State corruption recovery failed for: " + stateMachineId, e);
                return RecoveryResult.failure("Recovery exception: " + e.getMessage());
            }
        }
        
        /**
         * 从检查点恢复
         */
        private RecoveryResult recoverFromCheckpoint(String stateMachineId) {
            try {
                // 获取最近的有效检查点
                List<Checkpoint> checkpoints = checkpointManager.getCheckpointsByStateMachine(stateMachineId);
                
                for (Checkpoint checkpoint : checkpoints) {
                    try {
                        // 验证检查点完整性
                        if (validateCheckpointIntegrity(checkpoint)) {
                            // 尝试从检查点恢复
                            boolean restored = checkpointManager.restoreFromCheckpoint(stateMachineId, checkpoint.getCheckpointId());
                            
                            if (restored) {
                                log.info("Successfully recovered from checkpoint: {}", checkpoint.getCheckpointId());
                                return RecoveryResult.success("Recovered from checkpoint: " + checkpoint.getCheckpointId());
                            }
                        }
                    } catch (Exception e) {
                        log.warn("Failed to restore from checkpoint: {}", checkpoint.getCheckpointId(), e);
                    }
                }
                
                return RecoveryResult.failure("No valid checkpoints available");
                
            } catch (Exception e) {
                log.error("Checkpoint recovery failed for: " + stateMachineId, e);
                return RecoveryResult.failure("Checkpoint recovery error: " + e.getMessage());
            }
        }
        
        /**
         * 从副本节点恢复
         */
        private RecoveryResult recoverFromReplica(String stateMachineId) {
            try {
                // 获取状态机的副本节点列表
                List<String> replicaNodes = getReplicaNodes(stateMachineId);
                
                for (String replicaNode : replicaNodes) {
                    try {
                        // 从副本节点获取状态
                        StateSnapshot replicaSnapshot = getSnapshotFromNode(replicaNode, stateMachineId);
                        
                        if (replicaSnapshot != null && validateSnapshot(replicaSnapshot)) {
                            // 使用副本状态恢复本地状态机
                            boolean restored = restoreStateMachineFromSnapshot(stateMachineId, replicaSnapshot);
                            
                            if (restored) {
                                log.info("Successfully recovered from replica node: {}", replicaNode);
                                return RecoveryResult.success("Recovered from replica node: " + replicaNode);
                            }
                        }
                    } catch (Exception e) {
                        log.warn("Failed to recover from replica node: {}", replicaNode, e);
                    }
                }
                
                return RecoveryResult.failure("No valid replicas available");
                
            } catch (Exception e) {
                log.error("Replica recovery failed for: " + stateMachineId, e);
                return RecoveryResult.failure("Replica recovery error: " + e.getMessage());
            }
        }
        
        @Override
        public boolean canHandle(FailureType failureType) {
            return failureType == FailureType.STATE_CORRUPTION;
        }
        
        @Override
        public int getPriority() {
            return 1; // 高优先级
        }
    }
    
    /**
     * 性能下降恢复策略
     */
    @Component
    public static class PerformanceDegradationRecoveryStrategy implements RecoveryStrategy {
        
        @Override
        public RecoveryResult recover(FailureEvent failure) {
            String affectedComponent = failure.getAffectedComponent();
            
            try {
                log.info("Starting performance degradation recovery for: {}", affectedComponent);
                
                // 1. 分析性能问题根因
                PerformanceAnalysis analysis = analyzePerformanceIssue(affectedComponent);
                
                // 2. 根据分析结果选择恢复措施
                List<RecoveryAction> actions = selectRecoveryActions(analysis);
                
                // 3. 执行恢复措施
                List<String> executedActions = new ArrayList<>();
                boolean anyActionSucceeded = false;
                
                for (RecoveryAction action : actions) {
                    try {
                        boolean success = executeRecoveryAction(action, affectedComponent);
                        executedActions.add(action.getName() + ": " + (success ? "SUCCESS" : "FAILED"));
                        
                        if (success) {
                            anyActionSucceeded = true;
                            
                            // 验证性能是否恢复
                            if (verifyPerformanceRecovery(affectedComponent)) {
                                log.info("Performance recovery successful with action: {}", action.getName());
                                break;
                            }
                        }
                    } catch (Exception e) {
                        log.error("Recovery action failed: {}", action.getName(), e);
                        executedActions.add(action.getName() + ": ERROR - " + e.getMessage());
                    }
                }
                
                if (anyActionSucceeded) {
                    return RecoveryResult.success("Performance issues resolved")
                        .toBuilder()
                        .metrics(Map.of(
                            "executedActions", executedActions,
                            "rootCause", analysis.getRootCause()
                        ))
                        .build();
                } else {
                    return RecoveryResult.failure("All recovery actions failed: " + executedActions);
                }
                
            } catch (Exception e) {
                log.error("Performance degradation recovery failed for: " + affectedComponent, e);
                return RecoveryResult.failure("Recovery exception: " + e.getMessage());
            }
        }
        
        @Override
        public boolean canHandle(FailureType failureType) {
            return failureType == FailureType.PERFORMANCE_DEGRADATION;
        }
        
        @Override
        public int getPriority() {
            return 3; // 中等优先级
        }
    }
}
```

## 5. 小结

本节深入探讨了AI应用状态机的持久化与容错机制设计：

### 5.1 关键技术要点

1. **状态快照机制**
   - 全量快照与增量快照的优化策略
   - 快照完整性验证和校验和计算
   - 智能快照触发策略

2. **检查点设计**
   - 自动检查点创建和管理
   - 检查点压缩和存储优化
   - 多级恢复机制

3. **分布式一致性**
   - 强一致性和最终一致性的实现
   - 网络分区检测和处理
   - 冲突检测和解决策略

4. **故障恢复**
   - 多层次故障检测机制
   - 自动恢复策略选择
   - 故障升级和人工介入

### 5.2 设计原则总结

- **多层防护**：从本地缓存到分布式备份的多层数据保护
- **渐进恢复**：从检查点到副本再到重建的渐进式恢复策略
- **自动化优先**：最大化自动恢复能力，减少人工干预
- **性能平衡**：在数据安全和系统性能之间找到最佳平衡点

### 5.3 最佳实践

1. **合理设置快照频率**：平衡数据安全和性能开销
2. **多副本策略**：确保数据在多个节点上有可靠备份
3. **监控告警**：及时发现和响应各种故障情况
4. **定期演练**：验证恢复机制的有效性

这些持久化与容错机制为AI应用提供了坚实的可靠性保障，确保系统能够在各种故障情况下继续稳定运行。

下一节我们将探讨性能优化与状态机监控的具体实现。
