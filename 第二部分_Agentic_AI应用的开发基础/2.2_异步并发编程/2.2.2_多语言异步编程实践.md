# 2.2.2 å¤šè¯­è¨€å¼‚æ­¥ç¼–ç¨‹å®è·µ

## å­¦ä¹ ç›®æ ‡

åŸºäº2.2.1ç« èŠ‚å»ºç«‹çš„æŠ€æœ¯é€‰æ‹©æ¡†æ¶ï¼Œç†Ÿç»ƒè¿ç”¨Javaã€Pythonã€TypeScriptç­‰è¯­è¨€çš„å¼‚æ­¥ç¼–ç¨‹æœºåˆ¶ï¼Œå®ç°AIåº”ç”¨çš„é«˜æ•ˆå¹¶å‘å¤„ç†ã€‚

## ğŸ”— ç« èŠ‚è¡”æ¥

åœ¨2.2.1ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å»ºç«‹äº†å¼‚æ­¥ç¼–ç¨‹çš„ç†è®ºåŸºç¡€å’ŒæŠ€æœ¯é€‰æ‹©æ¡†æ¶ã€‚æœ¬ç« èŠ‚å°†è¿™äº›ç†è®ºä»˜è¯¸å®è·µï¼Œé€šè¿‡çœŸå®çš„ä¼ä¸šçº§é¡¹ç›®æ¡ˆä¾‹ï¼Œå±•ç¤ºå¦‚ä½•åœ¨ä¸åŒç¼–ç¨‹è¯­è¨€ä¸­å®ç°é«˜æ•ˆçš„å¼‚æ­¥AIåº”ç”¨ã€‚

## ğŸ“Š JD Genieé¡¹ç›®æ¶æ„æ¦‚è§ˆ

æœ¬ç« èŠ‚çš„ä»£ç ç¤ºä¾‹ä¸»è¦æ¥æºäºJD Genieé¡¹ç›®â€”â€”ä¸€ä¸ªä¼ä¸šçº§çš„AGIåº”ç”¨å¹³å°ã€‚è¯¥é¡¹ç›®é‡‡ç”¨å¾®æœåŠ¡æ¶æ„ï¼Œä½“ç°äº†2.2.1ç« èŠ‚ä¸­è®¨è®ºçš„å¤šç§å¼‚æ­¥ç¼–ç¨‹æ¨¡å¼ï¼š

```
JD Genie ç³»ç»Ÿæ¶æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å‰ç«¯å±‚ (TypeScript)                    â”‚
â”‚                React + SSE + WebSocket                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ å¼‚æ­¥é€šä¿¡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            APIç½‘å…³å±‚ (Java Spring)                       â”‚
â”‚            CompletableFuture + çº¿ç¨‹æ±                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ è´Ÿè½½å‡è¡¡
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ AgentæœåŠ¡   â”‚    â”‚ ToolæœåŠ¡      â”‚           â”‚ æ–‡ä»¶æœåŠ¡         â”‚
â”‚ (Java)     â”‚    â”‚ (Python)     â”‚           â”‚ (Python)       â”‚
â”‚ å¤šAgent    â”‚    â”‚ AsyncIO +    â”‚           â”‚ AsyncIO +      â”‚
â”‚ å¹¶å‘åè°ƒ    â”‚    â”‚ åç¨‹æ±         â”‚           â”‚ aiofiles       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æŠ€æœ¯é€‰å‹å¯¹ç…§

| ç»„ä»¶ | è¯­è¨€ | å¼‚æ­¥æ¨¡å‹ | é€‰æ‹©ç†ç”± |
|------|------|----------|----------|
| **å‰ç«¯UI** | TypeScript | Promise + Event Stream | ç”¨æˆ·äº¤äº’å“åº”æ€§è¦æ±‚é«˜ |
| **APIç½‘å…³** | Java | CompletableFuture + çº¿ç¨‹æ±  | ä¼ä¸šçº§ç¨³å®šæ€§å’Œæ€§èƒ½ |
| **AgentæœåŠ¡** | Java | å¤šçº¿ç¨‹ + CountDownLatch | å¤æ‚ä¸šåŠ¡é€»è¾‘å’ŒçŠ¶æ€ç®¡ç† |
| **ToolæœåŠ¡** | Python | AsyncIO + åç¨‹ | AIåº“ç”Ÿæ€ä¸°å¯Œï¼ŒI/Oå¯†é›† |
| **æ–‡ä»¶æœåŠ¡** | Python | AsyncIO + aiofiles | å¤§é‡æ–‡ä»¶I/Oæ“ä½œ |

è¿™ç§å¤šè¯­è¨€å¼‚æ­¥æ¶æ„å……åˆ†ä½“ç°äº†2.2.1ç« èŠ‚ä¸­"åœºæ™¯é©±åŠ¨æŠ€æœ¯é€‰æ‹©"çš„åŸåˆ™ã€‚

## 2.2.2.1 Javaå¼‚æ­¥ç¼–ç¨‹ï¼šEnterpriseçº§å¹¶å‘å¤„ç†

### çº¿ç¨‹æ± ä¸ä»»åŠ¡è°ƒåº¦

Javaåœ¨ä¼ä¸šçº§AIåº”ç”¨ä¸­æä¾›äº†ä¸°å¯Œçš„å¹¶å‘ç¼–ç¨‹å·¥å…·ã€‚åŸºäºJD Genieé¡¹ç›®çš„å®è·µï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ThreadPoolExecutorçš„ä¸“ä¸šåŒ–åº”ç”¨ï¼š

```java
// ThreadUtil.java - ç”Ÿäº§çº§çº¿ç¨‹æ± ç®¡ç†
public class ThreadUtil {
    private static ThreadPoolExecutor executor = null;

    public static synchronized void initPool(int poolSize) {
        if (executor == null) {
            ThreadFactory threadFactory = (new BasicThreadFactory.Builder())
                .namingPattern("exe-pool-%d")
                .daemon(true)
                .build();
            
            // è‡ªå®šä¹‰æ‹’ç»ç­–ç•¥ï¼šé¿å…ä»»åŠ¡ä¸¢å¤±
            RejectedExecutionHandler handler = (r, executor) -> {
                // æ—¥å¿—è®°å½•è¢«æ‹’ç»çš„ä»»åŠ¡
                logger.warn("Task rejected: {}", r.toString());
            };
            
            int maxPoolSize = Math.max(poolSize, 1000);
            executor = new ThreadPoolExecutor(
                poolSize,                    // æ ¸å¿ƒçº¿ç¨‹æ•°
                maxPoolSize,                 // æœ€å¤§çº¿ç¨‹æ•°  
                60000L, TimeUnit.MILLISECONDS, // ç©ºé—²çº¿ç¨‹å­˜æ´»æ—¶é—´
                new SynchronousQueue<>(),    // å·¥ä½œé˜Ÿåˆ—
                threadFactory,               // çº¿ç¨‹å·¥å‚
                handler                      // æ‹’ç»ç­–ç•¥
            );
        }
    }

    public static void execute(Runnable runnable) {
        if (executor == null) {
            initPool(100);
        }
        executor.execute(runnable);
    }

    public static CountDownLatch getCountDownLatch(int count) {
        return new CountDownLatch(count);
    }

    public static void await(CountDownLatch latch) {
        try {
            latch.await();
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            logger.error("Thread interrupted while waiting", e);
        }
    }
}
```

### CountDownLatchåœ¨AIå·¥å…·å¹¶å‘æ‰§è¡Œä¸­çš„åº”ç”¨

```java
// BaseAgent.java - AIå·¥å…·çš„å¹¶å‘æ‰§è¡Œæ¡†æ¶
public class BaseAgent {
    /**
     * å¹¶å‘æ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨å‘½ä»¤å¹¶è¿”å›æ‰§è¡Œç»“æœ
     */
    public Map<String, String> executeTools(List<ToolCall> commands) {
        Map<String, String> result = new ConcurrentHashMap<>();
        CountDownLatch taskCount = ThreadUtil.getCountDownLatch(commands.size());
        
        for (ToolCall toolCall : commands) {
            ThreadUtil.execute(() -> {
                try {
                    long startTime = System.currentTimeMillis();
                    String toolResult = executeTool(toolCall);
                    long duration = System.currentTimeMillis() - startTime;
                    
                    result.put(toolCall.getId(), toolResult);
                    logger.info("Tool {} completed in {}ms", 
                               toolCall.getFunction().getName(), duration);
                } catch (Exception e) {
                    logger.error("Tool execution failed: {}", toolCall.getId(), e);
                    result.put(toolCall.getId(), "Error: " + e.getMessage());
                } finally {
                    taskCount.countDown();
                }
            });
        }
        
        ThreadUtil.await(taskCount);
        return result;
    }
    
    private String executeTool(ToolCall toolCall) {
        // å·¥å…·æ‰§è¡Œé€»è¾‘
        String toolName = toolCall.getFunction().getName();
        Map<String, Object> arguments = toolCall.getFunction().getArguments();
        
        // æ ¹æ®å·¥å…·åç§°åˆ†å‘åˆ°å…·ä½“çš„å·¥å…·å®ç°
        return agentContext.getToolCollection().executeTool(toolName, arguments);
    }
}
```

### CompletableFutureåœ¨å¤æ‚AIæµç¨‹ä¸­çš„åº”ç”¨

```java
// é«˜çº§å¼‚æ­¥ç¼–ç¨‹ç¤ºä¾‹ï¼šAIå¤„ç†æµæ°´çº¿
public class AIProcessingPipeline {
    
    public CompletableFuture<AIResult> processComplexQuery(String query) {
        return CompletableFuture
            // é˜¶æ®µ1ï¼šé¢„å¤„ç†æŸ¥è¯¢
            .supplyAsync(() -> preprocessQuery(query))
            // é˜¶æ®µ2ï¼šå¹¶è¡Œæ‰§è¡Œå¤šä¸ªAIä»»åŠ¡
            .thenComposeAsync(this::executeParallelTasks)
            // é˜¶æ®µ3ï¼šèšåˆç»“æœ
            .thenApplyAsync(this::aggregateResults)
            // é”™è¯¯å¤„ç†
            .exceptionally(throwable -> {
                logger.error("AI processing failed", throwable);
                return AIResult.error("Processing failed: " + throwable.getMessage());
            });
    }
    
    private CompletableFuture<AIResult> executeParallelTasks(String preprocessedQuery) {
        // åˆ›å»ºå¤šä¸ªå¹¶è¡Œä»»åŠ¡
        CompletableFuture<String> textAnalysis = 
            CompletableFuture.supplyAsync(() -> analyzeText(preprocessedQuery));
        CompletableFuture<String> sentimentAnalysis = 
            CompletableFuture.supplyAsync(() -> analyzeSentiment(preprocessedQuery));
        CompletableFuture<String> entityExtraction = 
            CompletableFuture.supplyAsync(() -> extractEntities(preprocessedQuery));
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        return CompletableFuture.allOf(textAnalysis, sentimentAnalysis, entityExtraction)
            .thenApply(v -> new AIResult(
                textAnalysis.join(),
                sentimentAnalysis.join(), 
                entityExtraction.join()
            ));
    }
}
```

### å¤šAgentå¹¶è¡Œæ‰§è¡Œä¸çŠ¶æ€åŒæ­¥

```java
// PlanSolveHandlerImpl.java - å¤šAgentååŒå·¥ä½œ
public class PlanSolveHandlerImpl {
    
    public String handleMultiAgentTasks(List<String> tasks, ExecutorAgent mainExecutor) {
        if (tasks.size() == 1) {
            return mainExecutor.run(tasks.get(0));
        }
        
        Map<String, String> taskResults = new ConcurrentHashMap<>();
        CountDownLatch taskCount = ThreadUtil.getCountDownLatch(tasks.size());
        int memoryIndex = mainExecutor.getMemory().size();
        List<ExecutorAgent> slaveExecutors = new ArrayList<>();
        
        for (String task : tasks) {
            ExecutorAgent slaveExecutor = new ExecutorAgent(agentContext);
            // çŠ¶æ€åŒæ­¥ï¼šå¤åˆ¶ä¸»Agentçš„çŠ¶æ€å’Œè®°å¿†
            slaveExecutor.setState(mainExecutor.getState());
            slaveExecutor.getMemory().addMessages(mainExecutor.getMemory().getMessages());
            slaveExecutors.add(slaveExecutor);
            
            ThreadUtil.execute(() -> {
                try {
                    String taskResult = slaveExecutor.run(task);
                    taskResults.put(task, taskResult);
                } catch (Exception e) {
                    logger.error("Slave agent task failed: {}", task, e);
                    taskResults.put(task, "Error: " + e.getMessage());
                } finally {
                    taskCount.countDown();
                }
            });
        }
        
        ThreadUtil.await(taskCount);
        
        // ç»“æœèšåˆï¼šå°†ä»Agentçš„è®°å¿†åˆå¹¶å›ä¸»Agent
        for (ExecutorAgent slaveExecutor : slaveExecutors) {
            for (int i = memoryIndex; i < slaveExecutor.getMemory().size(); i++) {
                mainExecutor.getMemory().addMessage(slaveExecutor.getMemory().get(i));
            }
            slaveExecutor.getMemory().clear();
            mainExecutor.setState(slaveExecutor.getState());
        }
        
        return String.join("\n", taskResults.values());
    }
}
```

## 2.2.2.2 Pythonå¼‚æ­¥ç¼–ç¨‹ï¼šåç¨‹é©±åŠ¨çš„AIå¤„ç†

### AsyncIOä¸å¼‚æ­¥ç”Ÿæˆå™¨

Pythonçš„asyncioåº“ä¸ºAIåº”ç”¨æä¾›äº†å¼ºå¤§çš„å¼‚æ­¥å¤„ç†èƒ½åŠ›ã€‚åŸºäºGenie Toolé¡¹ç›®çš„å®ç°ï¼š

```python
# deepsearch.py - æ·±åº¦æœç´¢çš„å¼‚æ­¥å®ç°
import asyncio
from typing import AsyncGenerator, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

class DeepSearch:
    """æ·±åº¦æœç´¢å·¥å…·"""
    
    @timer()
    async def run(
        self,
        query: str,
        request_id: str = None,
        max_loop: int = 1,
        stream: bool = False,
        stream_mode: StreamMode = StreamMode(),
        *args,
        **kwargs
    ) -> AsyncGenerator[str, None]:
        """å¼‚æ­¥æµå¼æœç´¢å¤„ç†"""
        
        try:
            # æŸ¥è¯¢åˆ†è§£
            queries = await query_decompose(query, request_id=request_id)
            logger.info(f"Decomposed queries: {queries}")
            
            # å¹¶è¡Œæœç´¢
            docs, search_results = await self._search_queries_and_dedup(queries, request_id)
            
            # æµå¼ç­”æ¡ˆç”Ÿæˆ
            acc_content = ""
            async for chunk in answer_question(
                query=query, 
                docs=docs, 
                request_id=request_id,
                stream=stream
            ):
                if stream and chunk:
                    acc_content += chunk
                    yield json.dumps({
                        "requestId": request_id,
                        "query": query,
                        "searchResult": {"query": queries, "docs": [doc.dict() for doc in docs]},
                        "answer": chunk,
                        "isFinal": False,
                        "messageType": "search"
                    }, ensure_ascii=False)
                else:
                    acc_content += chunk
                    
        except Exception as e:
            logger.error(f"DeepSearch error: {e}")
            yield json.dumps({
                "requestId": request_id,
                "query": query,
                "error": str(e),
                "isFinal": True,
                "messageType": "error"
            }, ensure_ascii=False)
```

### çº¿ç¨‹æ± ä¸åç¨‹çš„æ··åˆä½¿ç”¨

åœ¨å¤„ç†CPUå¯†é›†å‹ä»»åŠ¡æ—¶ï¼ŒPythonéœ€è¦ç»“åˆçº¿ç¨‹æ± å’Œåç¨‹ï¼š

```python
async def _search_queries_and_dedup(
    self, 
    queries: List[str], 
    request_id: str
) -> Tuple[List[Doc], List[List[Doc]]]:
    """å¼‚æ­¥å¹¶è¡Œæœç´¢å¤šä¸ªæŸ¥è¯¢å¹¶å»é‡"""
    
    def _run_async(*args, **kwargs):
        """åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥ä»»åŠ¡"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(self._search_single_query(*args, **kwargs))
            return result
        finally:
            loop.close()

    process_list = []
    max_workers = int(os.getenv("SEARCH_THREAD_NUM", 5))
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        for query in queries:
            process = executor.submit(_run_async, query, request_id)
            process_list.append(process)
    
    # æ”¶é›†æ‰€æœ‰ç»“æœ
    results = [process.result() for process in as_completed(process_list)]
    all_docs = [doc for docs in results for doc in docs]
    
    # å»é‡å¤„ç†
    seen_content = set()
    deduped_docs = []
    for doc in all_docs:
        if doc.content and doc.content not in seen_content:
            deduped_docs.append(doc)
            seen_content.add(doc.content)
    
    return deduped_docs, results
```

### ä»£ç è§£é‡Šå™¨çš„å¼‚æ­¥æµå¼å¤„ç†

```python
# code_interpreter.py - å¼‚æ­¥ä»£ç æ‰§è¡Œä¸æµå¼è¾“å‡º
async def code_interpreter_agent(
    task: str,
    file_names: Optional[List[str]] = None,
    max_file_abstract_size: int = 2000,
    max_tokens: int = 32000,
    request_id: str = "",
    stream: bool = True,
):
    work_dir = ""
    try:
        work_dir = tempfile.mkdtemp()
        output_dir = os.path.join(work_dir, "output")
        os.makedirs(output_dir, exist_ok=True)
        
        # å¼‚æ­¥æ–‡ä»¶ä¸‹è½½
        import_files = await download_all_files_in_path(
            file_names=file_names, 
            work_dir=work_dir
        )

        # æ–‡ä»¶é¢„å¤„ç†ï¼ˆå¹¶å‘å¤„ç†å¤šä¸ªæ–‡ä»¶ï¼‰
        files = []
        if import_files:
            file_tasks = []
            for import_file in import_files:
                file_tasks.append(process_single_file(import_file, max_file_abstract_size))
            
            files = await asyncio.gather(*file_tasks)

        # åˆ›å»ºAIä»£ç†
        agent = create_ci_agent(
            prompt_templates=get_prompt("code_interpreter"),
            max_tokens=max_tokens,
            return_full_result=True,
            output_dir=output_dir,
        )

        template_task = Template(ci_prompt_template["task_template"]).render(
            files=files, task=task, output_dir=output_dir
        )

        if stream:
            # æµå¼å¤„ç†ï¼šå®æ—¶è¿”å›æ‰§è¡Œç»“æœ
            for step in agent.run(task=str(template_task), stream=True, max_steps=10):
                if isinstance(step, CodeOuput):
                    file_info = await upload_file(
                        content=step.code,
                        file_name=step.file_name,
                        file_type="py",
                        request_id=request_id,
                    )
                    step.file_list = [file_info]
                    yield step
                
                elif isinstance(step, FinalAnswerStep):
                    # å¤„ç†æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
                    file_list = []
                    file_path = get_new_file_by_path(output_dir=output_dir)
                    if file_path:
                        file_info = await upload_file_by_path(
                            file_path=file_path, 
                            request_id=request_id
                        )
                        if file_info:
                            file_list.append(file_info)
                    
                    output = ActionOutput(content=step.output, file_list=file_list)
                    yield output
                
                # æ§åˆ¶æµå¼è¾“å‡ºé¢‘ç‡
                await asyncio.sleep(0)
                
    except Exception as e:
        raise e
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if work_dir:
            shutil.rmtree(work_dir, ignore_errors=True)

async def process_single_file(import_file, max_abstract_size):
    """å¼‚æ­¥å¤„ç†å•ä¸ªæ–‡ä»¶"""
    file_name = import_file["file_name"]
    file_path = import_file["file_path"]
    
    if not file_name or not file_path:
        return None

    # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å¤„ç†ç­–ç•¥
    if file_name.split(".")[-1] in ["xlsx", "xls", "csv"]:
        # å¼‚æ­¥è¯»å–è¡¨æ ¼æ–‡ä»¶
        loop = asyncio.get_event_loop()
        df = await loop.run_in_executor(None, lambda: 
            pd.read_csv(file_path) if file_name.endswith(".csv") 
            else pd.read_excel(file_path)
        )
        return {"path": file_path, "abstract": f"{df.head(10)}"}
    
    elif file_name.split(".")[-1] in ["txt", "md", "html"]:
        # å¼‚æ­¥è¯»å–æ–‡æœ¬æ–‡ä»¶
        async with aiofiles.open(file_path, "r") as rf:
            content = await rf.read()
            return {
                "path": file_path,
                "abstract": content[:max_abstract_size]
            }
    
    return None
```

### å¤šæœç´¢å¼•æ“çš„å¼‚æ­¥èšåˆ

```python
# search_engine.py - å¤šå¼•æ“å¹¶è¡Œæœç´¢
class MixSearch:
    def __init__(self):
        self._engine = "mix_search"
        self._bing_engine = BingSearch()
        self._jina_engine = JinaSearch()
        self._sogou_engine = SogouSearch()
        self._serp_engine = SerperSearch()

    async def search(
        self, 
        query: str, 
        request_id: str = None,
        use_bing: bool = True, 
        use_jina: bool = True, 
        use_sogou: bool = True,
        use_serp: bool = True, 
        *args, 
        **kwargs
    ) -> List[Doc]:
        """å¹¶è¡Œè°ƒç”¨å¤šä¸ªæœç´¢å¼•æ“"""
        
        assert use_bing or use_jina or use_sogou or use_serp
        engines = []
        
        if use_bing:
            engines.append(self._bing_engine)
        if use_jina:
            engines.append(self._jina_engine)
        if use_sogou:
            engines.append(self._sogou_engine)
        if use_serp:
            engines.append(self._serp_engine)
        
        # ä½¿ç”¨TaskGroupè¿›è¡Œå¹¶å‘æ‰§è¡Œ
        async with asyncio.TaskGroup() as tg:
            tasks = [
                tg.create_task(engine.search_and_dedup(query=query, request_id=request_id)) 
                for engine in engines
            ]
        
        # èšåˆæ‰€æœ‰æœç´¢ç»“æœ
        results = [task.result() for task in tasks]
        return [doc for docs in results for doc in docs]
```

## 2.2.2.3 TypeScriptå¼‚æ­¥ç¼–ç¨‹ï¼šç°ä»£å‰ç«¯AIäº¤äº’

### åŸºäºPromiseçš„å¼‚æ­¥å¤„ç†

TypeScriptåœ¨AIåº”ç”¨å‰ç«¯æä¾›äº†ä¼˜é›…çš„å¼‚æ­¥ç¼–ç¨‹ä½“éªŒï¼š

```typescript
// querySSE.ts - SSEæµå¼é€šä¿¡çš„å°è£…
interface SSEConfig {
  body: any;
  handleMessage: (data: any) => void;
  handleError: (error: Error) => void;
  handleClose: () => void;
}

export default (config: SSEConfig, url: string = DEFAULT_SSE_URL): void => {
  const { body = null, handleMessage, handleError, handleClose } = config;

  fetchEventSource(url, {
    method: 'POST',
    credentials: 'include',
    headers: SSE_HEADERS,
    body: JSON.stringify(body),
    openWhenHidden: true,
    
    onmessage(event: EventSourceMessage) {
      if (event.data) {
        try {
          const parsedData = JSON.parse(event.data);
          handleMessage(parsedData);
        } catch (error) {
          console.error('Error parsing SSE message:', error);
          handleError(new Error('Failed to parse SSE message'));
        }
      }
    },
    
    onerror(error: Error) {
      console.error('SSE error:', error);
      handleError(error);
    },
    
    onclose() {
      console.log('SSE connection closed');
      handleClose();
    }
  });
};
```

### å“åº”å¼å¼‚æ­¥çŠ¶æ€ç®¡ç†

```typescript
// ä½¿ç”¨React Hooksç®¡ç†å¼‚æ­¥AIäº¤äº’çŠ¶æ€
import { useState, useCallback, useEffect } from 'react';

interface AIStreamState {
  isLoading: boolean;
  messages: Message[];
  error: string | null;
  isConnected: boolean;
}

export const useAIStream = () => {
  const [state, setState] = useState<AIStreamState>({
    isLoading: false,
    messages: [],
    error: null,
    isConnected: false
  });

  const sendMessage = useCallback(async (query: string) => {
    setState(prev => ({ ...prev, isLoading: true, error: null }));

    const config: SSEConfig = {
      body: { query, agentType: 'react' },
      
      handleMessage: (data) => {
        setState(prev => ({
          ...prev,
          messages: [...prev.messages, data],
          isConnected: true
        }));
      },
      
      handleError: (error) => {
        setState(prev => ({
          ...prev,
          error: error.message,
          isLoading: false,
          isConnected: false
        }));
      },
      
      handleClose: () => {
        setState(prev => ({
          ...prev,
          isLoading: false,
          isConnected: false
        }));
      }
    };

    querySSE(config);
  }, []);

  return {
    ...state,
    sendMessage
  };
};
```

### å¹¶å‘APIè°ƒç”¨ä¸æ•°æ®èšåˆ

```typescript
// å¤šæœåŠ¡å¹¶å‘è°ƒç”¨çš„æœ€ä½³å®è·µ
interface AIService {
  name: string;
  endpoint: string;
  timeout: number;
}

class AIServiceOrchestrator {
  private services: AIService[];

  constructor(services: AIService[]) {
    this.services = services;
  }

  async processQuery(query: string): Promise<AIResult[]> {
    const requests = this.services.map(service => 
      this.callService(service, query)
    );

    // ä½¿ç”¨Promise.allSettledå¤„ç†å¹¶å‘è¯·æ±‚
    const results = await Promise.allSettled(requests);
    
    return results.map((result, index) => ({
      serviceName: this.services[index].name,
      status: result.status,
      data: result.status === 'fulfilled' ? result.value : null,
      error: result.status === 'rejected' ? result.reason : null
    }));
  }

  private async callService(service: AIService, query: string): Promise<any> {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), service.timeout);

    try {
      const response = await fetch(service.endpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query }),
        signal: controller.signal
      });

      if (!response.ok) {
        throw new Error(`Service ${service.name} returned ${response.status}`);
      }

      return await response.json();
    } finally {
      clearTimeout(timeoutId);
    }
  }
}
```

## 2.2.2.4 è·¨è¯­è¨€å¼‚æ­¥é€šä¿¡æ¨¡å¼

### å¾®æœåŠ¡é—´çš„å¼‚æ­¥åè°ƒ

åœ¨å¤šè¯­è¨€AIåº”ç”¨æ¶æ„ä¸­ï¼Œä¸åŒæœåŠ¡éœ€è¦é«˜æ•ˆçš„å¼‚æ­¥é€šä¿¡ï¼š

```java
// JavaæœåŠ¡ - AIæ§åˆ¶å™¨
@RestController
public class GenieController {
    
    @Autowired
    private AsyncAIServiceClient aiServiceClient;
    
    @PostMapping("/AutoAgent")
    public SseEmitter processAIRequest(@RequestBody AgentRequest request) {
        SseEmitter emitter = new SseEmitter(60 * 60 * 1000L);
        
        ThreadUtil.execute(() -> {
            try {
                // å¼‚æ­¥è°ƒç”¨Python AIæœåŠ¡
                CompletableFuture<String> pythonServiceFuture = 
                    aiServiceClient.callPythonService(request);
                
                // å¼‚æ­¥è°ƒç”¨å…¶ä»–å¾®æœåŠ¡
                CompletableFuture<String> searchServiceFuture = 
                    aiServiceClient.callSearchService(request);
                
                // ç­‰å¾…æ‰€æœ‰æœåŠ¡å“åº”
                CompletableFuture.allOf(pythonServiceFuture, searchServiceFuture)
                    .thenAccept(v -> {
                        String pythonResult = pythonServiceFuture.join();
                        String searchResult = searchServiceFuture.join();
                        
                        // èšåˆç»“æœå¹¶å‘é€
                        String finalResult = aggregateResults(pythonResult, searchResult);
                        emitter.send(finalResult);
                        emitter.complete();
                    })
                    .exceptionally(throwable -> {
                        emitter.completeWithError(throwable);
                        return null;
                    });
                    
            } catch (Exception e) {
                emitter.completeWithError(e);
            }
        });
        
        return emitter;
    }
}
```

```python
# PythonæœåŠ¡ - AIå·¥å…·å¤„ç†
from fastapi import FastAPI
from fastapi.responses import EventSourceResponse
import asyncio

app = FastAPI()

@app.post("/v1/tool/process")
async def process_ai_tool(request: AIToolRequest):
    """å¼‚æ­¥å¤„ç†AIå·¥å…·è¯·æ±‚"""
    
    async def _stream():
        try:
            # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªAIå¤„ç†æ­¥éª¤
            tasks = [
                process_text_analysis(request.text),
                process_code_generation(request.task),
                process_data_analysis(request.data)
            ]
            
            # æµå¼è¿”å›å¤„ç†ç»“æœ
            async for result in asyncio.as_completed(tasks):
                processed_result = await result
                yield f"data: {json.dumps(processed_result)}\n\n"
                
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return EventSourceResponse(
        _stream(), 
        ping_message_factory=lambda: ServerSentEvent(data="heartbeat"),
        ping=15
    )

async def process_text_analysis(text: str) -> dict:
    """å¼‚æ­¥æ–‡æœ¬åˆ†æ"""
    # æ¨¡æ‹ŸAIå¤„ç†
    await asyncio.sleep(2)
    return {"type": "text_analysis", "result": "Analysis complete"}

async def process_code_generation(task: str) -> dict:
    """å¼‚æ­¥ä»£ç ç”Ÿæˆ"""
    await asyncio.sleep(3)
    return {"type": "code_generation", "result": "Code generated"}
```

## 2.2.2.5 å¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µæ€»ç»“

### 1. é”™è¯¯å¤„ç†ç­–ç•¥

```java
// Java - CompletableFutureé”™è¯¯å¤„ç†
public CompletableFuture<AIResult> robustAIProcessing(String input) {
    return CompletableFuture
        .supplyAsync(() -> processInput(input))
        .thenCompose(this::callAIService)
        .thenApply(this::formatResult)
        .exceptionally(throwable -> {
            logger.error("AI processing failed", throwable);
            return AIResult.error("Processing failed");
        })
        .orTimeout(30, TimeUnit.SECONDS)
        .whenComplete((result, throwable) -> {
            if (throwable != null) {
                metrics.incrementErrorCount();
            }
        });
}
```

```python
# Python - åç¨‹é”™è¯¯å¤„ç†
async def safe_async_processing(data: str) -> dict:
    """å®‰å…¨çš„å¼‚æ­¥å¤„ç†"""
    try:
        async with asyncio.timeout(30):  # è¶…æ—¶æ§åˆ¶
            result = await process_data(data)
            return {"status": "success", "data": result}
    except asyncio.TimeoutError:
        logger.error("Processing timeout")
        return {"status": "timeout", "error": "Processing timed out"}
    except Exception as e:
        logger.error(f"Processing error: {e}")
        return {"status": "error", "error": str(e)}
```

### 2. èµ„æºç®¡ç†åŸåˆ™

```java
// ä½¿ç”¨try-with-resourcesç®¡ç†å¼‚æ­¥èµ„æº
public void processLargeDataset(List<DataChunk> chunks) {
    try (ExecutorService executor = Executors.newFixedThreadPool(10)) {
        List<CompletableFuture<ProcessResult>> futures = chunks.stream()
            .map(chunk -> CompletableFuture.supplyAsync(() -> 
                processChunk(chunk), executor))
            .collect(Collectors.toList());
        
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
            .join();
    }
}
```

### 3. æ€§èƒ½ç›‘æ§é›†æˆ

```python
# å¼‚æ­¥ä»»åŠ¡æ€§èƒ½ç›‘æ§
import time
from functools import wraps

def async_monitor(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            duration = time.time() - start_time
            logger.info(f"{func.__name__} completed in {duration:.2f}s")
            return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"{func.__name__} failed after {duration:.2f}s: {e}")
            raise
    return wrapper

@async_monitor
async def process_ai_request(request):
    # AIå¤„ç†é€»è¾‘
    pass
```

## å°ç»“

å¤šè¯­è¨€å¼‚æ­¥ç¼–ç¨‹æ˜¯æ„å»ºç°ä»£AIåº”ç”¨çš„æ ¸å¿ƒæŠ€èƒ½ã€‚æ¯ç§è¯­è¨€éƒ½æœ‰å…¶ç‹¬ç‰¹çš„å¼‚æ­¥ç¼–ç¨‹æ¨¡å‹å’Œæœ€ä½³å®è·µï¼š

- **Java**ï¼šä¼ä¸šçº§çš„çº¿ç¨‹æ± ç®¡ç†å’ŒCompletableFutureç»„åˆ
- **Python**ï¼šåç¨‹é©±åŠ¨çš„é«˜å¹¶å‘å¤„ç†å’Œå¼‚æ­¥ç”Ÿæˆå™¨
- **TypeScript**ï¼šPromise-basedçš„å“åº”å¼å‰ç«¯äº¤äº’

æŒæ¡è¿™äº›æŠ€æœ¯å¹¶åˆç†ç»„åˆä½¿ç”¨ï¼Œèƒ½å¤Ÿæ„å»ºå‡ºé«˜æ€§èƒ½ã€é«˜å¯ç”¨çš„AIåº”ç”¨ç³»ç»Ÿã€‚

---

**å®è·µå»ºè®®ï¼š**
1. é€‰æ‹©åˆé€‚çš„å¼‚æ­¥æ¨¡å‹åŒ¹é…åº”ç”¨åœºæ™¯
2. å»ºç«‹ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œç›‘æ§æœºåˆ¶  
3. æ³¨æ„è·¨è¯­è¨€æœåŠ¡é—´çš„å¼‚æ­¥åè°ƒ
4. æŒç»­ä¼˜åŒ–å¼‚æ­¥ä»»åŠ¡çš„æ€§èƒ½è¡¨ç°
