# 2.3.4 工具调用状态机与异步执行管理

## 学习目标

🏗️ **架构设计层面**
- 掌握工具调用的生命周期状态管理（调用前、执行中、完成后、异常处理）
- 理解异步执行管理的状态机设计模式
- 掌握工具状态机与Agent状态机的协调机制

⚙️ **工程实现层面**
- 学会实现代码解释器的分步执行状态机
- 理解深度搜索工具的多轮迭代状态控制
- 掌握工具执行结果的状态持久化与缓存策略

🚀 **企业级应用**
- 掌握工具执行的监控、告警和故障恢复机制
- 理解高并发场景下的工具状态管理策略

## 引言

在前面的章节中，我们学习了Agent级状态机（2.3.2）和任务执行状态机（2.3.3）的设计。现在我们将深入到更细粒度的层面——工具调用状态机，它是整个AGI应用状态管理体系中的重要组成部分。

工具调用是AI应用中最复杂的异步操作之一，涉及多种外部系统的交互、长时间运行的任务、以及复杂的结果处理逻辑。它体现了2.3.1章节中提到的**状态机分层与组合**设计原则：工具状态机作为子状态机，需要与Agent状态机和任务状态机协调工作。

在JoyAgent-JDGenie项目中，工具系统支持代码解释器、深度搜索、文件操作等多种工具，每种工具都有其独特的执行模式和状态管理需求。本节将详细分析工具调用状态机的设计原理和实现方案，展示如何应用前面学到的SOLID原则来构建可扩展的异步执行管理架构。

## 1. 工具调用生命周期状态设计

在设计工具调用状态机时，我们需要考虑工具执行的复杂性和多样性。不同于Agent状态的4个简单状态，工具执行需要更细粒度的状态控制，以支持异步执行、流式输出、错误重试等高级特性。这正体现了2.3.1章节中提到的**状态粒度选择**原则。

### 1.1 工具执行状态枚举

```java
/**
 * 工具执行状态枚举
 */
public enum ToolExecutionState {
    PENDING("pending"),         // 待执行：工具调用请求已创建，等待执行
    INITIALIZING("initializing"), // 初始化中：正在准备执行环境
    RUNNING("running"),         // 执行中：工具正在运行
    STREAMING("streaming"),     // 流式输出：工具产生实时输出
    COMPLETED("completed"),     // 已完成：工具执行成功完毕
    FAILED("failed"),          // 执行失败：工具执行过程中出现错误
    TIMEOUT("timeout"),        // 执行超时：工具执行超过最大时间限制
    CANCELLED("cancelled"),    // 已取消：工具执行被用户或系统取消
    RETRYING("retrying");      // 重试中：工具执行失败后正在重试
    
    private final String value;
    
    ToolExecutionState(String value) {
        this.value = value;
    }
    
    /**
     * 判断是否为终态
     */
    public boolean isTerminal() {
        return this == COMPLETED || this == FAILED || 
               this == TIMEOUT || this == CANCELLED;
    }
    
    /**
     * 判断是否为活跃状态
     */
    public boolean isActive() {
        return this == RUNNING || this == STREAMING || this == RETRYING;
    }
}
```

### 1.2 工具执行上下文

```java
/**
 * 工具执行上下文 - 维护工具执行过程中的状态信息
 */
@Data
@Builder
@AllArgsConstructor
@NoArgsConstructor
public class ToolExecutionContext {
    private String toolCallId;
    private String toolName;
    private String sessionId;
    private String requestId;
    
    // 执行状态
    private ToolExecutionState state = ToolExecutionState.PENDING;
    private long startTime;
    private long endTime;
    private long lastUpdateTime;
    
    // 执行参数
    private Map<String, Object> parameters = new HashMap<>();
    private Map<String, Object> metadata = new HashMap<>();
    
    // 执行结果
    private StringBuilder outputBuffer = new StringBuilder();
    private String finalResult;
    private String errorMessage;
    private Throwable exception;
    
    // 流式输出控制
    private boolean streamingEnabled = false;
    private volatile boolean cancelled = false;
    private CountDownLatch completionLatch = new CountDownLatch(1);
    
    // 重试机制
    private int retryCount = 0;
    private int maxRetries = 3;
    private long retryDelay = 1000; // 毫秒
    
    /**
     * 线程安全的状态更新
     */
    public synchronized void updateState(ToolExecutionState newState) {
        ToolExecutionState oldState = this.state;
        this.state = newState;
        this.lastUpdateTime = System.currentTimeMillis();
        
        // 处理状态转换的特殊逻辑
        handleStateTransition(oldState, newState);
        
        // 通知状态变更监听器
        notifyStateListeners(oldState, newState);
    }
    
    /**
     * 添加流式输出
     */
    public synchronized void appendOutput(String output) {
        if (!cancelled && (state == ToolExecutionState.RUNNING || 
                          state == ToolExecutionState.STREAMING)) {
            outputBuffer.append(output);
            lastUpdateTime = System.currentTimeMillis();
            
            // 通知流式输出监听器
            notifyStreamListeners(output);
        }
    }
    
    /**
     * 完成工具执行
     */
    public void complete(String result) {
        this.finalResult = result;
        updateState(ToolExecutionState.COMPLETED);
        this.endTime = System.currentTimeMillis();
        completionLatch.countDown();
    }
    
    /**
     * 标记工具执行失败
     */
    public void fail(String error, Throwable exception) {
        this.errorMessage = error;
        this.exception = exception;
        updateState(ToolExecutionState.FAILED);
        this.endTime = System.currentTimeMillis();
        completionLatch.countDown();
    }
    
    /**
     * 取消工具执行
     */
    public void cancel() {
        this.cancelled = true;
        updateState(ToolExecutionState.CANCELLED);
        completionLatch.countDown();
    }
}
```

### 1.3 工具调用状态机核心接口

```java
/**
 * 工具调用状态机接口
 */
public interface ToolStateMachine {
    
    /**
     * 执行工具调用
     */
    CompletableFuture<ToolResult> executeAsync(ToolCall toolCall);
    
    /**
     * 流式执行工具调用
     */
    Stream<ToolStreamResult> executeStream(ToolCall toolCall);
    
    /**
     * 取消工具执行
     */
    boolean cancelExecution(String toolCallId);
    
    /**
     * 获取工具执行状态
     */
    ToolExecutionState getExecutionState(String toolCallId);
    
    /**
     * 获取工具执行上下文
     */
    ToolExecutionContext getExecutionContext(String toolCallId);
}
```

## 2. 代码解释器的分步执行状态机

### 2.1 代码解释器状态机实现

```python
class CodeInterpreterStateMachine:
    """代码解释器状态机 - Python实现"""
    
    class CodeState(Enum):
        PARSING = "parsing"           # 代码解析阶段
        VALIDATING = "validating"     # 代码验证阶段
        PREPARING = "preparing"       # 环境准备阶段
        EXECUTING = "executing"       # 代码执行阶段
        MONITORING = "monitoring"     # 执行监控阶段
        COLLECTING = "collecting"     # 结果收集阶段
        COMPLETED = "completed"       # 执行完成
        ERROR = "error"               # 执行出错
    
    def __init__(self, task: str, max_steps: int = 10):
        self.task = task
        self.max_steps = max_steps
        self.current_step = 0
        self.state = self.CodeState.PARSING
        self.execution_context = {
            'variables': {},
            'imports': set(),
            'outputs': [],
            'errors': []
        }
        self.code_history = []
        self.result_buffer = []
    
    async def execute_step_stream(self) -> AsyncGenerator[str, None]:
        """执行单步并返回流式结果"""
        
        try:
            if self.state == self.CodeState.PARSING:
                yield from self._parse_code_stream()
                
            elif self.state == self.CodeState.VALIDATING:
                yield from self._validate_code_stream()
                
            elif self.state == self.CodeState.PREPARING:
                yield from self._prepare_environment_stream()
                
            elif self.state == self.CodeState.EXECUTING:
                yield from self._execute_code_stream()
                
            elif self.state == self.CodeState.MONITORING:
                yield from self._monitor_execution_stream()
                
            elif self.state == self.CodeState.COLLECTING:
                yield from self._collect_results_stream()
                
        except Exception as e:
            self.state = self.CodeState.ERROR
            yield json.dumps({
                "type": "error",
                "message": str(e),
                "step": self.current_step
            })
    
    async def _parse_code_stream(self) -> AsyncGenerator[str, None]:
        """解析代码阶段"""
        yield json.dumps({
            "type": "state_change",
            "from": "parsing",
            "to": "validating",
            "message": "开始解析代码..."
        })
        
        # 解析代码块
        code_blocks = self._extract_code_blocks(self.task)
        
        if not code_blocks:
            self.state = self.CodeState.ERROR
            yield json.dumps({
                "type": "error",
                "message": "未找到可执行的代码块"
            })
            return
        
        self.execution_context['code_blocks'] = code_blocks
        self.state = self.CodeState.VALIDATING
        
        yield json.dumps({
            "type": "progress",
            "message": f"解析完成，发现 {len(code_blocks)} 个代码块",
            "code_blocks_count": len(code_blocks)
        })
    
    async def _execute_code_stream(self) -> AsyncGenerator[str, None]:
        """执行代码阶段"""
        yield json.dumps({
            "type": "state_change",
            "from": "executing",
            "to": "monitoring",
            "message": "开始执行代码..."
        })
        
        code_blocks = self.execution_context['code_blocks']
        
        for i, code_block in enumerate(code_blocks):
            try:
                # 执行前状态通知
                yield json.dumps({
                    "type": "code_execution_start",
                    "block_index": i,
                    "code": code_block,
                    "timestamp": time.time()
                })
                
                # 执行代码块
                async for output in self._execute_single_block(code_block):
                    yield output
                
                # 执行后状态通知
                yield json.dumps({
                    "type": "code_execution_complete",
                    "block_index": i,
                    "timestamp": time.time()
                })
                
            except Exception as e:
                yield json.dumps({
                    "type": "code_execution_error",
                    "block_index": i,
                    "error": str(e),
                    "timestamp": time.time()
                })
                
                # 根据错误严重程度决定是否继续
                if self._is_fatal_error(e):
                    self.state = self.CodeState.ERROR
                    return
        
        self.state = self.CodeState.COLLECTING
    
    async def _execute_single_block(self, code: str) -> AsyncGenerator[str, None]:
        """执行单个代码块并实时输出结果"""
        
        # 创建执行环境
        local_vars = self.execution_context['variables'].copy()
        
        try:
            # 编译代码
            compiled_code = compile(code, '<string>', 'exec')
            
            # 重定向标准输出
            old_stdout = sys.stdout
            stdout_buffer = StringIO()
            sys.stdout = stdout_buffer
            
            try:
                # 执行代码
                exec(compiled_code, globals(), local_vars)
                
                # 获取输出
                output = stdout_buffer.getvalue()
                if output:
                    yield json.dumps({
                        "type": "stdout",
                        "content": output,
                        "timestamp": time.time()
                    })
                
                # 更新执行上下文
                self.execution_context['variables'].update(local_vars)
                
                # 检查新创建的变量
                for var_name, var_value in local_vars.items():
                    if var_name not in self.execution_context['variables']:
                        yield json.dumps({
                            "type": "variable_created",
                            "name": var_name,
                            "value": str(var_value),
                            "type": type(var_value).__name__
                        })
                
            finally:
                sys.stdout = old_stdout
                
        except Exception as e:
            yield json.dumps({
                "type": "execution_error",
                "error": str(e),
                "error_type": type(e).__name__,
                "traceback": traceback.format_exc()
            })
            raise e
```

### 2.2 代码解释器工具集成

```java
/**
 * 代码解释器工具 - Java后端集成
 */
@Component
public class CodeInterpreterTool extends BaseTool implements ToolStateMachine {
    
    @Override
    public CompletableFuture<ToolResult> executeAsync(ToolCall toolCall) {
        String toolCallId = toolCall.getId();
        ToolExecutionContext context = createExecutionContext(toolCall);
        
        return CompletableFuture.supplyAsync(() -> {
            try {
                // 更新状态为初始化中
                context.updateState(ToolExecutionState.INITIALIZING);
                
                // 准备执行参数
                Map<String, Object> params = prepareExecutionParams(toolCall);
                String task = (String) params.get("task");
                List<String> fileNames = (List<String>) params.get("file_names");
                
                // 更新状态为执行中
                context.updateState(ToolExecutionState.RUNNING);
                
                // 调用Python代码解释器
                String result = executeCodeInterpreterAgent(
                    task, fileNames, context.getRequestId());
                
                // 更新状态为完成
                context.complete(result);
                
                return ToolResult.success(toolCallId, result);
                
            } catch (Exception e) {
                log.error("Code interpreter execution failed", e);
                context.fail(e.getMessage(), e);
                return ToolResult.failure(toolCallId, e.getMessage());
            }
        });
    }
    
    @Override
    public Stream<ToolStreamResult> executeStream(ToolCall toolCall) {
        String toolCallId = toolCall.getId();
        ToolExecutionContext context = createExecutionContext(toolCall);
        
        return Stream.generate(() -> {
            try {
                // 调用流式代码解释器
                return callStreamingCodeInterpreter(toolCall, context);
            } catch (Exception e) {
                context.fail(e.getMessage(), e);
                return ToolStreamResult.error(toolCallId, e.getMessage());
            }
        })
        .takeWhile(result -> !result.isTerminal())
        .peek(result -> updateContextFromStreamResult(context, result));
    }
    
    /**
     * 调用流式代码解释器
     */
    private ToolStreamResult callStreamingCodeInterpreter(
            ToolCall toolCall, ToolExecutionContext context) {
        
        String toolCallId = toolCall.getId();
        
        try {
            // 构建请求
            CodeInterpreterRequest request = buildCodeInterpreterRequest(toolCall);
            
            // 发送HTTP流式请求到Python服务
            HttpResponse response = sendStreamRequest(request);
            
            if (response.getStatusCode() == 200) {
                String chunk = response.getBody();
                
                // 解析响应
                Map<String, Object> chunkData = parseStreamChunk(chunk);
                String type = (String) chunkData.get("type");
                
                // 根据响应类型更新状态
                switch (type) {
                    case "state_change":
                        updateStateFromChunk(context, chunkData);
                        return ToolStreamResult.stateChange(toolCallId, chunkData);
                        
                    case "stdout":
                        context.appendOutput((String) chunkData.get("content"));
                        return ToolStreamResult.output(toolCallId, chunkData);
                        
                    case "code_execution_start":
                        context.updateState(ToolExecutionState.RUNNING);
                        return ToolStreamResult.progress(toolCallId, chunkData);
                        
                    case "code_execution_complete":
                        return ToolStreamResult.progress(toolCallId, chunkData);
                        
                    case "final_result":
                        context.complete((String) chunkData.get("result"));
                        return ToolStreamResult.complete(toolCallId, chunkData);
                        
                    case "error":
                        context.fail((String) chunkData.get("message"), null);
                        return ToolStreamResult.error(toolCallId, 
                            (String) chunkData.get("message"));
                        
                    default:
                        return ToolStreamResult.unknown(toolCallId, chunkData);
                }
            } else {
                context.fail("HTTP request failed: " + response.getStatusCode(), null);
                return ToolStreamResult.error(toolCallId, 
                    "HTTP request failed: " + response.getStatusCode());
            }
            
        } catch (Exception e) {
            log.error("Streaming code interpreter call failed", e);
            context.fail(e.getMessage(), e);
            return ToolStreamResult.error(toolCallId, e.getMessage());
        }
    }
}
```

## 3. 深度搜索工具的多轮迭代状态控制

### 3.1 深度搜索状态机设计

```python
class DeepSearchStateMachine:
    """深度搜索状态机"""
    
    class SearchState(Enum):
        INITIALIZING = "initializing"     # 初始化搜索
        DECOMPOSING = "decomposing"       # 查询分解
        SEARCHING = "searching"           # 执行搜索
        ANALYZING = "analyzing"           # 结果分析
        ITERATING = "iterating"           # 迭代搜索
        SYNTHESIZING = "synthesizing"     # 结果合成
        COMPLETED = "completed"           # 搜索完成
        ERROR = "error"                   # 搜索出错
    
    def __init__(self, query: str, max_loop: int = 3):
        self.original_query = query
        self.max_loop = max_loop
        self.current_loop = 0
        self.state = self.SearchState.INITIALIZING
        
        # 搜索上下文
        self.search_context = {
            'searched_queries': set(),
            'current_docs': [],
            'iteration_results': [],
            'synthesis_history': []
        }
    
    async def run(self, request_id: str = None, stream: bool = True) -> AsyncGenerator[str, None]:
        """执行深度搜索主循环"""
        
        self.current_loop = 1
        
        try:
            # 初始化阶段
            self.state = self.SearchState.INITIALIZING
            yield self._create_state_message("开始深度搜索...")
            
            while self.current_loop <= self.max_loop:
                log.info(f"{request_id} 第 {self.current_loop} 轮深度搜索...")
                
                # 查询分解阶段
                self.state = self.SearchState.DECOMPOSING
                yield self._create_state_message(f"第 {self.current_loop} 轮：分解查询")
                
                sub_queries = await self._decompose_query()
                yield self._create_progress_message("extend", sub_queries)
                
                # 搜索阶段
                self.state = self.SearchState.SEARCHING
                yield self._create_state_message("执行并行搜索...")
                
                searched_docs, docs_list = await self._search_queries_parallel(sub_queries)
                yield self._create_search_result_message(sub_queries, docs_list)
                
                # 分析阶段
                self.state = self.SearchState.ANALYZING
                yield self._create_state_message("分析搜索结果...")
                
                analysis_result = await self._analyze_search_results(searched_docs)
                
                # 检查是否需要继续迭代
                if self._should_continue_search(analysis_result):
                    self.state = self.SearchState.ITERATING
                    yield self._create_state_message("准备下一轮搜索...")
                    
                    # 更新搜索上下文
                    self._update_search_context(searched_docs, sub_queries, analysis_result)
                    self.current_loop += 1
                else:
                    break
            
            # 合成阶段
            self.state = self.SearchState.SYNTHESIZING
            yield self._create_state_message("合成最终结果...")
            
            final_result = await self._synthesize_final_result()
            
            # 完成
            self.state = self.SearchState.COMPLETED
            yield self._create_final_result_message(final_result)
            
        except Exception as e:
            self.state = self.SearchState.ERROR
            log.error(f"Deep search failed: {str(e)}")
            yield self._create_error_message(str(e))
    
    async def _decompose_query(self) -> List[str]:
        """查询分解 - 将复杂查询分解为多个子查询"""
        
        # 使用LLM进行智能查询分解
        decompose_prompt = f"""
        请将以下查询分解为3-5个更具体的子查询，以便进行深度搜索：
        
        原始查询：{self.original_query}
        
        已搜索的查询：{list(self.search_context['searched_queries'])}
        
        请返回JSON格式的子查询列表。
        """
        
        response = await self.llm.achat(decompose_prompt)
        
        try:
            sub_queries = json.loads(response.content).get("sub_queries", [])
            
            # 过滤已搜索的查询
            new_queries = [q for q in sub_queries 
                          if q not in self.search_context['searched_queries']]
            
            return new_queries[:5]  # 限制子查询数量
            
        except json.JSONDecodeError:
            log.warning("Failed to parse sub queries, using fallback")
            return [self.original_query]
    
    async def _search_queries_parallel(self, queries: List[str]) -> Tuple[List[Document], List[List[Document]]]:
        """并行搜索子查询"""
        
        tasks = [self._search_single_query(query) for query in queries]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        all_docs = []
        docs_lists = []
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                log.error(f"Search failed for query '{queries[i]}': {result}")
                docs_lists.append([])
            else:
                docs = result
                all_docs.extend(docs)
                docs_lists.append(docs)
        
        # 去重
        unique_docs = self._deduplicate_documents(all_docs)
        
        return unique_docs, docs_lists
    
    async def _search_single_query(self, query: str) -> List[Document]:
        """搜索单个查询"""
        
        try:
            # 调用搜索引擎
            search_results = await self.search_engine.search(query)
            
            # 转换为文档对象
            documents = []
            for result in search_results:
                doc = Document(
                    title=result.get('title', ''),
                    content=result.get('content', ''),
                    url=result.get('url', ''),
                    source=result.get('source', 'web'),
                    relevance_score=result.get('score', 0.0)
                )
                documents.append(doc)
            
            return documents
            
        except Exception as e:
            log.error(f"Single query search failed: {query}", e)
            return []
    
    def _should_continue_search(self, analysis_result: Dict[str, Any]) -> bool:
        """判断是否需要继续搜索"""
        
        # 检查信息充分性
        completeness_score = analysis_result.get('completeness_score', 0.0)
        if completeness_score < 0.7:
            return True
        
        # 检查是否还有未探索的方向
        unexplored_areas = analysis_result.get('unexplored_areas', [])
        if len(unexplored_areas) > 0:
            return True
        
        # 检查搜索深度
        if self.current_loop < 2:  # 至少搜索2轮
            return True
        
        return False
    
    def _create_state_message(self, message: str) -> str:
        """创建状态变更消息"""
        return json.dumps({
            "requestId": self.request_id,
            "state": self.state.value,
            "message": message,
            "loop": self.current_loop,
            "timestamp": time.time()
        }, ensure_ascii=False)
    
    def _create_search_result_message(self, queries: List[str], docs_lists: List[List[Document]]) -> str:
        """创建搜索结果消息"""
        
        truncate_len = int(os.getenv("SINGLE_PAGE_MAX_SIZE", 200))
        
        return json.dumps({
            "requestId": self.request_id,
            "query": self.original_query,
            "searchResult": {
                "query": queries,
                "docs": [[doc.to_dict(truncate_len=truncate_len) for doc in docs] 
                        for docs in docs_lists]
            },
            "isFinal": False,
            "messageType": "search",
            "loop": self.current_loop
        }, ensure_ascii=False)
```

### 3.2 深度搜索工具的Java集成

```java
/**
 * 深度搜索工具状态机
 */
@Component
public class DeepSearchTool extends BaseTool implements ToolStateMachine {
    
    private final Map<String, ToolExecutionContext> executionContexts = 
        new ConcurrentHashMap<>();
    
    @Override
    public Stream<ToolStreamResult> executeStream(ToolCall toolCall) {
        String toolCallId = toolCall.getId();
        ToolExecutionContext context = createExecutionContext(toolCall);
        executionContexts.put(toolCallId, context);
        
        return Stream.generate(new DeepSearchStreamSupplier(toolCall, context))
            .takeWhile(result -> !result.isTerminal())
            .peek(result -> updateContextFromResult(context, result));
    }
    
    /**
     * 深度搜索流式供应器
     */
    private class DeepSearchStreamSupplier implements Supplier<ToolStreamResult> {
        private final ToolCall toolCall;
        private final ToolExecutionContext context;
        private final BlockingQueue<ToolStreamResult> resultQueue = 
            new LinkedBlockingQueue<>();
        private volatile boolean initialized = false;
        
        public DeepSearchStreamSupplier(ToolCall toolCall, ToolExecutionContext context) {
            this.toolCall = toolCall;
            this.context = context;
        }
        
        @Override
        public ToolStreamResult get() {
            if (!initialized) {
                initialize();
                initialized = true;
            }
            
            try {
                // 从队列中获取结果，超时机制防止无限等待
                ToolStreamResult result = resultQueue.poll(30, TimeUnit.SECONDS);
                
                if (result == null) {
                    // 超时处理
                    context.updateState(ToolExecutionState.TIMEOUT);
                    return ToolStreamResult.timeout(toolCall.getId(), "Deep search timeout");
                }
                
                return result;
                
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                context.updateState(ToolExecutionState.CANCELLED);
                return ToolStreamResult.cancelled(toolCall.getId(), "Deep search interrupted");
            }
        }
        
        private void initialize() {
            // 异步启动深度搜索
            CompletableFuture.runAsync(() -> {
                try {
                    context.updateState(ToolExecutionState.INITIALIZING);
                    
                    // 调用Python深度搜索服务
                    executeDeepSearchAsync();
                    
                } catch (Exception e) {
                    log.error("Deep search initialization failed", e);
                    resultQueue.offer(ToolStreamResult.error(
                        toolCall.getId(), "Initialization failed: " + e.getMessage()));
                }
            });
        }
        
        private void executeDeepSearchAsync() {
            try {
                // 构建深度搜索请求
                DeepSearchRequest request = buildDeepSearchRequest();
                
                // 发送流式HTTP请求
                try (CloseableHttpClient httpClient = createHttpClient()) {
                    HttpPost httpPost = createStreamingRequest(request);
                    
                    httpClient.execute(httpPost, response -> {
                        processStreamingResponse(response);
                        return null;
                    });
                }
                
            } catch (Exception e) {
                log.error("Deep search execution failed", e);
                resultQueue.offer(ToolStreamResult.error(
                    toolCall.getId(), "Execution failed: " + e.getMessage()));
            }
        }
        
        private void processStreamingResponse(CloseableHttpResponse response) {
            try (BufferedReader reader = new BufferedReader(
                    new InputStreamReader(response.getEntity().getContent()))) {
                
                String line;
                while ((line = reader.readLine()) != null) {
                    if (context.isCancelled()) {
                        break;
                    }
                    
                    // 解析流式响应
                    ToolStreamResult result = parseStreamingLine(line);
                    if (result != null) {
                        resultQueue.offer(result);
                        
                        // 更新上下文状态
                        updateContextFromStreamResult(result);
                    }
                }
                
                // 搜索完成
                if (!context.isCancelled()) {
                    context.updateState(ToolExecutionState.COMPLETED);
                    resultQueue.offer(ToolStreamResult.complete(
                        toolCall.getId(), "Deep search completed"));
                }
                
            } catch (IOException e) {
                log.error("Error reading streaming response", e);
                resultQueue.offer(ToolStreamResult.error(
                    toolCall.getId(), "Response reading failed: " + e.getMessage()));
            }
        }
        
        private ToolStreamResult parseStreamingLine(String line) {
            try {
                Map<String, Object> data = objectMapper.readValue(line, Map.class);
                String messageType = (String) data.get("messageType");
                
                switch (messageType) {
                    case "extend":
                        context.updateState(ToolExecutionState.RUNNING);
                        return ToolStreamResult.progress(toolCall.getId(), data);
                        
                    case "search":
                        context.updateState(ToolExecutionState.STREAMING);
                        context.appendOutput("Search results: " + data.get("searchResult"));
                        return ToolStreamResult.data(toolCall.getId(), data);
                        
                    case "final_result":
                        String finalResult = (String) data.get("result");
                        context.complete(finalResult);
                        return ToolStreamResult.complete(toolCall.getId(), finalResult);
                        
                    case "error":
                        String error = (String) data.get("error");
                        context.fail(error, null);
                        return ToolStreamResult.error(toolCall.getId(), error);
                        
                    default:
                        return ToolStreamResult.unknown(toolCall.getId(), data);
                }
                
            } catch (Exception e) {
                log.error("Failed to parse streaming line: " + line, e);
                return null;
            }
        }
    }
}
```

## 4. 工具执行结果的状态持久化与缓存策略

### 4.1 工具执行结果缓存设计

```java
/**
 * 工具执行结果缓存管理器
 */
@Component
public class ToolResultCacheManager {
    
    /**
     * 缓存项数据结构
     */
    @Data
    @Builder
    public static class CacheItem {
        private String key;
        private ToolResult result;
        private long createTime;
        private long accessTime;
        private int accessCount;
        private long expirationTime;
        private Set<String> tags = new HashSet<>();
        
        public boolean isExpired() {
            return System.currentTimeMillis() > expirationTime;
        }
        
        public void updateAccess() {
            this.accessTime = System.currentTimeMillis();
            this.accessCount++;
        }
    }
    
    private final Map<String, CacheItem> cache = new ConcurrentHashMap<>();
    private final ScheduledExecutorService cleanupExecutor = 
        Executors.newSingleThreadScheduledExecutor();
    
    /**
     * 生成缓存键
     */
    public String generateCacheKey(ToolCall toolCall) {
        // 基于工具名称、参数和版本生成唯一键
        StringBuilder keyBuilder = new StringBuilder()
            .append(toolCall.getName())
            .append(":")
            .append(toolCall.getArguments().hashCode());
        
        // 对于某些工具，可能需要考虑时间敏感性
        if (isTimeSensitive(toolCall.getName())) {
            long timeWindow = getTimeWindow(toolCall.getName());
            long currentWindow = System.currentTimeMillis() / timeWindow;
            keyBuilder.append(":").append(currentWindow);
        }
        
        return DigestUtils.md5Hex(keyBuilder.toString());
    }
    
    /**
     * 检查缓存
     */
    public Optional<ToolResult> getFromCache(String cacheKey) {
        CacheItem item = cache.get(cacheKey);
        
        if (item == null) {
            return Optional.empty();
        }
        
        // 检查是否过期
        if (item.isExpired()) {
            cache.remove(cacheKey);
            return Optional.empty();
        }
        
        // 更新访问信息
        item.updateAccess();
        
        log.debug("Cache hit for key: {}, access count: {}", 
            cacheKey, item.getAccessCount());
        
        return Optional.of(item.getResult());
    }
    
    /**
     * 保存到缓存
     */
    public void saveToCache(String cacheKey, ToolResult result, Duration ttl) {
        long expirationTime = System.currentTimeMillis() + ttl.toMillis();
        
        CacheItem item = CacheItem.builder()
            .key(cacheKey)
            .result(result)
            .createTime(System.currentTimeMillis())
            .accessTime(System.currentTimeMillis())
            .accessCount(0)
            .expirationTime(expirationTime)
            .build();
        
        // 根据工具类型添加标签
        item.getTags().add("tool:" + result.getToolName());
        
        cache.put(cacheKey, item);
        
        log.debug("Cached result for key: {}, expires at: {}", 
            cacheKey, new Date(expirationTime));
    }
    
    /**
     * 智能缓存策略判断
     */
    public boolean shouldCache(ToolCall toolCall, ToolResult result) {
        String toolName = toolCall.getName();
        
        // 不缓存失败的结果
        if (!result.isSuccess()) {
            return false;
        }
        
        // 不缓存实时性要求高的工具
        if (isRealTimeRequired(toolName)) {
            return false;
        }
        
        // 不缓存包含敏感信息的结果
        if (containsSensitiveData(result)) {
            return false;
        }
        
        // 不缓存太大的结果
        if (result.getData().length() > MAX_CACHE_SIZE) {
            return false;
        }
        
        return true;
    }
    
    /**
     * 获取缓存TTL策略
     */
    public Duration getCacheTTL(String toolName) {
        switch (toolName.toLowerCase()) {
            case "code_interpreter":
                return Duration.ofMinutes(30); // 代码执行结果缓存30分钟
                
            case "deep_search":
                return Duration.ofHours(2);    // 搜索结果缓存2小时
                
            case "file_operation":
                return Duration.ofMinutes(10); // 文件操作缓存10分钟
                
            case "web_scraping":
                return Duration.ofMinutes(15); // 网页抓取缓存15分钟
                
            default:
                return Duration.ofMinutes(5);  // 默认缓存5分钟
        }
    }
    
    /**
     * 缓存清理任务
     */
    @Scheduled(fixedRate = 300000) // 每5分钟执行一次
    public void cleanupExpiredCache() {
        int removedCount = 0;
        Iterator<Map.Entry<String, CacheItem>> iterator = cache.entrySet().iterator();
        
        while (iterator.hasNext()) {
            Map.Entry<String, CacheItem> entry = iterator.next();
            if (entry.getValue().isExpired()) {
                iterator.remove();
                removedCount++;
            }
        }
        
        if (removedCount > 0) {
            log.info("Cleaned up {} expired cache items", removedCount);
        }
    }
}
```

### 4.2 工具执行状态持久化

```java
/**
 * 工具执行状态持久化管理器
 */
@Component
public class ToolExecutionPersistenceManager {
    
    /**
     * 持久化的执行记录
     */
    @Data
    @Builder
    public static class ExecutionRecord {
        private String id;
        private String toolCallId;
        private String toolName;
        private String sessionId;
        private String requestId;
        
        // 执行信息
        private ToolExecutionState state;
        private Map<String, Object> parameters;
        private long startTime;
        private long endTime;
        private long duration;
        
        // 结果信息
        private String result;
        private String errorMessage;
        private List<String> outputHistory = new ArrayList<>();
        
        // 元数据
        private Map<String, Object> metadata = new HashMap<>();
        private long createTime;
        private long updateTime;
    }
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final String KEY_PREFIX = "tool_execution:";
    private final Duration DEFAULT_TTL = Duration.ofHours(24);
    
    /**
     * 保存执行状态
     */
    public void saveExecutionState(ToolExecutionContext context) {
        ExecutionRecord record = buildExecutionRecord(context);
        
        String key = KEY_PREFIX + context.getToolCallId();
        
        try {
            redisTemplate.opsForValue().set(key, record, DEFAULT_TTL);
            log.debug("Saved execution state for tool call: {}", context.getToolCallId());
        } catch (Exception e) {
            log.error("Failed to save execution state", e);
        }
    }
    
    /**
     * 加载执行状态
     */
    public Optional<ExecutionRecord> loadExecutionState(String toolCallId) {
        String key = KEY_PREFIX + toolCallId;
        
        try {
            ExecutionRecord record = (ExecutionRecord) redisTemplate.opsForValue().get(key);
            return Optional.ofNullable(record);
        } catch (Exception e) {
            log.error("Failed to load execution state for tool call: " + toolCallId, e);
            return Optional.empty();
        }
    }
    
    /**
     * 更新执行状态
     */
    public void updateExecutionState(String toolCallId, ToolExecutionState newState) {
        String key = KEY_PREFIX + toolCallId;
        
        try {
            ExecutionRecord record = (ExecutionRecord) redisTemplate.opsForValue().get(key);
            if (record != null) {
                record.setState(newState);
                record.setUpdateTime(System.currentTimeMillis());
                
                if (newState.isTerminal()) {
                    record.setEndTime(System.currentTimeMillis());
                    record.setDuration(record.getEndTime() - record.getStartTime());
                }
                
                redisTemplate.opsForValue().set(key, record, DEFAULT_TTL);
                log.debug("Updated execution state for tool call: {} to {}", 
                    toolCallId, newState);
            }
        } catch (Exception e) {
            log.error("Failed to update execution state", e);
        }
    }
    
    /**
     * 追加输出历史
     */
    public void appendOutputHistory(String toolCallId, String output) {
        String key = KEY_PREFIX + toolCallId;
        
        try {
            ExecutionRecord record = (ExecutionRecord) redisTemplate.opsForValue().get(key);
            if (record != null) {
                record.getOutputHistory().add(output);
                record.setUpdateTime(System.currentTimeMillis());
                
                // 限制输出历史长度，避免占用过多内存
                if (record.getOutputHistory().size() > 1000) {
                    record.getOutputHistory().remove(0);
                }
                
                redisTemplate.opsForValue().set(key, record, DEFAULT_TTL);
            }
        } catch (Exception e) {
            log.error("Failed to append output history", e);
        }
    }
    
    /**
     * 获取会话的所有工具执行记录
     */
    public List<ExecutionRecord> getSessionExecutionRecords(String sessionId) {
        Set<String> keys = redisTemplate.keys(KEY_PREFIX + "*");
        List<ExecutionRecord> records = new ArrayList<>();
        
        for (String key : keys) {
            try {
                ExecutionRecord record = (ExecutionRecord) redisTemplate.opsForValue().get(key);
                if (record != null && sessionId.equals(record.getSessionId())) {
                    records.add(record);
                }
            } catch (Exception e) {
                log.warn("Failed to load execution record for key: " + key, e);
            }
        }
        
        // 按创建时间排序
        records.sort(Comparator.comparingLong(ExecutionRecord::getCreateTime));
        
        return records;
    }
    
    private ExecutionRecord buildExecutionRecord(ToolExecutionContext context) {
        return ExecutionRecord.builder()
            .id(UUID.randomUUID().toString())
            .toolCallId(context.getToolCallId())
            .toolName(context.getToolName())
            .sessionId(context.getSessionId())
            .requestId(context.getRequestId())
            .state(context.getState())
            .parameters(new HashMap<>(context.getParameters()))
            .startTime(context.getStartTime())
            .endTime(context.getEndTime())
            .result(context.getFinalResult())
            .errorMessage(context.getErrorMessage())
            .outputHistory(new ArrayList<>(
                Arrays.asList(context.getOutputBuffer().toString().split("\n"))))
            .metadata(new HashMap<>(context.getMetadata()))
            .createTime(System.currentTimeMillis())
            .updateTime(System.currentTimeMillis())
            .build();
    }
}
```

## 5. 工具状态机的监控与调试

### 5.1 工具执行监控系统

```java
/**
 * 工具执行监控器
 */
@Component
public class ToolExecutionMonitor {
    
    /**
     * 工具执行指标
     */
    @Data
    @Builder
    public static class ExecutionMetrics {
        private String toolName;
        private long totalExecutions;
        private long successfulExecutions;
        private long failedExecutions;
        private double successRate;
        private long averageExecutionTime;
        private long maxExecutionTime;
        private long minExecutionTime;
        private Map<String, Long> errorTypeCounts = new HashMap<>();
    }
    
    private final MeterRegistry meterRegistry;
    private final Map<String, ExecutionMetrics> toolMetrics = new ConcurrentHashMap<>();
    
    /**
     * 记录工具执行开始
     */
    public void recordExecutionStart(String toolName, String toolCallId) {
        Timer.Sample sample = Timer.start(meterRegistry);
        sample.stop(Timer.builder("tool.execution.duration")
            .tag("tool", toolName)
            .register(meterRegistry));
        
        meterRegistry.counter("tool.execution.total", "tool", toolName)
            .increment();
    }
    
    /**
     * 记录工具执行完成
     */
    public void recordExecutionComplete(String toolName, String toolCallId, 
                                       long executionTime, boolean success) {
        if (success) {
            meterRegistry.counter("tool.execution.success", "tool", toolName)
                .increment();
        } else {
            meterRegistry.counter("tool.execution.failure", "tool", toolName)
                .increment();
        }
        
        meterRegistry.timer("tool.execution.time", "tool", toolName)
            .record(executionTime, TimeUnit.MILLISECONDS);
        
        updateToolMetrics(toolName, executionTime, success, null);
    }
    
    /**
     * 记录工具执行错误
     */
    public void recordExecutionError(String toolName, String toolCallId, 
                                    String errorType, Throwable error) {
        meterRegistry.counter("tool.execution.error", 
            "tool", toolName, 
            "error_type", errorType)
            .increment();
        
        updateToolMetrics(toolName, 0, false, errorType);
    }
    
    private void updateToolMetrics(String toolName, long executionTime, 
                                  boolean success, String errorType) {
        toolMetrics.compute(toolName, (key, metrics) -> {
            if (metrics == null) {
                metrics = ExecutionMetrics.builder()
                    .toolName(toolName)
                    .totalExecutions(0)
                    .successfulExecutions(0)
                    .failedExecutions(0)
                    .averageExecutionTime(0)
                    .maxExecutionTime(0)
                    .minExecutionTime(Long.MAX_VALUE)
                    .build();
            }
            
            metrics.setTotalExecutions(metrics.getTotalExecutions() + 1);
            
            if (success) {
                metrics.setSuccessfulExecutions(metrics.getSuccessfulExecutions() + 1);
                
                // 更新执行时间统计
                metrics.setMaxExecutionTime(Math.max(metrics.getMaxExecutionTime(), executionTime));
                metrics.setMinExecutionTime(Math.min(metrics.getMinExecutionTime(), executionTime));
                
                // 更新平均执行时间
                long totalTime = metrics.getAverageExecutionTime() * (metrics.getSuccessfulExecutions() - 1) + executionTime;
                metrics.setAverageExecutionTime(totalTime / metrics.getSuccessfulExecutions());
                
            } else {
                metrics.setFailedExecutions(metrics.getFailedExecutions() + 1);
                
                if (errorType != null) {
                    metrics.getErrorTypeCounts().merge(errorType, 1L, Long::sum);
                }
            }
            
            // 更新成功率
            metrics.setSuccessRate((double) metrics.getSuccessfulExecutions() / 
                                  metrics.getTotalExecutions() * 100);
            
            return metrics;
        });
    }
    
    /**
     * 获取工具执行报告
     */
    public Map<String, ExecutionMetrics> getExecutionReport() {
        return new HashMap<>(toolMetrics);
    }
    
    /**
     * 获取性能异常的工具列表
     */
    public List<String> getPerformanceAnomalies() {
        return toolMetrics.entrySet().stream()
            .filter(entry -> {
                ExecutionMetrics metrics = entry.getValue();
                // 成功率低于80%或平均执行时间超过30秒
                return metrics.getSuccessRate() < 80.0 || 
                       metrics.getAverageExecutionTime() > 30000;
            })
            .map(Map.Entry::getKey)
            .collect(Collectors.toList());
    }
}
```

## 6. 小结

本节深入探讨了工具调用状态机与异步执行管理的关键技术：

1. **生命周期状态设计**：定义了完整的工具执行状态枚举和转换规则
2. **代码解释器状态机**：实现了分步执行的流式状态控制机制
3. **深度搜索状态机**：设计了多轮迭代的智能搜索状态管理
4. **结果持久化策略**：建立了缓存和持久化的综合解决方案
5. **监控调试系统**：提供了工具执行的全方位监控和性能分析

这些技术确保了AI应用中工具调用的可靠性、可观测性和可维护性，为复杂的AI工作流提供了坚实的技术基础。

## 延伸思考

1. 如何实现工具调用的智能负载均衡和资源调度？
2. 如何设计工具执行的断点续传和增量更新机制？
3. 如何优化长时间运行工具的内存使用和垃圾回收？
4. 如何实现跨服务的工具调用状态同步？

下一节我们将探讨多Agent协作的分布式状态机设计与实现。
