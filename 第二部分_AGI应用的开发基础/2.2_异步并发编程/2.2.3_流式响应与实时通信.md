# 2.2.3 流式响应与实时通信

## 学习目标

设计并实现AI应用的流式响应机制，掌握Server-Sent Events（SSE）等实时通信技术在AI场景中的应用。

## 2.2.3.1 AI应用中的实时通信需求

### 流式响应的重要性

在AI应用中，流式响应解决了几个关键用户体验问题：

1. **降低感知延迟**：用户可以立即看到AI开始响应，而不是等待完整结果
2. **处理长时间任务**：AI推理可能需要几秒到几分钟，流式响应保持用户参与感
3. **内容预览**：用户可以提前阅读部分结果，提升交互效率
4. **错误快速反馈**：如果处理出现问题，可以立即停止并反馈给用户

### 典型的AI流式场景

```
传统模式：
用户提问 → [等待30秒] → 完整答案显示

流式模式：
用户提问 → 立即显示"正在思考..." → 逐步显示答案内容 → 完成
```

## 2.2.3.2 Server-Sent Events (SSE) 实现

### 后端SSE服务实现

基于JD Genie项目的SSE实现，我们可以看到企业级的流式响应架构：

```java
// GenieController.java - SSE控制器实现
@RestController
public class GenieController {
    
    private final ScheduledExecutorService executor = Executors.newScheduledThreadPool(5);
    private static final long HEARTBEAT_INTERVAL = 10_000L; // 10秒心跳间隔
    
    @PostMapping("/AutoAgent")
    public SseEmitter AutoAgent(@RequestBody AgentRequest request) 
            throws UnsupportedEncodingException {
        
        logger.info("{} auto agent request: {}", 
                   request.getRequestId(), JSON.toJSONString(request));

        Long AUTO_AGENT_SSE_TIMEOUT = 60 * 60 * 1000L; // 1小时超时
        SseEmitter emitter = new SseEmitter(AUTO_AGENT_SSE_TIMEOUT);
        
        // 启动心跳机制
        ScheduledFuture<?> heartbeatFuture = startHeartbeat(emitter, request.getRequestId());
        
        // 注册连接监听器
        registerSSEMonitor(emitter, request.getRequestId(), heartbeatFuture);
        
        // 异步执行AI处理逻辑
        ThreadUtil.execute(() -> {
            try {
                Printer printer = new SSEPrinter(emitter, request, request.getAgentType());
                AgentContext agentContext = buildAgentContext(request, printer);
                
                // 获取处理器并执行
                AgentHandlerService handler = agentHandlerFactory.getHandler(agentContext, request);
                handler.handle(agentContext, request);
                
                // 正常完成
                emitter.complete();
                
            } catch (Exception e) {
                logger.error("{} auto agent error", request.getRequestId(), e);
                emitter.completeWithError(e);
            }
        });

        return emitter;
    }
    
    /**
     * SSE心跳机制：保持长连接活跃
     */
    private ScheduledFuture<?> startHeartbeat(SseEmitter emitter, String requestId) {
        return executor.scheduleAtFixedRate(() -> {
            try {
                logger.debug("{} send heartbeat", requestId);
                emitter.send("heartbeat");
            } catch (Exception e) {
                logger.error("{} heartbeat failed, closing connection", requestId, e);
                emitter.completeWithError(e);
            }
        }, HEARTBEAT_INTERVAL, HEARTBEAT_INTERVAL, TimeUnit.MILLISECONDS);
    }
    
    /**
     * SSE连接事件监听
     */
    private void registerSSEMonitor(SseEmitter emitter, String requestId, 
                                   ScheduledFuture<?> heartbeatFuture) {
        // 正常完成事件
        emitter.onCompletion(() -> {
            logger.info("{} SSE connection completed normally", requestId);
            heartbeatFuture.cancel(true);
        });

        // 连接超时事件
        emitter.onTimeout(() -> {
            logger.info("{} SSE connection timed out", requestId);
            heartbeatFuture.cancel(true);
            emitter.complete();
        });

        // 连接错误事件
        emitter.onError((ex) -> {
            logger.error("{} SSE connection error", requestId, ex);
            heartbeatFuture.cancel(true);
            emitter.completeWithError(ex);
        });
    }
}
```

### SSE打印器：结构化消息输出

```java
// SSEPrinter.java - 流式消息输出器
public class SSEPrinter implements Printer {
    
    private final SseEmitter emitter;
    private final AgentRequest request;
    private String agentType;

    @Override
    public void send(String messageId, String messageType, Object message, 
                    String digitalEmployee, Boolean isFinal) {
        try {
            AgentResponse response = new AgentResponse();
            response.setRequestId(request.getRequestId());
            response.setMessageId(messageId);
            response.setMessageType(messageType);
            response.setIsFinal(isFinal);
            response.setDigitalEmployee(digitalEmployee);

            // 根据消息类型处理内容
            switch (messageType) {
                case "planning":
                    if (message instanceof List) {
                        @SuppressWarnings("unchecked")
                        List<String> plans = (List<String>) message;
                        response.setPlanList(plans);
                    }
                    break;
                    
                case "agent_stream":
                    response.setResult((String) message);
                    break;
                    
                case "result":
                    if (message instanceof Map) {
                        @SuppressWarnings("unchecked")
                        Map<String, Object> taskResult = (Map<String, Object>) message;
                        response.setResultMap(taskResult);
                        Object summary = taskResult.get("taskSummary");
                        response.setResult(summary != null ? summary.toString() : null);
                    }
                    response.getResultMap().put("agentType", agentType);
                    break;
                    
                default:
                    logger.warn("Unknown message type: {}", messageType);
                    break;
            }

            // 发送SSE消息
            emitter.send(response);

        } catch (Exception e) {
            logger.error("SSE send error", e);
        }
    }
    
    @Override
    public void close() {
        emitter.complete();
    }
}
```

## 2.2.3.3 Python FastAPI流式响应

### EventSourceResponse实现

Python服务使用FastAPI的EventSourceResponse实现流式输出：

```python
# tool.py - FastAPI流式API实现
from fastapi.responses import EventSourceResponse
from sse_starlette import ServerSentEvent

@app.post("/v1/tool/deepsearch")
async def post_deepsearch(body: DeepSearchRequest):
    """深度搜索的流式API"""
    
    async def _stream():
        """异步流式生成器"""
        try:
            deepsearch = DeepSearch()
            
            # 流式执行搜索任务
            async for chunk in deepsearch.run(
                query=body.query,
                request_id=body.request_id,
                stream=True,
                stream_mode=StreamMode()
            ):
                # 发送流式数据
                yield ServerSentEvent(
                    data=chunk,
                    event="data",
                    id=body.request_id
                )
                
                # 控制流式输出频率
                await asyncio.sleep(0.01)
                
        except Exception as e:
            logger.error(f"DeepSearch streaming error: {e}")
            yield ServerSentEvent(
                data=json.dumps({
                    "error": str(e),
                    "requestId": body.request_id,
                    "isFinal": True
                }),
                event="error",
                id=body.request_id
            )

    return EventSourceResponse(
        _stream(),
        ping_message_factory=lambda: ServerSentEvent(data="heartbeat"),
        ping=15  # 15秒心跳间隔
    )
```

### 异步流式数据处理

```python
# deepsearch.py - 流式搜索实现
class DeepSearch:
    
    async def run(self, query: str, request_id: str = None, 
                  stream: bool = False, **kwargs) -> AsyncGenerator[str, None]:
        """流式执行深度搜索"""
        
        try:
            # 第一阶段：查询分解
            yield self._create_stream_message(
                request_id=request_id,
                status="query_decomposition",
                message="正在分解查询..."
            )
            
            queries = await query_decompose(query, request_id=request_id)
            
            # 第二阶段：并行搜索
            yield self._create_stream_message(
                request_id=request_id,
                status="searching",
                message=f"正在搜索 {len(queries)} 个子查询..."
            )
            
            docs, search_results = await self._search_queries_and_dedup(queries, request_id)
            
            # 第三阶段：生成答案
            yield self._create_stream_message(
                request_id=request_id,
                status="generating",
                message="正在生成答案...",
                search_result={
                    "query": queries,
                    "docs": [doc.dict() for doc in docs[:5]]  # 只显示前5个结果
                }
            )
            
            # 流式答案生成
            acc_content = ""
            async for chunk in answer_question(
                query=query, 
                docs=docs, 
                request_id=request_id,
                stream=stream
            ):
                if stream and chunk:
                    acc_content += chunk
                    yield json.dumps({
                        "requestId": request_id,
                        "query": query,
                        "searchResult": {
                            "query": queries, 
                            "docs": [doc.dict() for doc in docs]
                        },
                        "answer": chunk,
                        "isFinal": False,
                        "messageType": "search"
                    }, ensure_ascii=False)
            
            # 最终结果
            yield json.dumps({
                "requestId": request_id,
                "query": query,
                "searchResult": {
                    "query": queries, 
                    "docs": [doc.dict() for doc in docs]
                },
                "answer": acc_content,
                "isFinal": True,
                "messageType": "search"
            }, ensure_ascii=False)
            
        except Exception as e:
            logger.error(f"DeepSearch streaming error: {e}")
            yield json.dumps({
                "requestId": request_id,
                "query": query,
                "error": str(e),
                "isFinal": True,
                "messageType": "error"
            }, ensure_ascii=False)
    
    def _create_stream_message(self, request_id: str, status: str, 
                              message: str, **kwargs) -> str:
        """创建流式消息"""
        data = {
            "requestId": request_id,
            "status": status,
            "message": message,
            "isFinal": False,
            "messageType": "status"
        }
        data.update(kwargs)
        return json.dumps(data, ensure_ascii=False)
```

## 2.2.3.4 前端SSE客户端实现

### TypeScript SSE客户端

```typescript
// querySSE.ts - 现代化SSE客户端实现
import { fetchEventSource, EventSourceMessage } from '@microsoft/fetch-event-source';

interface SSEConfig {
  body: any;
  handleMessage: (data: any) => void;
  handleError: (error: Error) => void;
  handleClose: () => void;
  onStatusChange?: (status: string) => void;
}

const SSE_HEADERS = {
  'Content-Type': 'application/json',
  'Cache-Control': 'no-cache',
  'Connection': 'keep-alive',
  'Accept': 'text/event-stream',
};

export default function createSSEConnection(
  config: SSEConfig, 
  url: string = DEFAULT_SSE_URL
): AbortController {
  
  const { body, handleMessage, handleError, handleClose, onStatusChange } = config;
  const abortController = new AbortController();

  fetchEventSource(url, {
    method: 'POST',
    credentials: 'include',
    headers: SSE_HEADERS,
    body: JSON.stringify(body),
    signal: abortController.signal,
    openWhenHidden: true,
    
    onopen(response) {
      console.log('SSE connection opened:', response.status);
      onStatusChange?.('connected');
      
      if (response.ok && response.headers.get('content-type')?.includes('text/event-stream')) {
        return; // 连接成功
      } else {
        throw new Error(`SSE connection failed: ${response.status}`);
      }
    },
    
    onmessage(event: EventSourceMessage) {
      try {
        // 处理心跳消息
        if (event.data === 'heartbeat') {
          console.debug('Received heartbeat');
          return;
        }
        
        // 解析并处理业务消息
        const parsedData = JSON.parse(event.data);
        handleMessage(parsedData);
        
        // 状态更新
        if (parsedData.messageType === 'status') {
          onStatusChange?.(parsedData.status);
        }
        
      } catch (error) {
        console.error('Error parsing SSE message:', error);
        handleError(new Error('Failed to parse SSE message'));
      }
    },
    
    onerror(error: Error) {
      console.error('SSE error:', error);
      onStatusChange?.('error');
      handleError(error);
    },
    
    onclose() {
      console.log('SSE connection closed');
      onStatusChange?.('disconnected');
      handleClose();
    }
  });
  
  return abortController;
}
```

### React Hooks集成

```typescript
// useAIStream.ts - React流式AI交互Hook
import { useState, useCallback, useRef, useEffect } from 'react';

interface StreamMessage {
  id: string;
  type: string;
  content: string;
  timestamp: number;
  isFinal: boolean;
  metadata?: any;
}

interface StreamState {
  messages: StreamMessage[];
  isConnected: boolean;
  isLoading: boolean;
  error: string | null;
  status: string;
}

export function useAIStream() {
  const [state, setState] = useState<StreamState>({
    messages: [],
    isConnected: false,
    isLoading: false,
    error: null,
    status: 'disconnected'
  });
  
  const abortControllerRef = useRef<AbortController | null>(null);
  
  const sendMessage = useCallback(async (query: string, agentType: string = 'react') => {
    // 重置状态
    setState(prev => ({
      ...prev,
      messages: [],
      isLoading: true,
      error: null,
      status: 'connecting'
    }));
    
    // 中断之前的连接
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }
    
    const config: SSEConfig = {
      body: { 
        query, 
        agentType,
        requestId: `req_${Date.now()}`,
        isStream: true
      },
      
      handleMessage: (data) => {
        const message: StreamMessage = {
          id: data.messageId || `msg_${Date.now()}`,
          type: data.messageType || 'text',
          content: data.result || data.message || '',
          timestamp: Date.now(),
          isFinal: data.isFinal || false,
          metadata: {
            agentType: data.agentType,
            planList: data.planList,
            searchResult: data.searchResult
          }
        };
        
        setState(prev => ({
          ...prev,
          messages: [...prev.messages, message],
          isLoading: !message.isFinal
        }));
      },
      
      handleError: (error) => {
        setState(prev => ({
          ...prev,
          error: error.message,
          isLoading: false,
          isConnected: false,
          status: 'error'
        }));
      },
      
      handleClose: () => {
        setState(prev => ({
          ...prev,
          isLoading: false,
          isConnected: false,
          status: 'disconnected'
        }));
      },
      
      onStatusChange: (status) => {
        setState(prev => ({
          ...prev,
          status,
          isConnected: status === 'connected'
        }));
      }
    };

    // 创建新连接
    abortControllerRef.current = createSSEConnection(config);
  }, []);
  
  const disconnect = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
    }
  }, []);
  
  // 组件卸载时清理连接
  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);
  
  return {
    ...state,
    sendMessage,
    disconnect
  };
}
```

## 2.2.3.5 WebSocket vs SSE 技术选型

### SSE的优势

1. **简单易用**：基于HTTP协议，穿越代理和防火墙容易
2. **自动重连**：浏览器原生支持断线重连
3. **单向通信**：适合服务端推送场景
4. **标准化**：W3C标准，浏览器支持良好

```typescript
// SSE适用场景示例
const eventSource = new EventSource('/api/ai-stream');
eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  updateUI(data);
};
```

### WebSocket的优势

1. **双向通信**：支持客户端和服务端双向实时交互
2. **更低延迟**：没有HTTP头部开销
3. **二进制支持**：可以传输二进制数据
4. **协议灵活**：可以自定义子协议

```typescript
// WebSocket适用场景示例
const ws = new WebSocket('wss://api.example.com/ai-socket');
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.type === 'ai_response') {
    updateUI(data);
  }
};
ws.send(JSON.stringify({ type: 'user_input', data: userQuery }));
```

### AI应用场景选择指南

| 场景 | 推荐技术 | 理由 |
|------|----------|------|
| ChatGPT式对话 | SSE | 单向流式输出，简单可靠 |
| 实时协作编辑 | WebSocket | 需要双向实时同步 |
| AI模型训练监控 | SSE | 服务端状态推送为主 |
| 游戏AI对战 | WebSocket | 高频双向交互 |
| 文档AI分析 | SSE | 分析结果流式展示 |

## 2.2.3.6 流式数据的背压控制

### 客户端背压处理

```typescript
// 背压控制的SSE客户端
class BackpressureSSEClient {
  private messageQueue: any[] = [];
  private processing = false;
  private maxQueueSize = 100;
  
  constructor(private config: SSEConfig) {}
  
  start() {
    const originalHandleMessage = this.config.handleMessage;
    
    this.config.handleMessage = (data) => {
      // 队列满时丢弃旧消息
      if (this.messageQueue.length >= this.maxQueueSize) {
        this.messageQueue.shift();
        console.warn('Message queue overflow, dropping old message');
      }
      
      this.messageQueue.push(data);
      this.processQueue();
    };
    
    createSSEConnection(this.config);
  }
  
  private async processQueue() {
    if (this.processing) return;
    
    this.processing = true;
    try {
      while (this.messageQueue.length > 0) {
        const message = this.messageQueue.shift();
        await this.processMessage(message);
        
        // 控制处理速率
        await new Promise(resolve => setTimeout(resolve, 10));
      }
    } finally {
      this.processing = false;
    }
  }
  
  private async processMessage(message: any) {
    // 处理单个消息
    try {
      await this.config.handleMessage(message);
    } catch (error) {
      console.error('Error processing message:', error);
    }
  }
}
```

### 服务端流量控制

```python
# 服务端背压控制
import asyncio
from collections import deque

class FlowControlledStream:
    def __init__(self, max_buffer_size: int = 1000):
        self.buffer = deque(maxlen=max_buffer_size)
        self.client_ready = asyncio.Event()
        self.client_ready.set()  # 初始状态为就绪
    
    async def send_with_backpressure(self, data: str):
        """带背压控制的发送"""
        
        # 等待客户端就绪
        await self.client_ready.wait()
        
        # 检查缓冲区
        if len(self.buffer) >= self.buffer.maxlen * 0.8:
            # 缓冲区接近满，暂停发送
            self.client_ready.clear()
            logger.warning("Buffer near full, pausing stream")
            
            # 等待缓冲区清空
            while len(self.buffer) > self.buffer.maxlen * 0.3:
                await asyncio.sleep(0.1)
            
            self.client_ready.set()
        
        self.buffer.append(data)
        return data
    
    async def stream_generator(self):
        """流式生成器"""
        while self.buffer:
            try:
                data = self.buffer.popleft()
                yield f"data: {data}\n\n"
                await asyncio.sleep(0.01)  # 控制发送速率
            except IndexError:
                break

@app.post("/v1/controlled-stream")
async def controlled_stream(request: StreamRequest):
    flow_controller = FlowControlledStream()
    
    async def _stream():
        # 模拟AI处理并生成数据
        for i in range(1000):
            data = f"Processing step {i}"
            await flow_controller.send_with_backpressure(data)
        
        # 流式输出
        async for chunk in flow_controller.stream_generator():
            yield chunk
    
    return EventSourceResponse(_stream())
```

## 2.2.3.7 容错与恢复机制

### 断线重连策略

```typescript
// 智能重连的SSE客户端
class ResilientSSEClient {
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 5;
  private baseRetryDelay = 1000; // 1秒
  private currentConnection: AbortController | null = null;
  
  constructor(
    private config: SSEConfig,
    private url: string
  ) {}
  
  connect() {
    this.attemptConnection();
  }
  
  private async attemptConnection() {
    try {
      if (this.currentConnection) {
        this.currentConnection.abort();
      }
      
      const enhancedConfig: SSEConfig = {
        ...this.config,
        handleError: (error) => {
          console.error('SSE connection error:', error);
          this.handleConnectionError(error);
        },
        handleClose: () => {
          console.log('SSE connection closed');
          this.handleConnectionClose();
        }
      };
      
      this.currentConnection = createSSEConnection(enhancedConfig, this.url);
      this.reconnectAttempts = 0; // 重置重连计数
      
    } catch (error) {
      this.handleConnectionError(error);
    }
  }
  
  private handleConnectionError(error: any) {
    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      const delay = this.calculateRetryDelay();
      console.log(`Reconnecting in ${delay}ms (attempt ${this.reconnectAttempts + 1}/${this.maxReconnectAttempts})`);
      
      setTimeout(() => {
        this.reconnectAttempts++;
        this.attemptConnection();
      }, delay);
    } else {
      console.error('Max reconnection attempts reached');
      this.config.handleError(new Error('Connection failed after maximum retries'));
    }
  }
  
  private handleConnectionClose() {
    // 正常关闭不需要重连
    this.config.handleClose();
  }
  
  private calculateRetryDelay(): number {
    // 指数退避算法
    return Math.min(
      this.baseRetryDelay * Math.pow(2, this.reconnectAttempts),
      30000 // 最大30秒
    );
  }
  
  disconnect() {
    this.reconnectAttempts = this.maxReconnectAttempts; // 阻止自动重连
    if (this.currentConnection) {
      this.currentConnection.abort();
      this.currentConnection = null;
    }
  }
}
```

### 消息去重与排序

```typescript
// 消息去重和排序处理
class OrderedMessageHandler {
  private messageBuffer = new Map<string, any>();
  private expectedSequence = 0;
  private processedMessages = new Set<string>();
  
  handleMessage(message: any) {
    // 去重处理
    if (this.processedMessages.has(message.id)) {
      console.warn('Duplicate message received:', message.id);
      return;
    }
    
    // 如果消息有序列号，进行排序
    if (message.sequence !== undefined) {
      this.handleOrderedMessage(message);
    } else {
      // 无序列号消息直接处理
      this.processMessage(message);
    }
  }
  
  private handleOrderedMessage(message: any) {
    if (message.sequence === this.expectedSequence) {
      // 期望的下一个消息，立即处理
      this.processMessage(message);
      this.expectedSequence++;
      
      // 检查缓冲区中是否有后续消息
      this.processBufferedMessages();
    } else if (message.sequence > this.expectedSequence) {
      // 未来的消息，缓存起来
      this.messageBuffer.set(message.sequence.toString(), message);
    }
    // 过期消息直接丢弃
  }
  
  private processBufferedMessages() {
    while (this.messageBuffer.has(this.expectedSequence.toString())) {
      const message = this.messageBuffer.get(this.expectedSequence.toString());
      this.messageBuffer.delete(this.expectedSequence.toString());
      this.processMessage(message);
      this.expectedSequence++;
    }
  }
  
  private processMessage(message: any) {
    this.processedMessages.add(message.id);
    // 实际的消息处理逻辑
    console.log('Processing message:', message);
  }
}
```

## 2.2.3.8 性能优化策略

### 消息压缩与批量处理

```python
# 服务端消息优化
import json
import gzip
from typing import List

class OptimizedSSEHandler:
    
    def __init__(self, compression_threshold: int = 1024, batch_size: int = 10):
        self.compression_threshold = compression_threshold
        self.batch_size = batch_size
        self.message_batch: List[dict] = []
    
    async def send_message(self, message: dict, force_send: bool = False):
        """批量发送消息"""
        self.message_batch.append(message)
        
        if len(self.message_batch) >= self.batch_size or force_send:
            await self._flush_batch()
    
    async def _flush_batch(self):
        """刷新消息批次"""
        if not self.message_batch:
            return
            
        if len(self.message_batch) == 1:
            # 单条消息直接发送
            message = self.message_batch[0]
            yield self._format_sse_message(message)
        else:
            # 批量消息打包发送
            batch_data = {
                "type": "batch",
                "messages": self.message_batch,
                "count": len(self.message_batch)
            }
            yield self._format_sse_message(batch_data)
        
        self.message_batch.clear()
    
    def _format_sse_message(self, data: dict) -> str:
        """格式化SSE消息"""
        json_data = json.dumps(data, ensure_ascii=False)
        
        # 大消息压缩
        if len(json_data) > self.compression_threshold:
            compressed_data = gzip.compress(json_data.encode('utf-8'))
            encoded_data = base64.b64encode(compressed_data).decode('ascii')
            return f"data: {{\"compressed\": true, \"data\": \"{encoded_data}\"}}\n\n"
        else:
            return f"data: {json_data}\n\n"

# 使用示例
@app.post("/v1/optimized-stream")
async def optimized_stream(request: StreamRequest):
    handler = OptimizedSSEHandler()
    
    async def _stream():
        try:
            # 模拟AI处理过程
            for i in range(100):
                message = {
                    "sequence": i,
                    "content": f"Processing step {i}",
                    "timestamp": time.time()
                }
                
                # 批量发送，最后一条强制发送
                async for chunk in handler.send_message(
                    message, 
                    force_send=(i == 99)
                ):
                    yield chunk
                
                await asyncio.sleep(0.1)
        
        except Exception as e:
            yield f"data: {{\"error\": \"{str(e)}\"}}\n\n"
    
    return EventSourceResponse(_stream())
```

## 小结

流式响应与实时通信是现代AI应用用户体验的关键技术。通过合理选择SSE或WebSocket技术，配合适当的背压控制、容错机制和性能优化策略，可以构建出响应迅速、用户体验优秀的AI应用。

关键要点：
1. **技术选型**：根据应用场景选择SSE或WebSocket
2. **背压控制**：防止客户端处理不过来导致的问题
3. **容错机制**：处理网络不稳定和连接中断
4. **性能优化**：消息批量处理和压缩传输

---

**最佳实践建议：**
1. 优先选择SSE，除非需要双向通信
2. 实现智能重连和消息去重机制
3. 监控连接质量和消息延迟
4. 为用户提供连接状态反馈
