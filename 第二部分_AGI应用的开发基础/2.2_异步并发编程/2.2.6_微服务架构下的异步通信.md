# 2.2.6 微服务架构下的异步通信

## 学习目标

设计AI应用的微服务异步通信架构，实现服务间的高效协作与容错处理。

## 2.2.6.1 AI微服务架构概览

### 服务拆分原则

在AI应用中，微服务拆分通常基于以下原则：

1. **功能职责分离**：将不同AI能力拆分为独立服务
2. **数据域隔离**：每个服务管理自己的数据
3. **技术栈优化**：不同服务可选择最适合的技术栈
4. **独立部署**：服务可独立发布和扩展

基于JD Genie项目，典型的AI微服务架构包括：

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Frontend UI   │    │   API Gateway   │    │  Auth Service   │
│    (React)      │◄──►│    (Spring)     │◄──►│    (Java)       │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                               │
        ┌──────────────────────┼──────────────────────┐
        │                      │                      │
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│  Agent Service  │    │  Tool Service   │    │ File Service    │
│    (Java)       │    │   (Python)      │    │   (Python)      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                      │                      │
        └──────────────────────┼──────────────────────┘
                               │
                    ┌─────────────────┐
                    │ Message Queue   │
                    │    (Redis)      │
                    └─────────────────┘
```

### 异步通信的必要性

在AI微服务架构中，异步通信解决以下问题：

1. **服务解耦**：避免服务间紧耦合导致的连锁故障
2. **性能优化**：长时间AI处理不阻塞其他服务
3. **可伸缩性**：独立扩展不同服务的处理能力
4. **容错能力**：服务故障时其他服务仍可正常工作

## 2.2.6.2 基于消息队列的异步通信

### Redis Stream消息队列

```java
// AsyncMessageProducer.java - 异步消息生产者
@Component
public class AsyncMessageProducer {
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final ExecutorService executor = Executors.newFixedThreadPool(5);
    
    public AsyncMessageProducer(RedisTemplate<String, Object> redisTemplate) {
        this.redisTemplate = redisTemplate;
    }
    
    /**
     * 发送AI任务处理消息
     */
    public CompletableFuture<String> sendAITaskAsync(AITaskMessage task) {
        return CompletableFuture.supplyAsync(() -> {
            try {
                Map<String, Object> messageData = Map.of(
                    "taskId", task.getTaskId(),
                    "taskType", task.getTaskType(),
                    "payload", task.getPayload(),
                    "timestamp", System.currentTimeMillis(),
                    "priority", task.getPriority()
                );
                
                // 发送到Redis Stream
                RecordId recordId = redisTemplate.opsForStream()
                    .add("ai-tasks", messageData);
                
                logger.info("AI task {} sent to queue: {}", task.getTaskId(), recordId);
                return recordId.getValue();
                
            } catch (Exception e) {
                logger.error("Failed to send AI task: {}", task.getTaskId(), e);
                throw new RuntimeException(e);
            }
        }, executor);
    }
    
    /**
     * 批量发送消息
     */
    public CompletableFuture<List<String>> sendBatchTasksAsync(List<AITaskMessage> tasks) {
        List<CompletableFuture<String>> futures = tasks.stream()
            .map(this::sendAITaskAsync)
            .collect(Collectors.toList());
        
        return CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
            .thenApply(v -> futures.stream()
                .map(CompletableFuture::join)
                .collect(Collectors.toList()));
    }
    
    /**
     * 发送事件通知
     */
    public void publishEventAsync(String eventType, Object eventData) {
        CompletableFuture.runAsync(() -> {
            try {
                Map<String, Object> event = Map.of(
                    "eventType", eventType,
                    "data", eventData,
                    "timestamp", System.currentTimeMillis()
                );
                
                redisTemplate.convertAndSend("ai-events", event);
                logger.debug("Event published: {}", eventType);
                
            } catch (Exception e) {
                logger.error("Failed to publish event: {}", eventType, e);
            }
        }, executor);
    }
}

// AsyncMessageConsumer.java - 异步消息消费者
@Component
public class AsyncMessageConsumer {
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final AITaskProcessor taskProcessor;
    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(3);
    
    @PostConstruct
    public void startConsuming() {
        // 启动多个消费者线程
        for (int i = 0; i < 3; i++) {
            String consumerName = "consumer-" + i;
            scheduler.scheduleWithFixedDelay(
                () -> consumeMessages(consumerName), 
                0, 1, TimeUnit.SECONDS
            );
        }
    }
    
    private void consumeMessages(String consumerName) {
        try {
            List<MapRecord<String, Object, Object>> messages = redisTemplate.opsForStream()
                .read(Consumer.from("ai-processors", consumerName),
                      StreamReadOptions.empty().count(10),
                      StreamOffset.create("ai-tasks", ReadOffset.lastConsumed()));
            
            if (!messages.isEmpty()) {
                processMessagesAsync(messages, consumerName);
            }
            
        } catch (Exception e) {
            logger.error("Error consuming messages for {}: {}", consumerName, e.getMessage());
        }
    }
    
    private void processMessagesAsync(List<MapRecord<String, Object, Object>> messages, 
                                    String consumerName) {
        List<CompletableFuture<Void>> processingTasks = messages.stream()
            .map(message -> processMessageAsync(message, consumerName))
            .collect(Collectors.toList());
        
        CompletableFuture.allOf(processingTasks.toArray(new CompletableFuture[0]))
            .whenComplete((v, ex) -> {
                if (ex != null) {
                    logger.error("Batch processing failed for consumer {}", consumerName, ex);
                }
            });
    }
    
    private CompletableFuture<Void> processMessageAsync(MapRecord<String, Object, Object> message, 
                                                       String consumerName) {
        return CompletableFuture.runAsync(() -> {
            try {
                Map<Object, Object> messageData = message.getValue();
                AITaskMessage task = parseTaskMessage(messageData);
                
                // 处理AI任务
                taskProcessor.processTask(task);
                
                // 确认消息处理完成
                redisTemplate.opsForStream().acknowledge("ai-tasks", "ai-processors", message.getId());
                
                logger.info("Task {} processed by {}", task.getTaskId(), consumerName);
                
            } catch (Exception e) {
                logger.error("Failed to process message {} by {}", message.getId(), consumerName, e);
                // 这里可以实现重试或死信队列逻辑
            }
        });
    }
}
```

### Python异步消息处理

```python
# async_message_handler.py - Python异步消息处理
import asyncio
import json
import redis.asyncio as redis
from typing import Dict, List, Any, Callable
import logging

class AsyncMessageHandler:
    """异步消息处理器"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_client = redis.from_url(redis_url)
        self.message_handlers: Dict[str, Callable] = {}
        self.running = False
        
    def register_handler(self, message_type: str, handler: Callable):
        """注册消息处理器"""
        self.message_handlers[message_type] = handler
        logger.info(f"Registered handler for message type: {message_type}")
    
    async def start_consuming(self, stream_name: str, consumer_group: str, consumer_name: str):
        """开始消费消息"""
        self.running = True
        
        try:
            # 创建消费者组（如果不存在）
            try:
                await self.redis_client.xgroup_create(stream_name, consumer_group, id='0', mkstream=True)
            except redis.ResponseError as e:
                if "BUSYGROUP" not in str(e):
                    raise
            
            logger.info(f"Started consuming from {stream_name} as {consumer_name}")
            
            while self.running:
                try:
                    # 读取消息
                    messages = await self.redis_client.xreadgroup(
                        consumer_group, consumer_name,
                        {stream_name: '>'},
                        count=10,
                        block=1000
                    )
                    
                    if messages:
                        await self._process_messages_batch(messages[0][1], stream_name, consumer_group)
                
                except Exception as e:
                    logger.error(f"Error consuming messages: {e}")
                    await asyncio.sleep(1)
                    
        except Exception as e:
            logger.error(f"Consumer startup failed: {e}")
        finally:
            await self.redis_client.close()
    
    async def _process_messages_batch(self, messages: List, stream_name: str, consumer_group: str):
        """批量处理消息"""
        processing_tasks = []
        
        for message_id, fields in messages:
            task = self._process_single_message(message_id, fields, stream_name, consumer_group)
            processing_tasks.append(task)
        
        # 并发处理所有消息
        await asyncio.gather(*processing_tasks, return_exceptions=True)
    
    async def _process_single_message(self, message_id: str, fields: Dict, 
                                     stream_name: str, consumer_group: str):
        """处理单个消息"""
        try:
            # 解析消息
            message_type = fields.get(b'messageType', b'').decode('utf-8')
            payload = fields.get(b'payload', b'{}').decode('utf-8')
            
            if message_type in self.message_handlers:
                handler = self.message_handlers[message_type]
                data = json.loads(payload)
                
                # 异步处理消息
                await handler(data)
                
                # 确认消息处理完成
                await self.redis_client.xack(stream_name, consumer_group, message_id)
                
                logger.debug(f"Processed message {message_id} of type {message_type}")
            else:
                logger.warning(f"No handler for message type: {message_type}")
                
        except Exception as e:
            logger.error(f"Failed to process message {message_id}: {e}")
            # 这里可以实现重试逻辑
    
    async def send_message_async(self, stream_name: str, message_type: str, payload: Any):
        """异步发送消息"""
        try:
            message_data = {
                'messageType': message_type,
                'payload': json.dumps(payload),
                'timestamp': asyncio.get_event_loop().time()
            }
            
            message_id = await self.redis_client.xadd(stream_name, message_data)
            logger.debug(f"Sent message {message_id} to {stream_name}")
            return message_id
            
        except Exception as e:
            logger.error(f"Failed to send message to {stream_name}: {e}")
            raise
    
    def stop(self):
        """停止消息处理"""
        self.running = False

# AI工具服务的消息处理示例
class AIToolMessageHandler:
    """AI工具消息处理器"""
    
    def __init__(self):
        self.message_handler = AsyncMessageHandler()
        self._register_handlers()
    
    def _register_handlers(self):
        """注册消息处理器"""
        self.message_handler.register_handler("code_interpreter", self._handle_code_request)
        self.message_handler.register_handler("deep_search", self._handle_search_request)
        self.message_handler.register_handler("file_process", self._handle_file_request)
    
    async def _handle_code_request(self, data: Dict[str, Any]):
        """处理代码执行请求"""
        try:
            from genie_tool.tool.code_interpreter import code_interpreter_agent
            
            task = data.get('task', '')
            file_names = data.get('file_names', [])
            request_id = data.get('request_id', '')
            
            # 异步执行代码解释
            async for result in code_interpreter_agent(
                task=task,
                file_names=file_names,
                request_id=request_id,
                stream=True
            ):
                # 将结果发送到结果队列
                await self.message_handler.send_message_async(
                    'ai-results',
                    'code_result',
                    {
                        'request_id': request_id,
                        'result': result.dict() if hasattr(result, 'dict') else str(result)
                    }
                )
                
        except Exception as e:
            logger.error(f"Code execution failed: {e}")
            # 发送错误结果
            await self.message_handler.send_message_async(
                'ai-results',
                'code_error',
                {
                    'request_id': data.get('request_id', ''),
                    'error': str(e)
                }
            )
    
    async def _handle_search_request(self, data: Dict[str, Any]):
        """处理搜索请求"""
        try:
            from genie_tool.tool.deepsearch import DeepSearch
            
            query = data.get('query', '')
            request_id = data.get('request_id', '')
            
            search_tool = DeepSearch()
            
            # 异步执行搜索
            async for result in search_tool.run(
                query=query,
                request_id=request_id,
                stream=True
            ):
                # 发送搜索结果
                await self.message_handler.send_message_async(
                    'ai-results',
                    'search_result',
                    {
                        'request_id': request_id,
                        'result': result
                    }
                )
                
        except Exception as e:
            logger.error(f"Search failed: {e}")
            await self.message_handler.send_message_async(
                'ai-results',
                'search_error',
                {
                    'request_id': data.get('request_id', ''),
                    'error': str(e)
                }
            )
    
    async def start(self):
        """启动消息处理"""
        await self.message_handler.start_consuming(
            'ai-tools',
            'tool-processors',
            'tool-worker-1'
        )
```

## 2.2.6.3 事件驱动架构

### 领域事件设计

```java
// DomainEvent.java - 领域事件基类
public abstract class DomainEvent {
    private final String eventId;
    private final LocalDateTime occurredOn;
    private final String aggregateId;
    
    protected DomainEvent(String aggregateId) {
        this.eventId = UUID.randomUUID().toString();
        this.occurredOn = LocalDateTime.now();
        this.aggregateId = aggregateId;
    }
    
    // getters...
}

// AI相关的领域事件
public class AITaskStartedEvent extends DomainEvent {
    private final String taskType;
    private final Map<String, Object> taskParameters;
    
    public AITaskStartedEvent(String taskId, String taskType, Map<String, Object> parameters) {
        super(taskId);
        this.taskType = taskType;
        this.taskParameters = parameters;
    }
}

public class AITaskCompletedEvent extends DomainEvent {
    private final String result;
    private final long processingTimeMs;
    
    public AITaskCompletedEvent(String taskId, String result, long processingTimeMs) {
        super(taskId);
        this.result = result;
        this.processingTimeMs = processingTimeMs;
    }
}

public class AITaskFailedEvent extends DomainEvent {
    private final String errorMessage;
    private final String errorType;
    
    public AITaskFailedEvent(String taskId, String errorMessage, String errorType) {
        super(taskId);
        this.errorMessage = errorMessage;
        this.errorType = errorType;
    }
}
```

### 异步事件处理器

```java
// AsyncEventHandler.java - 异步事件处理器
@Component
public class AsyncEventHandler {
    
    private final ApplicationEventPublisher eventPublisher;
    private final ExecutorService eventExecutor = Executors.newFixedThreadPool(10);
    
    /**
     * 异步发布领域事件
     */
    public void publishEventAsync(DomainEvent event) {
        CompletableFuture.runAsync(() -> {
            try {
                eventPublisher.publishEvent(event);
                logger.debug("Event published: {}", event.getClass().getSimpleName());
            } catch (Exception e) {
                logger.error("Failed to publish event: {}", event.getEventId(), e);
            }
        }, eventExecutor);
    }
    
    /**
     * 批量发布事件
     */
    public CompletableFuture<Void> publishEventsAsync(List<DomainEvent> events) {
        List<CompletableFuture<Void>> futures = events.stream()
            .map(event -> CompletableFuture.runAsync(() -> publishEventAsync(event), eventExecutor))
            .collect(Collectors.toList());
        
        return CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]));
    }
}

// EventHandlers.java - 具体事件处理器
@Component
public class AIEventHandlers {
    
    private final NotificationService notificationService;
    private final MetricsService metricsService;
    private final AuditService auditService;
    
    @EventListener
    @Async("eventExecutor")
    public void handleTaskStarted(AITaskStartedEvent event) {
        try {
            // 记录任务开始指标
            metricsService.recordTaskStart(event.getTaskType());
            
            // 发送开始通知（如果需要）
            if (isNotificationRequired(event)) {
                notificationService.sendTaskStartNotification(event);
            }
            
            logger.info("AI task started: {} ({})", event.getAggregateId(), event.getTaskType());
            
        } catch (Exception e) {
            logger.error("Failed to handle task started event", e);
        }
    }
    
    @EventListener
    @Async("eventExecutor")
    public void handleTaskCompleted(AITaskCompletedEvent event) {
        try {
            // 记录完成指标
            metricsService.recordTaskCompletion(event.getProcessingTimeMs());
            
            // 审计日志
            auditService.logTaskCompletion(event);
            
            // 触发后续处理
            triggerPostProcessing(event);
            
            logger.info("AI task completed: {} ({}ms)", 
                       event.getAggregateId(), event.getProcessingTimeMs());
                       
        } catch (Exception e) {
            logger.error("Failed to handle task completed event", e);
        }
    }
    
    @EventListener
    @Async("eventExecutor")
    public void handleTaskFailed(AITaskFailedEvent event) {
        try {
            // 记录失败指标
            metricsService.recordTaskFailure(event.getErrorType());
            
            // 发送告警
            notificationService.sendErrorAlert(event);
            
            // 审计日志
            auditService.logTaskFailure(event);
            
            logger.error("AI task failed: {} - {}", event.getAggregateId(), event.getErrorMessage());
            
        } catch (Exception e) {
            logger.error("Failed to handle task failed event", e);
        }
    }
    
    private void triggerPostProcessing(AITaskCompletedEvent event) {
        // 异步触发后续处理逻辑
        CompletableFuture.runAsync(() -> {
            // 例如：清理临时文件、更新缓存、触发其他服务等
        });
    }
}
```

## 2.2.6.4 服务网格与异步通信

### Service Mesh集成

```java
// ServiceMeshClient.java - 服务网格客户端
@Component
public class ServiceMeshClient {
    
    private final WebClient webClient;
    private final CircuitBreaker circuitBreaker;
    
    public ServiceMeshClient() {
        this.webClient = WebClient.builder()
            .baseUrl("http://ai-tool-service")
            .codecs(configurer -> configurer.defaultCodecs().maxInMemorySize(10 * 1024 * 1024))
            .build();
            
        this.circuitBreaker = CircuitBreaker.ofDefaults("ai-tool-service");
    }
    
    /**
     * 异步调用AI工具服务
     */
    public CompletableFuture<AIToolResponse> callAIToolAsync(AIToolRequest request) {
        Supplier<CompletableFuture<AIToolResponse>> decoratedSupplier = 
            CircuitBreaker.decorateSupplier(circuitBreaker, () -> {
                return webClient.post()
                    .uri("/v1/tool/process")
                    .bodyValue(request)
                    .retrieve()
                    .bodyToMono(AIToolResponse.class)
                    .timeout(Duration.ofSeconds(30))
                    .toFuture();
            });
        
        return decoratedSupplier.get()
            .exceptionally(throwable -> {
                logger.error("AI tool service call failed", throwable);
                return AIToolResponse.error("Service unavailable");
            });
    }
    
    /**
     * 流式调用AI服务
     */
    public Flux<String> callAIServiceStream(AIStreamRequest request) {
        return webClient.post()
            .uri("/v1/ai/stream")
            .bodyValue(request)
            .accept(MediaType.TEXT_EVENT_STREAM)
            .retrieve()
            .bodyToFlux(String.class)
            .onErrorResume(throwable -> {
                logger.error("AI service stream failed", throwable);
                return Flux.just("Error: " + throwable.getMessage());
            })
            .timeout(Duration.ofMinutes(5));
    }
    
    /**
     * 并行调用多个AI服务
     */
    public CompletableFuture<List<AIServiceResponse>> callMultipleServicesAsync(
            List<AIServiceRequest> requests) {
        
        List<CompletableFuture<AIServiceResponse>> futures = requests.stream()
            .map(request -> callSingleServiceAsync(request))
            .collect(Collectors.toList());
        
        return CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
            .thenApply(v -> futures.stream()
                .map(future -> {
                    try {
                        return future.get();
                    } catch (Exception e) {
                        return AIServiceResponse.error(e.getMessage());
                    }
                })
                .collect(Collectors.toList()));
    }
    
    private CompletableFuture<AIServiceResponse> callSingleServiceAsync(AIServiceRequest request) {
        return webClient.post()
            .uri(request.getServiceEndpoint())
            .bodyValue(request.getPayload())
            .retrieve()
            .bodyToMono(AIServiceResponse.class)
            .toFuture();
    }
}
```

### Kubernetes异步调度

```yaml
# ai-service-deployment.yaml - AI服务Kubernetes配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-tool-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-tool-service
  template:
    metadata:
      labels:
        app: ai-tool-service
    spec:
      containers:
      - name: ai-tool
        image: ai-tool-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        - name: ASYNC_WORKERS
          value: "10"
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: ai-tool-service
spec:
  selector:
    app: ai-tool-service
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-tool-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-tool-service
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## 2.2.6.5 分布式事务与最终一致性

### Saga模式实现

```java
// SagaOrchestrator.java - Saga编排器
@Component
public class AIProcessingSaga {
    
    private final List<SagaStep> sagaSteps;
    private final SagaStateRepository sagaStateRepository;
    
    public AIProcessingSaga() {
        this.sagaSteps = List.of(
            new FilePreprocessStep(),
            new AIAnalysisStep(),
            new ResultStorageStep(),
            new NotificationStep()
        );
    }
    
    /**
     * 异步执行Saga流程
     */
    public CompletableFuture<SagaResult> executeSagaAsync(AIProcessingRequest request) {
        String sagaId = UUID.randomUUID().toString();
        SagaState sagaState = new SagaState(sagaId, request);
        
        return sagaStateRepository.save(sagaState)
            .thenCompose(state -> executeStepsAsync(state))
            .exceptionally(throwable -> {
                logger.error("Saga execution failed: {}", sagaId, throwable);
                compensateAsync(sagaState);
                return SagaResult.failed(throwable.getMessage());
            });
    }
    
    private CompletableFuture<SagaResult> executeStepsAsync(SagaState sagaState) {
        return sagaSteps.stream()
            .reduce(
                CompletableFuture.completedFuture(sagaState),
                (futureState, step) -> futureState.thenCompose(state -> 
                    executeStepAsync(step, state)
                ),
                (f1, f2) -> f1.thenCombine(f2, (s1, s2) -> s2)
            )
            .thenApply(state -> SagaResult.success(state.getResult()));
    }
    
    private CompletableFuture<SagaState> executeStepAsync(SagaStep step, SagaState sagaState) {
        return CompletableFuture.supplyAsync(() -> {
            try {
                logger.info("Executing saga step: {} for saga: {}", 
                           step.getStepName(), sagaState.getSagaId());
                
                StepResult result = step.execute(sagaState);
                sagaState.addStepResult(step.getStepName(), result);
                sagaState.markStepCompleted(step.getStepName());
                
                // 持久化状态
                sagaStateRepository.update(sagaState);
                
                return sagaState;
                
            } catch (Exception e) {
                sagaState.markStepFailed(step.getStepName(), e.getMessage());
                throw new RuntimeException("Step failed: " + step.getStepName(), e);
            }
        });
    }
    
    private CompletableFuture<Void> compensateAsync(SagaState sagaState) {
        // 反向执行补偿操作
        List<SagaStep> completedSteps = getCompletedSteps(sagaState);
        Collections.reverse(completedSteps);
        
        List<CompletableFuture<Void>> compensationFutures = completedSteps.stream()
            .map(step -> compensateStepAsync(step, sagaState))
            .collect(Collectors.toList());
        
        return CompletableFuture.allOf(compensationFutures.toArray(new CompletableFuture[0]));
    }
    
    private CompletableFuture<Void> compensateStepAsync(SagaStep step, SagaState sagaState) {
        return CompletableFuture.runAsync(() -> {
            try {
                logger.info("Compensating saga step: {} for saga: {}", 
                           step.getStepName(), sagaState.getSagaId());
                
                step.compensate(sagaState);
                sagaState.markStepCompensated(step.getStepName());
                
            } catch (Exception e) {
                logger.error("Compensation failed for step: {}", step.getStepName(), e);
            }
        });
    }
}

// SagaStep接口
public interface SagaStep {
    String getStepName();
    StepResult execute(SagaState sagaState) throws Exception;
    void compensate(SagaState sagaState) throws Exception;
}

// 具体的Saga步骤实现
public class FilePreprocessStep implements SagaStep {
    
    @Override
    public String getStepName() {
        return "file-preprocess";
    }
    
    @Override
    public StepResult execute(SagaState sagaState) throws Exception {
        // 文件预处理逻辑
        AIProcessingRequest request = sagaState.getOriginalRequest();
        List<String> processedFiles = preprocessFiles(request.getFileNames());
        
        return StepResult.success("files-processed", processedFiles);
    }
    
    @Override
    public void compensate(SagaState sagaState) throws Exception {
        // 清理预处理的文件
        StepResult result = sagaState.getStepResult("file-preprocess");
        if (result != null) {
            List<String> processedFiles = (List<String>) result.getData();
            cleanupProcessedFiles(processedFiles);
        }
    }
}
```

## 2.2.6.6 监控与故障处理

### 分布式链路追踪

```java
// TracingConfiguration.java - 链路追踪配置
@Configuration
public class TracingConfiguration {
    
    @Bean
    public Tracer tracer() {
        return GlobalTracer.get();
    }
    
    @Aspect
    @Component
    public class AsyncTracingAspect {
        
        @Around("@annotation(AsyncTraced)")
        public Object traceAsync(ProceedingJoinPoint joinPoint) throws Throwable {
            Span span = tracer.nextSpan()
                .name(joinPoint.getSignature().getName())
                .tag("service", "ai-service")
                .start();
            
            try (Tracer.SpanInScope ws = tracer.withSpanInScope(span)) {
                Object result = joinPoint.proceed();
                
                if (result instanceof CompletableFuture) {
                    return ((CompletableFuture<?>) result)
                        .whenComplete((res, ex) -> {
                            if (ex != null) {
                                span.tag("error", ex.getMessage());
                            }
                            span.end();
                        });
                } else {
                    span.end();
                    return result;
                }
                
            } catch (Exception e) {
                span.tag("error", e.getMessage());
                span.end();
                throw e;
            }
        }
    }
}

// 使用示例
@Service
public class AIServiceWithTracing {
    
    @AsyncTraced
    public CompletableFuture<String> processAIRequestAsync(AIRequest request) {
        return CompletableFuture.supplyAsync(() -> {
            // AI处理逻辑
            return "AI result";
        });
    }
}
```

### 健康检查与自动恢复

```python
# health_check.py - 健康检查服务
import asyncio
import aiohttp
from typing import Dict, List
import logging

class ServiceHealthChecker:
    """服务健康检查器"""
    
    def __init__(self, check_interval: int = 30):
        self.check_interval = check_interval
        self.services: Dict[str, str] = {}
        self.service_status: Dict[str, bool] = {}
        self.running = False
    
    def register_service(self, service_name: str, health_endpoint: str):
        """注册需要监控的服务"""
        self.services[service_name] = health_endpoint
        self.service_status[service_name] = True
        logger.info(f"Registered service for health check: {service_name}")
    
    async def start_monitoring(self):
        """开始健康检查监控"""
        self.running = True
        logger.info("Started health check monitoring")
        
        while self.running:
            await self._check_all_services()
            await asyncio.sleep(self.check_interval)
    
    async def _check_all_services(self):
        """检查所有服务的健康状态"""
        check_tasks = [
            self._check_single_service(service_name, endpoint)
            for service_name, endpoint in self.services.items()
        ]
        
        results = await asyncio.gather(*check_tasks, return_exceptions=True)
        
        for i, (service_name, _) in enumerate(self.services.items()):
            is_healthy = not isinstance(results[i], Exception) and results[i]
            previous_status = self.service_status.get(service_name, True)
            
            self.service_status[service_name] = is_healthy
            
            if previous_status != is_healthy:
                if is_healthy:
                    logger.info(f"Service {service_name} is now healthy")
                    await self._handle_service_recovery(service_name)
                else:
                    logger.error(f"Service {service_name} is now unhealthy")
                    await self._handle_service_failure(service_name)
    
    async def _check_single_service(self, service_name: str, endpoint: str) -> bool:
        """检查单个服务的健康状态"""
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                async with session.get(endpoint) as response:
                    return response.status == 200
        except Exception as e:
            logger.debug(f"Health check failed for {service_name}: {e}")
            return False
    
    async def _handle_service_failure(self, service_name: str):
        """处理服务故障"""
        # 发送告警
        await self._send_alert(f"Service {service_name} is unhealthy")
        
        # 尝试自动恢复
        if service_name in ["ai-tool-service", "file-service"]:
            await self._attempt_service_restart(service_name)
    
    async def _handle_service_recovery(self, service_name: str):
        """处理服务恢复"""
        await self._send_recovery_notification(f"Service {service_name} has recovered")
    
    async def _attempt_service_restart(self, service_name: str):
        """尝试重启服务"""
        try:
            # 这里可以集成Kubernetes API来重启Pod
            logger.info(f"Attempting to restart service: {service_name}")
            # kubectl rollout restart deployment/{service_name}
        except Exception as e:
            logger.error(f"Failed to restart service {service_name}: {e}")
    
    async def _send_alert(self, message: str):
        """发送告警"""
        # 集成告警系统（如钉钉、Slack等）
        logger.warning(f"ALERT: {message}")
    
    async def _send_recovery_notification(self, message: str):
        """发送恢复通知"""
        logger.info(f"RECOVERY: {message}")
    
    def stop(self):
        """停止健康检查"""
        self.running = False
```

## 小结

微服务架构下的异步通信是构建可扩展AI应用的关键技术。通过合理的消息队列、事件驱动架构、服务网格集成以及完善的监控机制，可以实现服务间的高效协作和故障容错。

关键要点：
1. **消息驱动通信**：使用Redis Stream等消息队列实现服务解耦
2. **事件驱动架构**：通过领域事件实现业务逻辑的松耦合
3. **分布式事务**：使用Saga模式处理跨服务的事务一致性
4. **服务治理**：集成服务网格和熔断器模式
5. **监控告警**：实施链路追踪和健康检查机制

---

**架构设计建议：**
1. 合理拆分服务边界，避免过度拆分
2. 设计清晰的消息协议和事件模型
3. 实施有效的服务发现和负载均衡
4. 建立完善的监控和故障恢复机制
5. 考虑数据一致性和事务处理策略
